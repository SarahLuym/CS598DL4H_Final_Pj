{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":["nCvD6b0w0HxI","crMtkro_05Ae","zw8mdz7VlVFT"],"authorship_tag":"ABX9TyOTQZTbUu/sRapivonSQVCK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Preparation"],"metadata":{"id":"bNXOeEc_OGqg"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"AP1-sbhoIHb3","executionInfo":{"status":"ok","timestamp":1682969358398,"user_tz":300,"elapsed":2,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICirv2eqN8ua","executionInfo":{"status":"ok","timestamp":1682969383122,"user_tz":300,"elapsed":24726,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"c2d707a2-e637-4b6b-8b22-1dfb376b8f3f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'CS598_DL4H'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","os.chdir(GOOGLE_DRIVE_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ki7zFjNON_2c","executionInfo":{"status":"ok","timestamp":1682969383545,"user_tz":300,"elapsed":426,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"8f2ec1b7-d9cb-440f-ebc9-a3c74f9e50a6"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['mimic-iii-clinical-database-1.4', 'mimic3benchmark', 'mimic3models', 'data', 'utils', 'model', 'prepare_dataset.ipynb', 'demographic_data.txt', 'diagnosis_data.txt', 'idx_list.txt', 'demographic.ipynb', 'ConCare (1).ipynb', 'retain-master', 'Retain_Test.ipynb', 'concare-notebook.ipynb', 'ConCare.ipynb']\n"]}]},{"cell_type":"code","source":["%cd mimic3-benchmarks-master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VeIQbaG-OB1O","executionInfo":{"status":"ok","timestamp":1682969383545,"user_tz":300,"elapsed":7,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"db3f8623-84db-4f2b-860f-f642adf7ad08"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'mimic3-benchmarks-master'\n","/content\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import argparse\n","import os\n","import imp\n","import re\n","import pickle\n","import datetime\n","import random\n","import math\n","import copy\n","\n","\n","import torch\n","from torch import nn\n","import torch.nn.utils.rnn as rnn_utils\n","from torch.utils.data import DataLoader, Dataset\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","\n","from utils import utils\n","from utils.readers import InHospitalMortalityReader\n","from utils.preprocessing import Discretizer, Normalizer\n","from utils import metrics\n","from utils import common_utils\n"],"metadata":{"id":"MXyamQovODig","executionInfo":{"status":"ok","timestamp":1682969395072,"user_tz":300,"elapsed":11529,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"6hvVGcvwVDwY"}},{"cell_type":"code","source":["TIMESTEP = 1.0\n","data_path = 'data/hospital-mortality/'\n","# Build readers, discretizers, normalizers\n","train_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'train'),\n","                                         listfile=os.path.join(data_path, 'train_listfile.csv'),\n","                                         period_length=48.0)\n","\n","val_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'train'),\n","                                       listfile=os.path.join(data_path, 'val_listfile.csv'),\n","                                       period_length=48.0)\n","\n","discretizer = Discretizer(timestep=TIMESTEP,\n","                          store_masks=True,\n","                          impute_strategy='previous',\n","                          start_time='zero')"],"metadata":{"id":"USEPOzQUVGej","executionInfo":{"status":"ok","timestamp":1682969396191,"user_tz":300,"elapsed":1138,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["discretizer_header = discretizer.transform(train_reader.read_example(0)[\"X\"])[1].split(',')\n","cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n","\n","normalizer = Normalizer(fields=cont_channels)  # choose here which columns to standardize\n","normalizer_state = 'ihm_normalizer'\n","normalizer_state = os.path.join(os.path.dirname(data_path), normalizer_state)\n","normalizer.load_params(normalizer_state)"],"metadata":{"id":"n-Eqe4l2Vtn7","executionInfo":{"status":"ok","timestamp":1682969515429,"user_tz":300,"elapsed":119240,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train_raw = utils.load_data(train_reader, discretizer, normalizer, return_names=True)\n","val_raw = utils.load_data(val_reader, discretizer, normalizer, return_names=True)"],"metadata":{"id":"2nuWQUPUZDNW","executionInfo":{"status":"ok","timestamp":1682981620447,"user_tz":300,"elapsed":12096040,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["demographic_data = []\n","with open('demographic_data.txt', 'r') as f:\n","  for line in f:\n","    demographic_data.append(np.fromstring(line, dtype=float, sep=' '))\n","\n","diagnosis_data = []\n","with open('diagnosis_data.txt', 'r') as f:\n","  for line in f:\n","    diagnosis_data.append(np.fromstring(line, dtype=int, sep=' '))\n","\n","idx_list = []\n","with open('idx_list.txt', 'r') as f:\n","  for line in f:\n","    idx_list.append(line.strip())\n","\n","len(demographic_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjR4Ah1rZDIn","executionInfo":{"status":"ok","timestamp":1682981626265,"user_tz":300,"elapsed":5839,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"e5813c8d-7566-49cd-b7ee-fff74f812738"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-761523da05f3>:9: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n","  diagnosis_data.append(np.fromstring(line, dtype=int, sep=' '))\n"]},{"output_type":"execute_result","data":{"text/plain":["42125"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["class Dataset(Dataset):\n","  def __init__(self, x, y, name):\n","    self.x = x\n","    self.y = y\n","    self.name = name\n","  \n","  def __getitem__(self, index):\n","    return self.x[index], self.y[index], self.name[index]\n","  \n","  def __len__(self):\n","    return len(self.x)"],"metadata":{"id":"3EQDS3mjbi05","executionInfo":{"status":"ok","timestamp":1682981626265,"user_tz":300,"elapsed":10,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 256\n","train_dataset = Dataset(train_raw['data'][0], train_raw['data'][1], train_raw['names'])\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_dataset = Dataset(val_raw['data'][0], val_raw['data'][1], val_raw['names'])\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"id":"GOrTvUANeiwI","executionInfo":{"status":"ok","timestamp":1682981626266,"user_tz":300,"elapsed":10,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# ConCare Model"],"metadata":{"id":"W8Imh5JuZUb8"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n","print(\"available device: {}\".format(device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTRqdZw_ZV3x","executionInfo":{"status":"ok","timestamp":1682981626266,"user_tz":300,"elapsed":9,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"773bf46e-cb34-4efe-c646-653946b4bef4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["available device: cuda:0\n"]}]},{"cell_type":"code","source":["class DemographicEmbed(nn.Module):\n","  def __init__(self, demo_input_dim, hidden_dim):\n","    super().__init__()\n","    self.demo_input_dim = demo_input_dim\n","    self.hidden_dim = hidden_dim\n","\n","    self.fc = nn.Linear(self.demo_input_dim, self.hidden_dim)\n","    # self.dropout = nn.Dropout(dropout)\n","  \n","  def forward(self, x):\n","    return F.tanh(self.fc(x))"],"metadata":{"id":"osxsnJwZymGQ","executionInfo":{"status":"ok","timestamp":1682981626266,"user_tz":300,"elapsed":6,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class TimeAwareSelfAttention(nn.Module):\n","  def __init__(self, input_dim, hidden_dim):\n","    super().__init__()\n","    self.input_dim = input_dim\n","    self.hidden_dim = hidden_dim\n","\n","    self.w_qs = nn.Parameter(torch.randn(input_dim, hidden_dim))\n","    self.w_ks = nn.Parameter(torch.randn(input_dim, hidden_dim))\n","    self.beta = nn.Parameter(torch.zeros(1)+0.8)\n","\n","    nn.init.kaiming_uniform_(self.w_qs, a=math.sqrt(5))\n","    nn.init.kaiming_uniform_(self.w_ks, a=math.sqrt(5))\n","  \n","  def forward(self, input):\n","    b, time_step, input_dim = input.size()\n","    time_decays = torch.tensor(range(47, -1, -1), dtype=torch.float32).unsqueeze(-1).unsqueeze(0).to(device) # 1*T*1\n","    b_time_decays = time_decays.repeat(b, 1, 1)+1 # B*T*1\n","\n","    q = torch.matmul(input[:, -1, :], self.w_qs).reshape(b, 1, self.hidden_dim) # B*1*H\n","    k = torch.matmul(input, self.w_ks) # B*T*H\n","    v = input # B*T*H\n","    product = torch.matmul(q, k.transpose(1, 2)).squeeze() # B*T\n","    denominator = self.beta * torch.log(math.e + (1 - F.sigmoid(product)) * (b_time_decays.squeeze()))\n","    weights = F.softmax(F.tanh(product / denominator)) # B*T\n","    output = torch.matmul(weights.unsqueeze(1), v).squeeze() # B*H\n","\n","    return output, weights"],"metadata":{"id":"Lnphzxbfvh0P","executionInfo":{"status":"ok","timestamp":1682981626778,"user_tz":300,"elapsed":518,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class ScaledDotProductAttention(nn.Module):\n","  def __init__(self, dropout=0.1):\n","    super().__init__()\n","    self.dropout = nn.Dropout(dropout)\n","    \n","  def forward(self, q, k, v):\n","    d_k = q.size(-1)\n","    attn = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n","    attn = self.dropout(F.softmax(attn, dim=-1))\n","    output = torch.matmul(attn, v)\n","\n","    return output, attn"],"metadata":{"id":"Wt3T3gbXzh_0","executionInfo":{"status":"ok","timestamp":1682981626779,"user_tz":300,"elapsed":7,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def cov(u):\n","  miu = torch.mean(u, dim=1).unsqueeze(1)\n","  diff = u - miu\n","  cov = torch.mm(diff, diff.T) / (diff.size(1)-1)\n","  return cov\n","\n","def cross_head_decorr(u):\n","  covs = cov(u[0, :, :])\n","  loss = 0.5 * (torch.norm(covs, p='fro') ** 2 - torch.norm(torch.diag(covs)) ** 2)\n","  for i in range(u.size(0)-1):\n","    covs = cov(u[i+1, :, :])\n","    loss += 0.5 * (torch.norm(covs, p='fro') ** 2 - torch.norm(torch.diag(covs)) ** 2)\n","  return loss"],"metadata":{"id":"AjrKSZfusZFU","executionInfo":{"status":"ok","timestamp":1682981626779,"user_tz":300,"elapsed":6,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, n_head, d_model):\n","    super().__init__()\n","    self.n_head = n_head\n","    self.d_model = d_model\n","\n","    self.w_qs = nn.Linear(self.d_model, self.d_model, bias=False)\n","    self.w_ks = nn.Linear(self.d_model, self.d_model, bias=False)\n","    self.w_vs = nn.Linear(self.d_model, self.d_model, bias=False)\n","    self.fc = nn.Linear(self.d_model, self.d_model, bias=False)\n","\n","    self.attn = ScaledDotProductAttention()\n","\n","    # self.dropout = nn.Dropout(dropout)\n","    # self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n","\n","  def forward(self, q, k, v):\n","    b, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1)\n","    q = self.w_qs(q).view(b, len_q, self.n_head, self.d_model // self.n_head)\n","    k = self.w_ks(k).view(b, len_k, self.n_head, self.d_model // self.n_head)\n","    v = self.w_vs(v).view(b, len_v, self.n_head, self.d_model // self.n_head)\n","    q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2) # B*num_heads*d_input*d_k\n","\n","    q, attn = self.attn(q, k, v)\n","\n","    q = q.transpose(1, 2).contiguous().view(b, len_q, self.d_model) # B*d_input*d_model\n","    output_q = self.fc(q)\n","\n","    # DeCov\n","    u = q.transpose(0, 1).transpose(1, 2) # d_input*d_model*B\n","    decov_loss = cross_head_decorr(u)\n","\n","    return output_q, decov_loss\n"],"metadata":{"id":"-Zdx7jxAx8ST","executionInfo":{"status":"ok","timestamp":1682981626779,"user_tz":300,"elapsed":6,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class PositionwiseFeedForward(nn.Module):\n","  def __init__(self, d_model, ff_hidden, dropout=0.1):\n","    super().__init__()\n","    self.fc1 = nn.Linear(d_model, ff_hidden)\n","    self.fc2 = nn.Linear(ff_hidden, d_model)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x):\n","    output = self.fc2(self.dropout(F.relu(self.fc1(x))))\n","    return output"],"metadata":{"id":"hSJCXZntwUC8","executionInfo":{"status":"ok","timestamp":1682981626779,"user_tz":300,"elapsed":6,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class ResConnect(nn.Module):\n","  def __init__(self, norm_shape, dropout=0.5):\n","    super().__init__()\n","    self.lnorm = nn.LayerNorm(norm_shape)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x, layer):\n","    res = layer(self.lnorm(x))\n","    output = x + self.dropout(res[0])\n","    return output, res[1]"],"metadata":{"id":"KlfNS6Xpt6WS","executionInfo":{"status":"ok","timestamp":1682981626780,"user_tz":300,"elapsed":6,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["class FinalAttention(nn.Module):\n","  def __init__(self, input_dim, hidden_dim, dropout=0.5):\n","    super().__init__()\n","\n","    self.input_dim = input_dim\n","    self.hidden_dim = hidden_dim\n","\n","    self.w_qs = nn.Linear(input_dim, hidden_dim)\n","    self.w_ks = nn.Linear(input_dim, hidden_dim)\n","    self.w_vs = nn.Linear(input_dim, hidden_dim)\n","\n","    # Parameter Initialization\n","    nn.init.kaiming_uniform_(self.w_qs.weight, a=math.sqrt(5))\n","    nn.init.kaiming_uniform_(self.w_ks.weight, a=math.sqrt(5))\n","    nn.init.kaiming_uniform_(self.w_vs.weight, a=math.sqrt(5))\n","    \n","    self.dropout = nn.Dropout(dropout)\n","  \n","  def forward(self, input):\n","    batch_size, time_step, input_dim = input.size()\n","    q = self.w_qs(input[:, -1, :]).reshape(batch_size, self.hidden_dim, 1) # B*H*1\n","    k = self.w_ks(input) # B*T*H\n","    v = self.w_vs(input) # B*T*H\n","\n","    attention = F.tanh(torch.matmul(k, q).squeeze())\n","    score = F.softmax(attention)\n","\n","    score = self.dropout(score)\n","\n","    v = torch.matmul(score.unsqueeze(1), v).squeeze()\n","\n","    return v, score"],"metadata":{"id":"o2xtgG7LZZE8","executionInfo":{"status":"ok","timestamp":1682981626780,"user_tz":300,"elapsed":6,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class ConCare(nn.Module):\n","  def __init__(self, demo_input_dim, input_dim, hidden_dim1, hidden_dim2, d_model, n_head, ff_hidden, output_dim, dropout=0.5):\n","    super().__init__()\n","    self.demo_input_dim = demo_input_dim\n","    self.input_dim = input_dim\n","    self.hidden_dim1 = hidden_dim1\n","    self.hidden_dim2 = hidden_dim2\n","    self.d_model = d_model\n","    self.n_head = n_head\n","    self.ff_hidden = ff_hidden\n","    self.output_dim = output_dim\n","    self.dropout = dropout\n","\n","    self.demo_embed = DemographicEmbed(self.demo_input_dim, self.hidden_dim1)\n","    self.grus = nn.ModuleList([copy.deepcopy(nn.GRU(1, self.hidden_dim1, batch_first=True)) for _ in range(self.input_dim)])\n","    self.time_attns = nn.ModuleList([copy.deepcopy(TimeAwareSelfAttention(self.hidden_dim1, self.hidden_dim2)) for _ in range(self.input_dim)])\n","    self.multi_attn = MultiHeadAttention(self.n_head, self.d_model)\n","    self.final_attn = FinalAttention(self.hidden_dim1, self.hidden_dim1, dropout=self.dropout)\n","    self.res = ResConnect(self.d_model, dropout=self.dropout)\n","    self.pos_ff = PositionwiseFeedForward(self.d_model, self.ff_hidden, dropout=0.1)\n","    self.output_fc1 = nn.Linear(self.hidden_dim1, self.hidden_dim1)\n","    self.output_fc2 = nn.Linear(self.hidden_dim1, self.output_dim)\n","    self.dp = nn.Dropout(self.dropout)\n","  \n","  def forward(self, input, demo):\n","    # Demographic embedding\n","    demo_embedding = self.demo_embed(demo)\n","\n","    # First record embedding\n","    batch_size = input.size(0)\n","    feat_dim = input.size(2)\n","    record_embedding1 = self.grus[0](input[:, :, 0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim1).unsqueeze(0)).to(device))[0] # B*1*H\n","    time_attn_output = self.time_attns[0](record_embedding1)[0].unsqueeze(1) # B*1*H\n","\n","    # All other records embeddings\n","    for i in range(1, feat_dim):\n","      embedding = self.grus[i](input[:, :, i].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim1).unsqueeze(0)).to(device))[0] # B*1*H\n","      attn = self.time_attns[i](embedding)[0].unsqueeze(1) # B*1*H\n","      time_attn_output = torch.cat((time_attn_output, attn), 1)\n","    \n","    # Combine with demographic embedding\n","    demo_embedding = demo_embedding.unsqueeze(1)\n","    time_attn_output = torch.cat((time_attn_output, demo_embedding), 1)\n","    time_attn_output = self.dp(time_attn_output)\n","\n","    # Get multi-head attention\n","    multi_attn_output, dev_loss = self.res(time_attn_output, lambda x: self.multi_attn(time_attn_output, time_attn_output, time_attn_output))\n","    final_input = self.res(multi_attn_output, lambda x: self.pos_ff(multi_attn_output))[0]\n","\n","    # Get final output\n","    value, score = self.final_attn(final_input)\n","    output = F.sigmoid(self.output_fc2(F.relu(self.output_fc1(value))))\n","\n","    return output, dev_loss"],"metadata":{"id":"row6kSkZsN3A","executionInfo":{"status":"ok","timestamp":1682981626780,"user_tz":300,"elapsed":6,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"ycMI90-I-THV"}},{"cell_type":"code","source":["RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic=True"],"metadata":{"id":"iGTYs-lr-Uly","executionInfo":{"status":"ok","timestamp":1682981626780,"user_tz":300,"elapsed":6,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["model = ConCare(demo_input_dim=12, input_dim=76, hidden_dim1=64, hidden_dim2=8, d_model=64, n_head=4, ff_hidden=256, output_dim=1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.BCELoss()"],"metadata":{"id":"1DkBKR7z_CC3","executionInfo":{"status":"ok","timestamp":1682981634873,"user_tz":300,"elapsed":8098,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["max_roc = 0\n","max_prc = 0\n","train_total_loss = []\n","val_total_loss = []\n","result_history = []\n","file_name = 'model/concare0'\n","\n","\n","for epoch in range(100):\n","  \n","  # Start training\n","  train_batch_total_loss = []\n","  model.train()\n","\n","  for step, (batch_x, batch_y, batch_name) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","    batch_x = batch_x.float().to(device)\n","    batch_y = batch_y.float().to(device)\n","\n","    # Get batch demographic data\n","    batch_demo = []\n","    for i in range(len(batch_name)):\n","      cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","      cur_idx = cur_id + '_' + cur_ep\n","      cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","      batch_demo.append(cur_demo)\n","    batch_demo = torch.stack(batch_demo).to(device)\n","\n","    # Get model outputs\n","    output, decov_loss = model(batch_x, batch_demo)\n","\n","    # Get loss\n","    loss = loss_func(output, batch_y.unsqueeze(-1))\n","    loss += 800 * decov_loss\n","    train_batch_total_loss.append(loss.cpu().detach().numpy())\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    if step % 50 == 0:\n","      print('Epoch %d Batch %d: Train Loss = %.4f'%(epoch, step, np.mean(np.array(train_batch_total_loss))))\n","    \n","  train_total_loss.append(np.mean(np.array(train_batch_total_loss)))\n","  print('Epoch %d: Train Loss = %.4f'%(epoch, np.mean(np.array(train_batch_total_loss))))\n","\n","  # Start Validating\n","  val_batch_total_loss = []\n","  y_true = []\n","  y_pred = []\n","\n","  with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(val_loader):\n","      batch_x = batch_x.float().to(device)\n","      batch_y = batch_y.float().to(device)\n","\n","      # Get batch demographic data\n","      batch_demo = []\n","      for i in range(len(batch_name)):\n","        cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","        cur_idx = cur_id + '_' + cur_ep\n","        cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","        batch_demo.append(cur_demo)\n","      batch_demo = torch.stack(batch_demo).to(device)\n","\n","      # Get model outputs\n","      output, decov_loss = model(batch_x, batch_demo)\n","\n","      # Get loss\n","      loss = loss_func(output, batch_y.unsqueeze(-1))\n","      loss += 10 * decov_loss\n","      val_batch_total_loss.append(loss.cpu().detach().numpy())\n","      y_pred += list(output.cpu().detach().numpy())\n","      y_true += list(batch_y.cpu().numpy().flatten())\n","    \n","    val_total_loss.append(np.mean(np.array(val_batch_total_loss)))\n","    print('Epoch %d: Validation Loss = %.4f'%(epoch, np.mean(np.array(val_batch_total_loss))))\n","\n","    y_pred = np.array(y_pred)\n","    y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","    result = metrics.print_metrics_binary(y_true, y_pred)\n","    result_history.append(result)\n","\n","    cur_auroc = result['auroc']\n","    print('Epoch %d: Validation AUROC = %.4f'%(epoch, cur_auroc))\n","    \n","    if cur_auroc > max_roc:\n","        max_roc = cur_auroc\n","        state = {\n","            'net': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'epoch': epoch\n","        }\n","        torch.save(state, file_name)\n","        print('\\n------------ Save best model ------------\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnVsIv98_uls","outputId":"dfdb5284-bed8-4432-bb96-f641b2dc3095","executionInfo":{"status":"ok","timestamp":1682983860490,"user_tz":300,"elapsed":2225635,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 Batch 0: Train Loss = 0.7203\n","Epoch 0 Batch 50: Train Loss = 0.4778\n","Epoch 0: Train Loss = 0.4703\n","Epoch 0: Validation Loss = 0.3991\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6345500971440993\n","AUC of PRC = 0.2329938027896914\n","min(+P, Se) = 0.27253218884120173\n","f1_score = nan\n","Epoch 0: Validation AUROC = 0.6346\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0: Train Loss = 0.3344\n","Epoch 1 Batch 50: Train Loss = 0.4006\n","Epoch 1: Train Loss = 0.4019\n","Epoch 1: Validation Loss = 0.3978\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6636780420369012\n","AUC of PRC = 0.23252787139961517\n","min(+P, Se) = 0.27713625866050806\n","f1_score = nan\n","Epoch 1: Validation AUROC = 0.6637\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Batch 0: Train Loss = 0.3533\n","Epoch 2 Batch 50: Train Loss = 0.3991\n","Epoch 2: Train Loss = 0.3999\n","Epoch 2: Validation Loss = 0.3972\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6988448004130323\n","AUC of PRC = 0.291550349696185\n","min(+P, Se) = 0.3287037037037037\n","f1_score = nan\n","Epoch 2: Validation AUROC = 0.6988\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Batch 0: Train Loss = 0.4331\n","Epoch 3 Batch 50: Train Loss = 0.4018\n","Epoch 3: Train Loss = 0.3995\n","Epoch 3: Validation Loss = 0.3986\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7187979776364773\n","AUC of PRC = 0.315345016729362\n","min(+P, Se) = 0.3548387096774194\n","f1_score = nan\n","Epoch 3: Validation AUROC = 0.7188\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 Batch 0: Train Loss = 0.4416\n","Epoch 4 Batch 50: Train Loss = 0.3983\n","Epoch 4: Train Loss = 0.3992\n","Epoch 4: Validation Loss = 0.3978\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7519182562973832\n","AUC of PRC = 0.3454428229739622\n","min(+P, Se) = 0.39592760180995473\n","f1_score = nan\n","Epoch 4: Validation AUROC = 0.7519\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 Batch 0: Train Loss = 0.4379\n","Epoch 5 Batch 50: Train Loss = 0.3919\n","Epoch 5: Train Loss = 0.3886\n","Epoch 5: Validation Loss = 0.3672\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7629467439743485\n","AUC of PRC = 0.35473360916223745\n","min(+P, Se) = 0.3876146788990826\n","f1_score = nan\n","Epoch 5: Validation AUROC = 0.7629\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 Batch 0: Train Loss = 0.4293\n","Epoch 6 Batch 50: Train Loss = 0.3712\n","Epoch 6: Train Loss = 0.3707\n","Epoch 6: Validation Loss = 0.3716\n","confusion matrix:\n","[[2709   17]\n"," [ 410   22]]\n","accuracy = 0.8647878170013428\n","precision class 0 = 0.8685476183891296\n","precision class 1 = 0.5641025900840759\n","recall class 0 = 0.9937637448310852\n","recall class 1 = 0.05092592537403107\n","AUC of ROC = 0.7217458425042798\n","AUC of PRC = 0.3148603921449167\n","min(+P, Se) = 0.32407407407407407\n","f1_score = 0.0934182607144379\n","Epoch 6: Validation AUROC = 0.7217\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 Batch 0: Train Loss = 0.3587\n","Epoch 7 Batch 50: Train Loss = 0.3633\n","Epoch 7: Train Loss = 0.3593\n","Epoch 7: Validation Loss = 0.3365\n","confusion matrix:\n","[[2720    6]\n"," [ 426    6]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8645899295806885\n","precision class 1 = 0.5\n","recall class 0 = 0.9977989792823792\n","recall class 1 = 0.013888888992369175\n","AUC of ROC = 0.7928045433548001\n","AUC of PRC = 0.391096629309723\n","min(+P, Se) = 0.4383561643835616\n","f1_score = 0.027027026880083512\n","Epoch 7: Validation AUROC = 0.7928\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 Batch 0: Train Loss = 0.3075\n","Epoch 8 Batch 50: Train Loss = 0.3473\n","Epoch 8: Train Loss = 0.3479\n","Epoch 8: Validation Loss = 0.3280\n","confusion matrix:\n","[[2721    5]\n"," [ 421   11]]\n","accuracy = 0.8651044964790344\n","precision class 0 = 0.8660089373588562\n","precision class 1 = 0.6875\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.025462962687015533\n","AUC of ROC = 0.8093521575500666\n","AUC of PRC = 0.432754229887048\n","min(+P, Se) = 0.4657534246575342\n","f1_score = 0.04910714080443194\n","Epoch 8: Validation AUROC = 0.8094\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 Batch 0: Train Loss = 0.3428\n","Epoch 9 Batch 50: Train Loss = 0.3377\n","Epoch 9: Train Loss = 0.3354\n","Epoch 9: Validation Loss = 0.3215\n","confusion matrix:\n","[[2664   62]\n"," [ 346   86]]\n","accuracy = 0.8708043098449707\n","precision class 0 = 0.8850498199462891\n","precision class 1 = 0.5810810923576355\n","recall class 0 = 0.9772560596466064\n","recall class 1 = 0.19907407462596893\n","AUC of ROC = 0.8154011609738866\n","AUC of PRC = 0.43929504504536177\n","min(+P, Se) = 0.481651376146789\n","f1_score = 0.29655172055456513\n","Epoch 9: Validation AUROC = 0.8154\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 Batch 0: Train Loss = 0.2837\n","Epoch 10 Batch 50: Train Loss = 0.3311\n","Epoch 10: Train Loss = 0.3294\n","Epoch 10: Validation Loss = 0.3137\n","confusion matrix:\n","[[2696   30]\n"," [ 366   66]]\n","accuracy = 0.8746041655540466\n","precision class 0 = 0.8804702758789062\n","precision class 1 = 0.6875\n","recall class 0 = 0.988994836807251\n","recall class 1 = 0.1527777761220932\n","AUC of ROC = 0.821674343088503\n","AUC of PRC = 0.45922594160604313\n","min(+P, Se) = 0.46017699115044247\n","f1_score = 0.24999999334989512\n","Epoch 10: Validation AUROC = 0.8217\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11 Batch 0: Train Loss = 0.2931\n","Epoch 11 Batch 50: Train Loss = 0.3192\n","Epoch 11: Train Loss = 0.3192\n","Epoch 11: Validation Loss = 0.3083\n","confusion matrix:\n","[[2689   37]\n"," [ 354   78]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8836674094200134\n","precision class 1 = 0.678260862827301\n","recall class 0 = 0.9864270091056824\n","recall class 1 = 0.1805555522441864\n","AUC of ROC = 0.8283861172250753\n","AUC of PRC = 0.474102532636191\n","min(+P, Se) = 0.46206896551724136\n","f1_score = 0.2851919612945434\n","Epoch 11: Validation AUROC = 0.8284\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12 Batch 0: Train Loss = 0.3185\n","Epoch 12 Batch 50: Train Loss = 0.3150\n","Epoch 12: Train Loss = 0.3140\n","Epoch 12: Validation Loss = 0.3124\n","confusion matrix:\n","[[2665   61]\n"," [ 319  113]]\n","accuracy = 0.8796706795692444\n","precision class 0 = 0.8930965065956116\n","precision class 1 = 0.6494252681732178\n","recall class 0 = 0.9776228666305542\n","recall class 1 = 0.26157405972480774\n","AUC of ROC = 0.8275352571940979\n","AUC of PRC = 0.48006537118765874\n","min(+P, Se) = 0.47126436781609193\n","f1_score = 0.3729372881823997\n","Epoch 12: Validation AUROC = 0.8275\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13 Batch 0: Train Loss = 0.3080\n","Epoch 13 Batch 50: Train Loss = 0.3123\n","Epoch 13: Train Loss = 0.3133\n","Epoch 13: Validation Loss = 0.3161\n","confusion matrix:\n","[[2599  127]\n"," [ 282  150]]\n","accuracy = 0.870487630367279\n","precision class 0 = 0.9021173119544983\n","precision class 1 = 0.5415162444114685\n","recall class 0 = 0.9534115791320801\n","recall class 1 = 0.3472222089767456\n","AUC of ROC = 0.8265519279367409\n","AUC of PRC = 0.47042746924560885\n","min(+P, Se) = 0.46952595936794583\n","f1_score = 0.4231311604994965\n","Epoch 13: Validation AUROC = 0.8266\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14 Batch 0: Train Loss = 0.2995\n","Epoch 14 Batch 50: Train Loss = 0.3137\n","Epoch 14: Train Loss = 0.3122\n","Epoch 14: Validation Loss = 0.3078\n","confusion matrix:\n","[[2689   37]\n"," [ 353   79]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.8839579224586487\n","precision class 1 = 0.681034505367279\n","recall class 0 = 0.9864270091056824\n","recall class 1 = 0.18287037312984467\n","AUC of ROC = 0.8289576030542648\n","AUC of PRC = 0.48310200994284264\n","min(+P, Se) = 0.4791666666666667\n","f1_score = 0.28832116836591765\n","Epoch 14: Validation AUROC = 0.8290\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15 Batch 0: Train Loss = 0.2493\n","Epoch 15 Batch 50: Train Loss = 0.3091\n","Epoch 15: Train Loss = 0.3119\n","Epoch 15: Validation Loss = 0.3089\n","confusion matrix:\n","[[2668   58]\n"," [ 327  105]]\n","accuracy = 0.8780874013900757\n","precision class 0 = 0.8908180594444275\n","precision class 1 = 0.6441717743873596\n","recall class 0 = 0.978723406791687\n","recall class 1 = 0.2430555522441864\n","AUC of ROC = 0.830486094127877\n","AUC of PRC = 0.4820943261997877\n","min(+P, Se) = 0.4791666666666667\n","f1_score = 0.3529411841213315\n","Epoch 15: Validation AUROC = 0.8305\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16 Batch 0: Train Loss = 0.3046\n","Epoch 16 Batch 50: Train Loss = 0.3097\n","Epoch 16: Train Loss = 0.3067\n","Epoch 16: Validation Loss = 0.3069\n","confusion matrix:\n","[[2702   24]\n"," [ 363   69]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.881566047668457\n","precision class 1 = 0.7419354915618896\n","recall class 0 = 0.9911959171295166\n","recall class 1 = 0.1597222238779068\n","AUC of ROC = 0.8307332001847776\n","AUC of PRC = 0.48798602236995203\n","min(+P, Se) = 0.48089887640449436\n","f1_score = 0.2628571499260105\n","Epoch 16: Validation AUROC = 0.8307\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17 Batch 0: Train Loss = 0.3122\n","Epoch 17 Batch 50: Train Loss = 0.3091\n","Epoch 17: Train Loss = 0.3053\n","Epoch 17: Validation Loss = 0.3200\n","confusion matrix:\n","[[2708   18]\n"," [ 376   56]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.878080427646637\n","precision class 1 = 0.7567567825317383\n","recall class 0 = 0.9933969378471375\n","recall class 1 = 0.12962962687015533\n","AUC of ROC = 0.8345128189451372\n","AUC of PRC = 0.49779194602327037\n","min(+P, Se) = 0.4861111111111111\n","f1_score = 0.2213438743186112\n","Epoch 17: Validation AUROC = 0.8345\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18 Batch 0: Train Loss = 0.3114\n","Epoch 18 Batch 50: Train Loss = 0.3052\n","Epoch 18: Train Loss = 0.3031\n","Epoch 18: Validation Loss = 0.3066\n","confusion matrix:\n","[[2709   17]\n"," [ 377   55]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8778353929519653\n","precision class 1 = 0.7638888955116272\n","recall class 0 = 0.9937637448310852\n","recall class 1 = 0.12731482088565826\n","AUC of ROC = 0.8368437678323959\n","AUC of PRC = 0.48869179419286585\n","min(+P, Se) = 0.4791666666666667\n","f1_score = 0.2182539810939712\n","Epoch 18: Validation AUROC = 0.8368\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19 Batch 0: Train Loss = 0.2744\n","Epoch 19 Batch 50: Train Loss = 0.3017\n","Epoch 19: Train Loss = 0.3016\n","Epoch 19: Validation Loss = 0.3044\n","confusion matrix:\n","[[2698   28]\n"," [ 363   69]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8814113140106201\n","precision class 1 = 0.7113401889801025\n","recall class 0 = 0.9897285103797913\n","recall class 1 = 0.1597222238779068\n","AUC of ROC = 0.8357033436591397\n","AUC of PRC = 0.5003934661375535\n","min(+P, Se) = 0.4818181818181818\n","f1_score = 0.26086957073139777\n","Epoch 19: Validation AUROC = 0.8357\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20 Batch 0: Train Loss = 0.3289\n","Epoch 20 Batch 50: Train Loss = 0.3028\n","Epoch 20: Train Loss = 0.3051\n","Epoch 20: Validation Loss = 0.3012\n","confusion matrix:\n","[[2687   39]\n"," [ 340   92]]\n","accuracy = 0.879987359046936\n","precision class 0 = 0.8876775503158569\n","precision class 1 = 0.7022900581359863\n","recall class 0 = 0.9856933355331421\n","recall class 1 = 0.21296297013759613\n","AUC of ROC = 0.8368556560963019\n","AUC of PRC = 0.4963114208522556\n","min(+P, Se) = 0.48842592592592593\n","f1_score = 0.3268206050644943\n","Epoch 20: Validation AUROC = 0.8369\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21 Batch 0: Train Loss = 0.2741\n","Epoch 21 Batch 50: Train Loss = 0.3039\n","Epoch 21: Train Loss = 0.3038\n","Epoch 21: Validation Loss = 0.3054\n","confusion matrix:\n","[[2706   20]\n"," [ 374   58]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8785714507102966\n","precision class 1 = 0.7435897588729858\n","recall class 0 = 0.9926632642745972\n","recall class 1 = 0.13425925374031067\n","AUC of ROC = 0.8367724382489606\n","AUC of PRC = 0.49291202197678274\n","min(+P, Se) = 0.46943231441048033\n","f1_score = 0.22745098090914276\n","Epoch 21: Validation AUROC = 0.8368\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22 Batch 0: Train Loss = 0.2972\n","Epoch 22 Batch 50: Train Loss = 0.2999\n","Epoch 22: Train Loss = 0.3021\n","Epoch 22: Validation Loss = 0.3060\n","confusion matrix:\n","[[2644   82]\n"," [ 305  127]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.8965750932693481\n","precision class 1 = 0.6076555252075195\n","recall class 0 = 0.9699193239212036\n","recall class 1 = 0.29398149251937866\n","AUC of ROC = 0.8343404391185021\n","AUC of PRC = 0.48865940779597866\n","min(+P, Se) = 0.4791666666666667\n","f1_score = 0.3962558651119238\n","Epoch 22: Validation AUROC = 0.8343\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23 Batch 0: Train Loss = 0.3593\n","Epoch 23 Batch 50: Train Loss = 0.2956\n","Epoch 23: Train Loss = 0.2981\n","Epoch 23: Validation Loss = 0.3015\n","confusion matrix:\n","[[2676   50]\n"," [ 327  105]]\n","accuracy = 0.8806206583976746\n","precision class 0 = 0.8911088705062866\n","precision class 1 = 0.6774193644523621\n","recall class 0 = 0.9816581010818481\n","recall class 1 = 0.2430555522441864\n","AUC of ROC = 0.8357491983913481\n","AUC of PRC = 0.4981289340115494\n","min(+P, Se) = 0.481981981981982\n","f1_score = 0.35775128701972947\n","Epoch 23: Validation AUROC = 0.8357\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24 Batch 0: Train Loss = 0.2981\n","Epoch 24 Batch 50: Train Loss = 0.2974\n","Epoch 24: Train Loss = 0.2968\n","Epoch 24: Validation Loss = 0.3029\n","confusion matrix:\n","[[2687   39]\n"," [ 345   87]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8862137198448181\n","precision class 1 = 0.6904761791229248\n","recall class 0 = 0.9856933355331421\n","recall class 1 = 0.2013888955116272\n","AUC of ROC = 0.8356150308415533\n","AUC of PRC = 0.49578657411330346\n","min(+P, Se) = 0.4791666666666667\n","f1_score = 0.31182796377049016\n","Epoch 24: Validation AUROC = 0.8356\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25 Batch 0: Train Loss = 0.3338\n","Epoch 25 Batch 50: Train Loss = 0.2965\n","Epoch 25: Train Loss = 0.2960\n","Epoch 25: Validation Loss = 0.2997\n","confusion matrix:\n","[[2689   37]\n"," [ 347   85]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8857048749923706\n","precision class 1 = 0.6967213153839111\n","recall class 0 = 0.9864270091056824\n","recall class 1 = 0.19675925374031067\n","AUC of ROC = 0.8397045936251732\n","AUC of PRC = 0.5007338599617337\n","min(+P, Se) = 0.4861111111111111\n","f1_score = 0.30685920967891855\n","Epoch 25: Validation AUROC = 0.8397\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26 Batch 0: Train Loss = 0.2959\n","Epoch 26 Batch 50: Train Loss = 0.2963\n","Epoch 26: Train Loss = 0.2969\n","Epoch 26: Validation Loss = 0.3052\n","confusion matrix:\n","[[2626  100]\n"," [ 293  139]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.8996231555938721\n","precision class 1 = 0.581589937210083\n","recall class 0 = 0.9633162021636963\n","recall class 1 = 0.32175925374031067\n","AUC of ROC = 0.8394099345126492\n","AUC of PRC = 0.49297214417061896\n","min(+P, Se) = 0.49191685912240185\n","f1_score = 0.4143070082486454\n","Epoch 26: Validation AUROC = 0.8394\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27 Batch 0: Train Loss = 0.3208\n","Epoch 27 Batch 50: Train Loss = 0.3022\n","Epoch 27: Train Loss = 0.3008\n","Epoch 27: Validation Loss = 0.2992\n","confusion matrix:\n","[[2690   36]\n"," [ 352   80]]\n","accuracy = 0.8771374225616455\n","precision class 0 = 0.884286642074585\n","precision class 1 = 0.6896551847457886\n","recall class 0 = 0.9867938160896301\n","recall class 1 = 0.18518517911434174\n","AUC of ROC = 0.8400289733974621\n","AUC of PRC = 0.49761892736622737\n","min(+P, Se) = 0.49195402298850577\n","f1_score = 0.29197079150625543\n","Epoch 27: Validation AUROC = 0.8400\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28 Batch 0: Train Loss = 0.2868\n","Epoch 28 Batch 50: Train Loss = 0.2943\n","Epoch 28: Train Loss = 0.2922\n","Epoch 28: Validation Loss = 0.3019\n","confusion matrix:\n","[[2690   36]\n"," [ 353   79]]\n","accuracy = 0.8768207430839539\n","precision class 0 = 0.8839960694313049\n","precision class 1 = 0.686956524848938\n","recall class 0 = 0.9867938160896301\n","recall class 1 = 0.18287037312984467\n","AUC of ROC = 0.8365822260264668\n","AUC of PRC = 0.5014148182419343\n","min(+P, Se) = 0.48299319727891155\n","f1_score = 0.2888482620230117\n","Epoch 28: Validation AUROC = 0.8366\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29 Batch 0: Train Loss = 0.2839\n","Epoch 29 Batch 50: Train Loss = 0.2942\n","Epoch 29: Train Loss = 0.2951\n","Epoch 29: Validation Loss = 0.3000\n","confusion matrix:\n","[[2695   31]\n"," [ 347   85]]\n","accuracy = 0.8803039789199829\n","precision class 0 = 0.8859302997589111\n","precision class 1 = 0.732758641242981\n","recall class 0 = 0.9886280298233032\n","recall class 1 = 0.19675925374031067\n","AUC of ROC = 0.8384198119616315\n","AUC of PRC = 0.5047898000166937\n","min(+P, Se) = 0.4954128440366973\n","f1_score = 0.31021898303087037\n","Epoch 29: Validation AUROC = 0.8384\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30 Batch 0: Train Loss = 0.2378\n","Epoch 30 Batch 50: Train Loss = 0.2947\n","Epoch 30: Train Loss = 0.2956\n","Epoch 30: Validation Loss = 0.3032\n","confusion matrix:\n","[[2678   48]\n"," [ 328  104]]\n","accuracy = 0.8809372782707214\n","precision class 0 = 0.8908848762512207\n","precision class 1 = 0.6842105388641357\n","recall class 0 = 0.9823917746543884\n","recall class 1 = 0.24074074625968933\n","AUC of ROC = 0.8321742276025108\n","AUC of PRC = 0.4929794452411057\n","min(+P, Se) = 0.4766146993318486\n","f1_score = 0.35616437982586796\n","Epoch 30: Validation AUROC = 0.8322\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31 Batch 0: Train Loss = 0.2953\n","Epoch 31 Batch 50: Train Loss = 0.2890\n","Epoch 31: Train Loss = 0.2934\n","Epoch 31: Validation Loss = 0.3010\n","confusion matrix:\n","[[2661   65]\n"," [ 318  114]]\n","accuracy = 0.8787207007408142\n","precision class 0 = 0.8932527899742126\n","precision class 1 = 0.6368715167045593\n","recall class 0 = 0.9761555194854736\n","recall class 1 = 0.2638888955116272\n","AUC of ROC = 0.838323856688677\n","AUC of PRC = 0.4927098989787465\n","min(+P, Se) = 0.49074074074074076\n","f1_score = 0.37315876418788496\n","Epoch 31: Validation AUROC = 0.8383\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32 Batch 0: Train Loss = 0.2627\n","Epoch 32 Batch 50: Train Loss = 0.2965\n","Epoch 32: Train Loss = 0.2950\n","Epoch 32: Validation Loss = 0.3109\n","confusion matrix:\n","[[2704   22]\n"," [ 372   60]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8790637254714966\n","precision class 1 = 0.7317073345184326\n","recall class 0 = 0.9919295907020569\n","recall class 1 = 0.1388888955116272\n","AUC of ROC = 0.8382066723730334\n","AUC of PRC = 0.505486829716202\n","min(+P, Se) = 0.4896551724137931\n","f1_score = 0.23346304526384845\n","Epoch 32: Validation AUROC = 0.8382\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33 Batch 0: Train Loss = 0.2353\n","Epoch 33 Batch 50: Train Loss = 0.2943\n","Epoch 33: Train Loss = 0.2947\n","Epoch 33: Validation Loss = 0.3005\n","confusion matrix:\n","[[2676   50]\n"," [ 332  100]]\n","accuracy = 0.8790373802185059\n","precision class 0 = 0.8896276354789734\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9816581010818481\n","recall class 1 = 0.23148147761821747\n","AUC of ROC = 0.8370416225102579\n","AUC of PRC = 0.49206959747954676\n","min(+P, Se) = 0.47685185185185186\n","f1_score = 0.34364260436498045\n","Epoch 33: Validation AUROC = 0.8370\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34 Batch 0: Train Loss = 0.3004\n","Epoch 34 Batch 50: Train Loss = 0.2928\n","Epoch 34: Train Loss = 0.2921\n","Epoch 34: Validation Loss = 0.3014\n","confusion matrix:\n","[[2685   41]\n"," [ 339   93]]\n","accuracy = 0.8796706795692444\n","precision class 0 = 0.8878968358039856\n","precision class 1 = 0.6940298676490784\n","recall class 0 = 0.9849596619606018\n","recall class 1 = 0.2152777761220932\n","AUC of ROC = 0.8366093992011086\n","AUC of PRC = 0.501978586757942\n","min(+P, Se) = 0.48842592592592593\n","f1_score = 0.328621902707725\n","Epoch 34: Validation AUROC = 0.8366\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35 Batch 0: Train Loss = 0.3215\n","Epoch 35 Batch 50: Train Loss = 0.2941\n","Epoch 35: Train Loss = 0.2945\n","Epoch 35: Validation Loss = 0.3008\n","confusion matrix:\n","[[2688   38]\n"," [ 342   90]]\n","accuracy = 0.8796706795692444\n","precision class 0 = 0.8871287107467651\n","precision class 1 = 0.703125\n","recall class 0 = 0.9860601425170898\n","recall class 1 = 0.2083333283662796\n","AUC of ROC = 0.8348210646449825\n","AUC of PRC = 0.5054418075077942\n","min(+P, Se) = 0.49537037037037035\n","f1_score = 0.3214285707717039\n","Epoch 35: Validation AUROC = 0.8348\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36 Batch 0: Train Loss = 0.2777\n","Epoch 36 Batch 50: Train Loss = 0.2954\n","Epoch 36: Train Loss = 0.2946\n","Epoch 36: Validation Loss = 0.3015\n","confusion matrix:\n","[[2666   60]\n"," [ 321  111]]\n","accuracy = 0.8793540000915527\n","precision class 0 = 0.8925343155860901\n","precision class 1 = 0.6491228342056274\n","recall class 0 = 0.9779897332191467\n","recall class 1 = 0.2569444477558136\n","AUC of ROC = 0.8362298239178283\n","AUC of PRC = 0.4932651175741877\n","min(+P, Se) = 0.47453703703703703\n","f1_score = 0.36815922386159255\n","Epoch 36: Validation AUROC = 0.8362\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37 Batch 0: Train Loss = 0.2273\n","Epoch 37 Batch 50: Train Loss = 0.2899\n","Epoch 37: Train Loss = 0.2922\n","Epoch 37: Validation Loss = 0.3006\n","confusion matrix:\n","[[2685   41]\n"," [ 338   94]]\n","accuracy = 0.879987359046936\n","precision class 0 = 0.8881905674934387\n","precision class 1 = 0.6962962746620178\n","recall class 0 = 0.9849596619606018\n","recall class 1 = 0.21759259700775146\n","AUC of ROC = 0.8370560582592863\n","AUC of PRC = 0.49935401218870196\n","min(+P, Se) = 0.5068807339449541\n","f1_score = 0.3315696675761215\n","Epoch 37: Validation AUROC = 0.8371\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38 Batch 0: Train Loss = 0.3676\n","Epoch 38 Batch 50: Train Loss = 0.2924\n","Epoch 38: Train Loss = 0.2934\n","Epoch 38: Validation Loss = 0.3025\n","confusion matrix:\n","[[2673   53]\n"," [ 323  109]]\n","accuracy = 0.8809372782707214\n","precision class 0 = 0.8921895623207092\n","precision class 1 = 0.6728395223617554\n","recall class 0 = 0.9805576205253601\n","recall class 1 = 0.25231480598449707\n","AUC of ROC = 0.8356863604249886\n","AUC of PRC = 0.4944609884828848\n","min(+P, Se) = 0.48847926267281105\n","f1_score = 0.36700336007047263\n","Epoch 38: Validation AUROC = 0.8357\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39 Batch 0: Train Loss = 0.3469\n","Epoch 39 Batch 50: Train Loss = 0.2907\n","Epoch 39: Train Loss = 0.2896\n","Epoch 39: Validation Loss = 0.3024\n","confusion matrix:\n","[[2677   49]\n"," [ 332  100]]\n","accuracy = 0.8793540000915527\n","precision class 0 = 0.889664351940155\n","precision class 1 = 0.6711409687995911\n","recall class 0 = 0.9820249676704407\n","recall class 1 = 0.23148147761821747\n","AUC of ROC = 0.833432685253118\n","AUC of PRC = 0.49388872671237005\n","min(+P, Se) = 0.484304932735426\n","f1_score = 0.34423407306047793\n","Epoch 39: Validation AUROC = 0.8334\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40 Batch 0: Train Loss = 0.2961\n","Epoch 40 Batch 50: Train Loss = 0.2908\n","Epoch 40: Train Loss = 0.2893\n","Epoch 40: Validation Loss = 0.3056\n","confusion matrix:\n","[[2686   40]\n"," [ 336   96]]\n","accuracy = 0.8809372782707214\n","precision class 0 = 0.8888153433799744\n","precision class 1 = 0.7058823704719543\n","recall class 0 = 0.9853264689445496\n","recall class 1 = 0.2222222238779068\n","AUC of ROC = 0.8318855126219395\n","AUC of PRC = 0.4982024917551075\n","min(+P, Se) = 0.4896551724137931\n","f1_score = 0.3380281783668467\n","Epoch 40: Validation AUROC = 0.8319\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41 Batch 0: Train Loss = 0.3180\n","Epoch 41 Batch 50: Train Loss = 0.2898\n","Epoch 41: Train Loss = 0.2907\n","Epoch 41: Validation Loss = 0.3036\n","confusion matrix:\n","[[2695   31]\n"," [ 347   85]]\n","accuracy = 0.8803039789199829\n","precision class 0 = 0.8859302997589111\n","precision class 1 = 0.732758641242981\n","recall class 0 = 0.9886280298233032\n","recall class 1 = 0.19675925374031067\n","AUC of ROC = 0.835590405152034\n","AUC of PRC = 0.5037490146894815\n","min(+P, Se) = 0.4851258581235698\n","f1_score = 0.31021898303087037\n","Epoch 41: Validation AUROC = 0.8356\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42 Batch 0: Train Loss = 0.2429\n","Epoch 42 Batch 50: Train Loss = 0.2915\n","Epoch 42: Train Loss = 0.2916\n","Epoch 42: Validation Loss = 0.3011\n","confusion matrix:\n","[[2688   38]\n"," [ 352   80]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.8842105269432068\n","precision class 1 = 0.6779661178588867\n","recall class 0 = 0.9860601425170898\n","recall class 1 = 0.18518517911434174\n","AUC of ROC = 0.8380156109888318\n","AUC of PRC = 0.4965666052095689\n","min(+P, Se) = 0.5011547344110855\n","f1_score = 0.29090907988430065\n","Epoch 42: Validation AUROC = 0.8380\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43 Batch 0: Train Loss = 0.3359\n","Epoch 43 Batch 50: Train Loss = 0.2951\n","Epoch 43: Train Loss = 0.2946\n","Epoch 43: Validation Loss = 0.3033\n","confusion matrix:\n","[[2697   29]\n"," [ 365   67]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8807968497276306\n","precision class 1 = 0.6979166865348816\n","recall class 0 = 0.9893617033958435\n","recall class 1 = 0.15509259700775146\n","AUC of ROC = 0.8350010869269857\n","AUC of PRC = 0.5001454959241081\n","min(+P, Se) = 0.4771689497716895\n","f1_score = 0.2537878860126842\n","Epoch 43: Validation AUROC = 0.8350\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44 Batch 0: Train Loss = 0.3407\n","Epoch 44 Batch 50: Train Loss = 0.2905\n","Epoch 44: Train Loss = 0.2897\n","Epoch 44: Validation Loss = 0.3005\n","confusion matrix:\n","[[2665   61]\n"," [ 312  120]]\n","accuracy = 0.8818872570991516\n","precision class 0 = 0.8951964974403381\n","precision class 1 = 0.6629834175109863\n","recall class 0 = 0.9776228666305542\n","recall class 1 = 0.2777777910232544\n","AUC of ROC = 0.8359385614521344\n","AUC of PRC = 0.5020220640295507\n","min(+P, Se) = 0.4942263279445728\n","f1_score = 0.3915171406529075\n","Epoch 44: Validation AUROC = 0.8359\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45 Batch 0: Train Loss = 0.2796\n","Epoch 45 Batch 50: Train Loss = 0.2893\n","Epoch 45: Train Loss = 0.2862\n","Epoch 45: Validation Loss = 0.3025\n","confusion matrix:\n","[[2682   44]\n"," [ 325  107]]\n","accuracy = 0.8831539154052734\n","precision class 0 = 0.8919188380241394\n","precision class 1 = 0.7086092829704285\n","recall class 0 = 0.983859121799469\n","recall class 1 = 0.24768517911434174\n","AUC of ROC = 0.8344380927148718\n","AUC of PRC = 0.5030286913274218\n","min(+P, Se) = 0.4930555555555556\n","f1_score = 0.3670668845182464\n","Epoch 45: Validation AUROC = 0.8344\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46 Batch 0: Train Loss = 0.2815\n","Epoch 46 Batch 50: Train Loss = 0.2862\n","Epoch 46: Train Loss = 0.2858\n","Epoch 46: Validation Loss = 0.3003\n","confusion matrix:\n","[[2680   46]\n"," [ 331  101]]\n","accuracy = 0.8806206583976746\n","precision class 0 = 0.8900697231292725\n","precision class 1 = 0.6870748400688171\n","recall class 0 = 0.9831254482269287\n","recall class 1 = 0.23379629850387573\n","AUC of ROC = 0.8363945612890953\n","AUC of PRC = 0.5013533267090309\n","min(+P, Se) = 0.4791666666666667\n","f1_score = 0.3488773785487716\n","Epoch 46: Validation AUROC = 0.8364\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47 Batch 0: Train Loss = 0.2428\n","Epoch 47 Batch 50: Train Loss = 0.2916\n","Epoch 47: Train Loss = 0.2895\n","Epoch 47: Validation Loss = 0.3031\n","confusion matrix:\n","[[2696   30]\n"," [ 346   86]]\n","accuracy = 0.8809372782707214\n","precision class 0 = 0.8862590193748474\n","precision class 1 = 0.7413793206214905\n","recall class 0 = 0.988994836807251\n","recall class 1 = 0.19907407462596893\n","AUC of ROC = 0.8363656897910382\n","AUC of PRC = 0.5064641718265773\n","min(+P, Se) = 0.49774774774774777\n","f1_score = 0.3138686097724481\n","Epoch 47: Validation AUROC = 0.8364\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48 Batch 0: Train Loss = 0.2900\n","Epoch 48 Batch 50: Train Loss = 0.2953\n","Epoch 48: Train Loss = 0.2932\n","Epoch 48: Validation Loss = 0.3000\n","confusion matrix:\n","[[2688   38]\n"," [ 328  104]]\n","accuracy = 0.8841038346290588\n","precision class 0 = 0.8912466764450073\n","precision class 1 = 0.7323943376541138\n","recall class 0 = 0.9860601425170898\n","recall class 1 = 0.24074074625968933\n","AUC of ROC = 0.8383849963316216\n","AUC of PRC = 0.5094497180486866\n","min(+P, Se) = 0.48842592592592593\n","f1_score = 0.3623693296399865\n","Epoch 48: Validation AUROC = 0.8384\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49 Batch 0: Train Loss = 0.2509\n","Epoch 49 Batch 50: Train Loss = 0.2876\n","Epoch 49: Train Loss = 0.2882\n","Epoch 49: Validation Loss = 0.3093\n","confusion matrix:\n","[[2671   55]\n"," [ 337   95]]\n","accuracy = 0.8758708238601685\n","precision class 0 = 0.8879654407501221\n","precision class 1 = 0.6333333253860474\n","recall class 0 = 0.9798239469528198\n","recall class 1 = 0.21990740299224854\n","AUC of ROC = 0.8289108991603489\n","AUC of PRC = 0.4757388987788191\n","min(+P, Se) = 0.48089887640449436\n","f1_score = 0.32646047517867915\n","Epoch 49: Validation AUROC = 0.8289\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50 Batch 0: Train Loss = 0.3609\n","Epoch 50 Batch 50: Train Loss = 0.2871\n","Epoch 50: Train Loss = 0.2875\n","Epoch 50: Validation Loss = 0.3004\n","confusion matrix:\n","[[2675   51]\n"," [ 322  110]]\n","accuracy = 0.8818872570991516\n","precision class 0 = 0.8925592303276062\n","precision class 1 = 0.6832298040390015\n","recall class 0 = 0.9812912940979004\n","recall class 1 = 0.25462964177131653\n","AUC of ROC = 0.8372853319203282\n","AUC of PRC = 0.5021213738944527\n","min(+P, Se) = 0.48847926267281105\n","f1_score = 0.3709949642355663\n","Epoch 50: Validation AUROC = 0.8373\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51 Batch 0: Train Loss = 0.2063\n","Epoch 51 Batch 50: Train Loss = 0.2837\n","Epoch 51: Train Loss = 0.2833\n","Epoch 51: Validation Loss = 0.3029\n","confusion matrix:\n","[[2695   31]\n"," [ 351   81]]\n","accuracy = 0.8790373802185059\n","precision class 0 = 0.8847669363021851\n","precision class 1 = 0.7232142686843872\n","recall class 0 = 0.9886280298233032\n","recall class 1 = 0.1875\n","AUC of ROC = 0.8404476101192901\n","AUC of PRC = 0.5070527766950338\n","min(+P, Se) = 0.4874715261958998\n","f1_score = 0.29779411620334767\n","Epoch 51: Validation AUROC = 0.8404\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52 Batch 0: Train Loss = 0.3216\n","Epoch 52 Batch 50: Train Loss = 0.2875\n","Epoch 52: Train Loss = 0.2894\n","Epoch 52: Validation Loss = 0.3010\n","confusion matrix:\n","[[2665   61]\n"," [ 317  115]]\n","accuracy = 0.8803039789199829\n","precision class 0 = 0.8936955332756042\n","precision class 1 = 0.6534090638160706\n","recall class 0 = 0.9776228666305542\n","recall class 1 = 0.26620370149612427\n","AUC of ROC = 0.8363911646422653\n","AUC of PRC = 0.5111639750317256\n","min(+P, Se) = 0.5\n","f1_score = 0.37828946691470783\n","Epoch 52: Validation AUROC = 0.8364\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53 Batch 0: Train Loss = 0.2949\n","Epoch 53 Batch 50: Train Loss = 0.2905\n","Epoch 53: Train Loss = 0.2879\n","Epoch 53: Validation Loss = 0.3018\n","confusion matrix:\n","[[2657   69]\n"," [ 312  120]]\n","accuracy = 0.8793540000915527\n","precision class 0 = 0.8949140906333923\n","precision class 1 = 0.6349206566810608\n","recall class 0 = 0.9746881723403931\n","recall class 1 = 0.2777777910232544\n","AUC of ROC = 0.8357152319230456\n","AUC of PRC = 0.4934509676342572\n","min(+P, Se) = 0.4837962962962963\n","f1_score = 0.38647344680274137\n","Epoch 53: Validation AUROC = 0.8357\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54 Batch 0: Train Loss = 0.3207\n","Epoch 54 Batch 50: Train Loss = 0.2869\n","Epoch 54: Train Loss = 0.2859\n","Epoch 54: Validation Loss = 0.3019\n","confusion matrix:\n","[[2674   52]\n"," [ 338   94]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.8877822160720825\n","precision class 1 = 0.6438356041908264\n","recall class 0 = 0.9809244275093079\n","recall class 1 = 0.21759259700775146\n","AUC of ROC = 0.835869779353822\n","AUC of PRC = 0.4942500959994705\n","min(+P, Se) = 0.4837962962962963\n","f1_score = 0.32525951894078287\n","Epoch 54: Validation AUROC = 0.8359\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55 Batch 0: Train Loss = 0.2560\n","Epoch 55 Batch 50: Train Loss = 0.2825\n","Epoch 55: Train Loss = 0.2843\n","Epoch 55: Validation Loss = 0.3041\n","confusion matrix:\n","[[2642   84]\n"," [ 295  137]]\n","accuracy = 0.879987359046936\n","precision class 0 = 0.89955735206604\n","precision class 1 = 0.6199095249176025\n","recall class 0 = 0.9691855907440186\n","recall class 1 = 0.31712964177131653\n","AUC of ROC = 0.8338776459878807\n","AUC of PRC = 0.4897269199477281\n","min(+P, Se) = 0.49074074074074076\n","f1_score = 0.41960186683544776\n","Epoch 55: Validation AUROC = 0.8339\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56 Batch 0: Train Loss = 0.3488\n","Epoch 56 Batch 50: Train Loss = 0.2880\n","Epoch 56: Train Loss = 0.2869\n","Epoch 56: Validation Loss = 0.3030\n","confusion matrix:\n","[[2673   53]\n"," [ 327  105]]\n","accuracy = 0.8796706795692444\n","precision class 0 = 0.890999972820282\n","precision class 1 = 0.6645569801330566\n","recall class 0 = 0.9805576205253601\n","recall class 1 = 0.2430555522441864\n","AUC of ROC = 0.8351029863318933\n","AUC of PRC = 0.49185023221523916\n","min(+P, Se) = 0.4861111111111111\n","f1_score = 0.35593219074905735\n","Epoch 56: Validation AUROC = 0.8351\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57 Batch 0: Train Loss = 0.2762\n","Epoch 57 Batch 50: Train Loss = 0.2873\n","Epoch 57: Train Loss = 0.2853\n","Epoch 57: Validation Loss = 0.3060\n","confusion matrix:\n","[[2687   39]\n"," [ 340   92]]\n","accuracy = 0.879987359046936\n","precision class 0 = 0.8876775503158569\n","precision class 1 = 0.7022900581359863\n","recall class 0 = 0.9856933355331421\n","recall class 1 = 0.21296297013759613\n","AUC of ROC = 0.8349017350072009\n","AUC of PRC = 0.4955207337739419\n","min(+P, Se) = 0.48394495412844035\n","f1_score = 0.3268206050644943\n","Epoch 57: Validation AUROC = 0.8349\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58 Batch 0: Train Loss = 0.3226\n","Epoch 58 Batch 50: Train Loss = 0.2889\n","Epoch 58: Train Loss = 0.2878\n","Epoch 58: Validation Loss = 0.3062\n","confusion matrix:\n","[[2685   41]\n"," [ 347   85]]\n","accuracy = 0.8771374225616455\n","precision class 0 = 0.8855540752410889\n","precision class 1 = 0.6746031641960144\n","recall class 0 = 0.9849596619606018\n","recall class 1 = 0.19675925374031067\n","AUC of ROC = 0.8341909866579711\n","AUC of PRC = 0.4867730750677451\n","min(+P, Se) = 0.4699074074074074\n","f1_score = 0.30465948011078814\n","Epoch 58: Validation AUROC = 0.8342\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59 Batch 0: Train Loss = 0.2835\n","Epoch 59 Batch 50: Train Loss = 0.2863\n","Epoch 59: Train Loss = 0.2840\n","Epoch 59: Validation Loss = 0.3028\n","confusion matrix:\n","[[2683   43]\n"," [ 333   99]]\n","accuracy = 0.8809372782707214\n","precision class 0 = 0.8895888328552246\n","precision class 1 = 0.6971830725669861\n","recall class 0 = 0.9842259883880615\n","recall class 1 = 0.2291666716337204\n","AUC of ROC = 0.8364692875193608\n","AUC of PRC = 0.49800366532920454\n","min(+P, Se) = 0.4780600461893764\n","f1_score = 0.3449477320843719\n","Epoch 59: Validation AUROC = 0.8365\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60 Batch 0: Train Loss = 0.2371\n","Epoch 60 Batch 50: Train Loss = 0.2893\n","Epoch 60: Train Loss = 0.2878\n","Epoch 60: Validation Loss = 0.3009\n","confusion matrix:\n","[[2657   69]\n"," [ 309  123]]\n","accuracy = 0.8803039789199829\n","precision class 0 = 0.8958193063735962\n","precision class 1 = 0.640625\n","recall class 0 = 0.9746881723403931\n","recall class 1 = 0.2847222089767456\n","AUC of ROC = 0.8355054889812776\n","AUC of PRC = 0.49474203194060795\n","min(+P, Se) = 0.48623853211009177\n","f1_score = 0.39423075653392164\n","Epoch 60: Validation AUROC = 0.8355\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61 Batch 0: Train Loss = 0.2762\n","Epoch 61 Batch 50: Train Loss = 0.2812\n","Epoch 61: Train Loss = 0.2812\n","Epoch 61: Validation Loss = 0.3010\n","confusion matrix:\n","[[2668   58]\n"," [ 320  112]]\n","accuracy = 0.8803039789199829\n","precision class 0 = 0.8929049372673035\n","precision class 1 = 0.658823549747467\n","recall class 0 = 0.978723406791687\n","recall class 1 = 0.25925925374031067\n","AUC of ROC = 0.8361712317600065\n","AUC of PRC = 0.49682128727756164\n","min(+P, Se) = 0.4838709677419355\n","f1_score = 0.37209300873638845\n","Epoch 61: Validation AUROC = 0.8362\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62 Batch 0: Train Loss = 0.2728\n","Epoch 62 Batch 50: Train Loss = 0.2811\n","Epoch 62: Train Loss = 0.2836\n","Epoch 62: Validation Loss = 0.3011\n","confusion matrix:\n","[[2626  100]\n"," [ 290  142]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.9005486965179443\n","precision class 1 = 0.586776852607727\n","recall class 0 = 0.9633162021636963\n","recall class 1 = 0.32870370149612427\n","AUC of ROC = 0.8386253090948617\n","AUC of PRC = 0.4957593543030901\n","min(+P, Se) = 0.4908256880733945\n","f1_score = 0.42136498157125457\n","Epoch 62: Validation AUROC = 0.8386\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63 Batch 0: Train Loss = 0.2751\n","Epoch 63 Batch 50: Train Loss = 0.2799\n","Epoch 63: Train Loss = 0.2825\n","Epoch 63: Validation Loss = 0.3016\n","confusion matrix:\n","[[2659   67]\n"," [ 311  121]]\n","accuracy = 0.8803039789199829\n","precision class 0 = 0.8952862024307251\n","precision class 1 = 0.6436170339584351\n","recall class 0 = 0.9754218459129333\n","recall class 1 = 0.28009259700775146\n","AUC of ROC = 0.8383671639357626\n","AUC of PRC = 0.49463551717324017\n","min(+P, Se) = 0.4853932584269663\n","f1_score = 0.390322587264316\n","Epoch 63: Validation AUROC = 0.8384\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64 Batch 0: Train Loss = 0.3057\n","Epoch 64 Batch 50: Train Loss = 0.2834\n","Epoch 64: Train Loss = 0.2827\n","Epoch 64: Validation Loss = 0.3130\n","confusion matrix:\n","[[2704   22]\n"," [ 378   54]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.8773523569107056\n","precision class 1 = 0.7105262875556946\n","recall class 0 = 0.9919295907020569\n","recall class 1 = 0.125\n","AUC of ROC = 0.8368794326241135\n","AUC of PRC = 0.48984237500753003\n","min(+P, Se) = 0.4861111111111111\n","f1_score = 0.21259842393299094\n","Epoch 64: Validation AUROC = 0.8369\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65 Batch 0: Train Loss = 0.2556\n","Epoch 65 Batch 50: Train Loss = 0.2822\n","Epoch 65: Train Loss = 0.2785\n","Epoch 65: Validation Loss = 0.3021\n","confusion matrix:\n","[[2676   50]\n"," [ 330  102]]\n","accuracy = 0.8796706795692444\n","precision class 0 = 0.8902195692062378\n","precision class 1 = 0.6710526347160339\n","recall class 0 = 0.9816581010818481\n","recall class 1 = 0.2361111044883728\n","AUC of ROC = 0.8421773525175947\n","AUC of PRC = 0.5094179798771143\n","min(+P, Se) = 0.4976958525345622\n","f1_score = 0.34931506167032583\n","Epoch 65: Validation AUROC = 0.8422\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66 Batch 0: Train Loss = 0.2736\n","Epoch 66 Batch 50: Train Loss = 0.2822\n","Epoch 66: Train Loss = 0.2836\n","Epoch 66: Validation Loss = 0.2993\n","confusion matrix:\n","[[2674   52]\n"," [ 331  101]]\n","accuracy = 0.8787207007408142\n","precision class 0 = 0.8898502588272095\n","precision class 1 = 0.6601307392120361\n","recall class 0 = 0.9809244275093079\n","recall class 1 = 0.23379629850387573\n","AUC of ROC = 0.8404416659873375\n","AUC of PRC = 0.5017635061699136\n","min(+P, Se) = 0.49777777777777776\n","f1_score = 0.345299150478205\n","Epoch 66: Validation AUROC = 0.8404\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67 Batch 0: Train Loss = 0.2838\n","Epoch 67 Batch 50: Train Loss = 0.2768\n","Epoch 67: Train Loss = 0.2791\n","Epoch 67: Validation Loss = 0.2999\n","confusion matrix:\n","[[2652   74]\n"," [ 300  132]]\n","accuracy = 0.8815706372261047\n","precision class 0 = 0.8983739614486694\n","precision class 1 = 0.6407766938209534\n","recall class 0 = 0.9728540182113647\n","recall class 1 = 0.3055555522441864\n","AUC of ROC = 0.8362671870329611\n","AUC of PRC = 0.49998026759838293\n","min(+P, Se) = 0.49195402298850577\n","f1_score = 0.4137931123572556\n","Epoch 67: Validation AUROC = 0.8363\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68 Batch 0: Train Loss = 0.2785\n","Epoch 68 Batch 50: Train Loss = 0.2787\n","Epoch 68: Train Loss = 0.2797\n","Epoch 68: Validation Loss = 0.3005\n","confusion matrix:\n","[[2642   84]\n"," [ 302  130]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.8974184989929199\n","precision class 1 = 0.6074766516685486\n","recall class 0 = 0.9691855907440186\n","recall class 1 = 0.30092594027519226\n","AUC of ROC = 0.8363189858971224\n","AUC of PRC = 0.4966137165077843\n","min(+P, Se) = 0.4908256880733945\n","f1_score = 0.4024768097695537\n","Epoch 68: Validation AUROC = 0.8363\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69 Batch 0: Train Loss = 0.3043\n","Epoch 69 Batch 50: Train Loss = 0.2787\n","Epoch 69: Train Loss = 0.2807\n","Epoch 69: Validation Loss = 0.3028\n","confusion matrix:\n","[[2610  116]\n"," [ 279  153]]\n","accuracy = 0.8749208450317383\n","precision class 0 = 0.9034267663955688\n","precision class 1 = 0.5687732100486755\n","recall class 0 = 0.957446813583374\n","recall class 1 = 0.3541666567325592\n","AUC of ROC = 0.8377345384636287\n","AUC of PRC = 0.4956408597922487\n","min(+P, Se) = 0.4922737306843267\n","f1_score = 0.4365192294485406\n","Epoch 69: Validation AUROC = 0.8377\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70 Batch 0: Train Loss = 0.2902\n","Epoch 70 Batch 50: Train Loss = 0.2804\n","Epoch 70: Train Loss = 0.2821\n","Epoch 70: Validation Loss = 0.3072\n","confusion matrix:\n","[[2660   66]\n"," [ 314  118]]\n","accuracy = 0.8796706795692444\n","precision class 0 = 0.8944182991981506\n","precision class 1 = 0.6413043737411499\n","recall class 0 = 0.9757887125015259\n","recall class 1 = 0.27314814925193787\n","AUC of ROC = 0.8264381402679275\n","AUC of PRC = 0.4864548631080959\n","min(+P, Se) = 0.47453703703703703\n","f1_score = 0.38311687634111524\n","Epoch 70: Validation AUROC = 0.8264\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71 Batch 0: Train Loss = 0.3181\n","Epoch 71 Batch 50: Train Loss = 0.2800\n","Epoch 71: Train Loss = 0.2817\n","Epoch 71: Validation Loss = 0.3046\n","confusion matrix:\n","[[2634   92]\n"," [ 302  130]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8971389532089233\n","precision class 1 = 0.5855855941772461\n","recall class 0 = 0.9662508964538574\n","recall class 1 = 0.30092594027519226\n","AUC of ROC = 0.832728730197549\n","AUC of PRC = 0.48757087776384045\n","min(+P, Se) = 0.48847926267281105\n","f1_score = 0.39755351795671423\n","Epoch 71: Validation AUROC = 0.8327\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72 Batch 0: Train Loss = 0.3135\n","Epoch 72 Batch 50: Train Loss = 0.2798\n","Epoch 72: Train Loss = 0.2784\n","Epoch 72: Validation Loss = 0.3075\n","confusion matrix:\n","[[2660   66]\n"," [ 321  111]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.8923180103302002\n","precision class 1 = 0.6271186470985413\n","recall class 0 = 0.9757887125015259\n","recall class 1 = 0.2569444477558136\n","AUC of ROC = 0.8310388983995001\n","AUC of PRC = 0.4924642504239296\n","min(+P, Se) = 0.4861111111111111\n","f1_score = 0.36453201126035817\n","Epoch 72: Validation AUROC = 0.8310\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73 Batch 0: Train Loss = 0.3886\n","Epoch 73 Batch 50: Train Loss = 0.2800\n","Epoch 73: Train Loss = 0.2805\n","Epoch 73: Validation Loss = 0.3034\n","confusion matrix:\n","[[2674   52]\n"," [ 328  104]]\n","accuracy = 0.8796706795692444\n","precision class 0 = 0.8907395005226135\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9809244275093079\n","recall class 1 = 0.24074074625968933\n","AUC of ROC = 0.832552104562376\n","AUC of PRC = 0.4994531737732385\n","min(+P, Se) = 0.48623853211009177\n","f1_score = 0.3537415169716282\n","Epoch 73: Validation AUROC = 0.8326\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74 Batch 0: Train Loss = 0.2465\n","Epoch 74 Batch 50: Train Loss = 0.2790\n","Epoch 74: Train Loss = 0.2788\n","Epoch 74: Validation Loss = 0.3088\n","confusion matrix:\n","[[2683   43]\n"," [ 340   92]]\n","accuracy = 0.8787207007408142\n","precision class 0 = 0.8875289559364319\n","precision class 1 = 0.6814814805984497\n","recall class 0 = 0.9842259883880615\n","recall class 1 = 0.21296297013759613\n","AUC of ROC = 0.8320349650824707\n","AUC of PRC = 0.49572939655638987\n","min(+P, Se) = 0.48842592592592593\n","f1_score = 0.32451499400495665\n","Epoch 74: Validation AUROC = 0.8320\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75 Batch 0: Train Loss = 0.2370\n","Epoch 75 Batch 50: Train Loss = 0.2737\n","Epoch 75: Train Loss = 0.2757\n","Epoch 75: Validation Loss = 0.3084\n","confusion matrix:\n","[[2682   44]\n"," [ 354   78]]\n","accuracy = 0.8739708662033081\n","precision class 0 = 0.8833991885185242\n","precision class 1 = 0.6393442749977112\n","recall class 0 = 0.983859121799469\n","recall class 1 = 0.1805555522441864\n","AUC of ROC = 0.8317029428548136\n","AUC of PRC = 0.4892573801406286\n","min(+P, Se) = 0.49884526558891457\n","f1_score = 0.2815884550938145\n","Epoch 75: Validation AUROC = 0.8317\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76 Batch 0: Train Loss = 0.2683\n","Epoch 76 Batch 50: Train Loss = 0.2758\n","Epoch 76: Train Loss = 0.2773\n","Epoch 76: Validation Loss = 0.3057\n","confusion matrix:\n","[[2586  140]\n"," [ 267  165]]\n","accuracy = 0.8711209893226624\n","precision class 0 = 0.9064143300056458\n","precision class 1 = 0.5409836173057556\n","recall class 0 = 0.9486426711082458\n","recall class 1 = 0.3819444477558136\n","AUC of ROC = 0.8380198567973695\n","AUC of PRC = 0.4976518837243141\n","min(+P, Se) = 0.4930555555555556\n","f1_score = 0.4477611855282426\n","Epoch 76: Validation AUROC = 0.8380\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77 Batch 0: Train Loss = 0.2918\n","Epoch 77 Batch 50: Train Loss = 0.2754\n","Epoch 77: Train Loss = 0.2758\n","Epoch 77: Validation Loss = 0.3066\n","confusion matrix:\n","[[2658   68]\n"," [ 331  101]]\n","accuracy = 0.8736541867256165\n","precision class 0 = 0.8892606496810913\n","precision class 1 = 0.5976331233978271\n","recall class 0 = 0.9750550389289856\n","recall class 1 = 0.23379629850387573\n","AUC of ROC = 0.8327091994782752\n","AUC of PRC = 0.4877891805632018\n","min(+P, Se) = 0.47874720357941836\n","f1_score = 0.33610648945796184\n","Epoch 77: Validation AUROC = 0.8327\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78 Batch 0: Train Loss = 0.2613\n","Epoch 78 Batch 50: Train Loss = 0.2778\n","Epoch 78: Train Loss = 0.2776\n","Epoch 78: Validation Loss = 0.3033\n","confusion matrix:\n","[[2649   77]\n"," [ 309  123]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.8955374956130981\n","precision class 1 = 0.6150000095367432\n","recall class 0 = 0.9717534780502319\n","recall class 1 = 0.2847222089767456\n","AUC of ROC = 0.8329554563734681\n","AUC of PRC = 0.4845288477828924\n","min(+P, Se) = 0.4930875576036866\n","f1_score = 0.3892404958617701\n","Epoch 78: Validation AUROC = 0.8330\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79 Batch 0: Train Loss = 0.2314\n","Epoch 79 Batch 50: Train Loss = 0.2784\n","Epoch 79: Train Loss = 0.2796\n","Epoch 79: Validation Loss = 0.3040\n","confusion matrix:\n","[[2671   55]\n"," [ 332  100]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.8894438743591309\n","precision class 1 = 0.6451612710952759\n","recall class 0 = 0.9798239469528198\n","recall class 1 = 0.23148147761821747\n","AUC of ROC = 0.8358196788130758\n","AUC of PRC = 0.49091500518549064\n","min(+P, Se) = 0.4837962962962963\n","f1_score = 0.34071548989784034\n","Epoch 79: Validation AUROC = 0.8358\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80 Batch 0: Train Loss = 0.2376\n","Epoch 80 Batch 50: Train Loss = 0.2774\n","Epoch 80: Train Loss = 0.2780\n","Epoch 80: Validation Loss = 0.3062\n","confusion matrix:\n","[[2653   73]\n"," [ 311  121]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8950742483139038\n","precision class 1 = 0.623711347579956\n","recall class 0 = 0.9732208251953125\n","recall class 1 = 0.28009259700775146\n","AUC of ROC = 0.8291877258770142\n","AUC of PRC = 0.4842898033402586\n","min(+P, Se) = 0.4837962962962963\n","f1_score = 0.3865814752702071\n","Epoch 80: Validation AUROC = 0.8292\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81 Batch 0: Train Loss = 0.2785\n","Epoch 81 Batch 50: Train Loss = 0.2728\n","Epoch 81: Train Loss = 0.2746\n","Epoch 81: Validation Loss = 0.3057\n","confusion matrix:\n","[[2652   74]\n"," [ 309  123]]\n","accuracy = 0.8787207007408142\n","precision class 0 = 0.8956433534622192\n","precision class 1 = 0.624365508556366\n","recall class 0 = 0.9728540182113647\n","recall class 1 = 0.2847222089767456\n","AUC of ROC = 0.8297838373957229\n","AUC of PRC = 0.49047775358826234\n","min(+P, Se) = 0.4850574712643678\n","f1_score = 0.3910969720005765\n","Epoch 81: Validation AUROC = 0.8298\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82 Batch 0: Train Loss = 0.2679\n","Epoch 82 Batch 50: Train Loss = 0.2801\n","Epoch 82: Train Loss = 0.2785\n","Epoch 82: Validation Loss = 0.3277\n","confusion matrix:\n","[[2699   27]\n"," [ 369   63]]\n","accuracy = 0.8746041655540466\n","precision class 0 = 0.879726231098175\n","precision class 1 = 0.699999988079071\n","recall class 0 = 0.9900953769683838\n","recall class 1 = 0.1458333283662796\n","AUC of ROC = 0.832804305589522\n","AUC of PRC = 0.4965548188872883\n","min(+P, Se) = 0.48853211009174313\n","f1_score = 0.2413793070846449\n","Epoch 82: Validation AUROC = 0.8328\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83 Batch 0: Train Loss = 0.3950\n","Epoch 83 Batch 50: Train Loss = 0.2844\n","Epoch 83: Train Loss = 0.2835\n","Epoch 83: Validation Loss = 0.3083\n","confusion matrix:\n","[[2679   47]\n"," [ 339   93]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.8876739740371704\n","precision class 1 = 0.6642857193946838\n","recall class 0 = 0.982758641242981\n","recall class 1 = 0.2152777761220932\n","AUC of ROC = 0.8313114793076276\n","AUC of PRC = 0.4883889195166027\n","min(+P, Se) = 0.5069444444444444\n","f1_score = 0.32517481838918233\n","Epoch 83: Validation AUROC = 0.8313\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84 Batch 0: Train Loss = 0.2471\n","Epoch 84 Batch 50: Train Loss = 0.2788\n","Epoch 84: Train Loss = 0.2778\n","Epoch 84: Validation Loss = 0.3057\n","confusion matrix:\n","[[2630   96]\n"," [ 309  123]]\n","accuracy = 0.8717542886734009\n","precision class 0 = 0.894862174987793\n","precision class 1 = 0.5616438388824463\n","recall class 0 = 0.9647835493087769\n","recall class 1 = 0.2847222089767456\n","AUC of ROC = 0.8323559482079291\n","AUC of PRC = 0.48751623343535383\n","min(+P, Se) = 0.5069444444444444\n","f1_score = 0.3778801734055235\n","Epoch 84: Validation AUROC = 0.8324\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85 Batch 0: Train Loss = 0.2381\n","Epoch 85 Batch 50: Train Loss = 0.2746\n","Epoch 85: Train Loss = 0.2756\n","Epoch 85: Validation Loss = 0.3060\n","confusion matrix:\n","[[2641   85]\n"," [ 297  135]]\n","accuracy = 0.8790373802185059\n","precision class 0 = 0.8989108204841614\n","precision class 1 = 0.6136363744735718\n","recall class 0 = 0.9688187837600708\n","recall class 1 = 0.3125\n","AUC of ROC = 0.8323398141354854\n","AUC of PRC = 0.4847201010964201\n","min(+P, Se) = 0.484304932735426\n","f1_score = 0.4141104319155824\n","Epoch 85: Validation AUROC = 0.8323\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86 Batch 0: Train Loss = 0.2716\n","Epoch 86 Batch 50: Train Loss = 0.2736\n","Epoch 86: Train Loss = 0.2713\n","Epoch 86: Validation Loss = 0.3016\n","confusion matrix:\n","[[2656   70]\n"," [ 306  126]]\n","accuracy = 0.8809372782707214\n","precision class 0 = 0.8966914415359497\n","precision class 1 = 0.6428571343421936\n","recall class 0 = 0.9743213653564453\n","recall class 1 = 0.2916666567325592\n","AUC of ROC = 0.8378780467922068\n","AUC of PRC = 0.4953981114661095\n","min(+P, Se) = 0.4896073903002309\n","f1_score = 0.40127386149298494\n","Epoch 86: Validation AUROC = 0.8379\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87 Batch 0: Train Loss = 0.2411\n","Epoch 87 Batch 50: Train Loss = 0.2741\n","Epoch 87: Train Loss = 0.2760\n","Epoch 87: Validation Loss = 0.3037\n","confusion matrix:\n","[[2631   95]\n"," [ 302  130]]\n","accuracy = 0.8742875456809998\n","precision class 0 = 0.8970337510108948\n","precision class 1 = 0.5777778029441833\n","recall class 0 = 0.9651504158973694\n","recall class 1 = 0.30092594027519226\n","AUC of ROC = 0.8347319026656885\n","AUC of PRC = 0.4933811001850139\n","min(+P, Se) = 0.4930875576036866\n","f1_score = 0.39573823569035305\n","Epoch 87: Validation AUROC = 0.8347\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88 Batch 0: Train Loss = 0.2454\n","Epoch 88 Batch 50: Train Loss = 0.2715\n","Epoch 88: Train Loss = 0.2726\n","Epoch 88: Validation Loss = 0.3025\n","confusion matrix:\n","[[2638   88]\n"," [ 304  128]]\n","accuracy = 0.8758708238601685\n","precision class 0 = 0.8966689109802246\n","precision class 1 = 0.5925925970077515\n","recall class 0 = 0.967718243598938\n","recall class 1 = 0.29629629850387573\n","AUC of ROC = 0.8352074332219233\n","AUC of PRC = 0.4896871715035198\n","min(+P, Se) = 0.48498845265588914\n","f1_score = 0.395061731338501\n","Epoch 88: Validation AUROC = 0.8352\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89 Batch 0: Train Loss = 0.3455\n","Epoch 89 Batch 50: Train Loss = 0.2741\n","Epoch 89: Train Loss = 0.2745\n","Epoch 89: Validation Loss = 0.3045\n","confusion matrix:\n","[[2680   46]\n"," [ 343   89]]\n","accuracy = 0.8768207430839539\n","precision class 0 = 0.8865365386009216\n","precision class 1 = 0.6592592597007751\n","recall class 0 = 0.9831254482269287\n","recall class 1 = 0.20601852238178253\n","AUC of ROC = 0.8337528192168691\n","AUC of PRC = 0.48630567877639574\n","min(+P, Se) = 0.4792626728110599\n","f1_score = 0.3139329905412636\n","Epoch 89: Validation AUROC = 0.8338\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90 Batch 0: Train Loss = 0.2495\n","Epoch 90 Batch 50: Train Loss = 0.2732\n","Epoch 90: Train Loss = 0.2759\n","Epoch 90: Validation Loss = 0.3046\n","confusion matrix:\n","[[2660   66]\n"," [ 315  117]]\n","accuracy = 0.8793540000915527\n","precision class 0 = 0.8941176533699036\n","precision class 1 = 0.6393442749977112\n","recall class 0 = 0.9757887125015259\n","recall class 1 = 0.2708333432674408\n","AUC of ROC = 0.8366289299203825\n","AUC of PRC = 0.4950511027018472\n","min(+P, Se) = 0.4955357142857143\n","f1_score = 0.3804878293893514\n","Epoch 90: Validation AUROC = 0.8366\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91 Batch 0: Train Loss = 0.3328\n","Epoch 91 Batch 50: Train Loss = 0.2722\n","Epoch 91: Train Loss = 0.2734\n","Epoch 91: Validation Loss = 0.3072\n","confusion matrix:\n","[[2652   74]\n"," [ 326  106]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.8905305862426758\n","precision class 1 = 0.5888888835906982\n","recall class 0 = 0.9728540182113647\n","recall class 1 = 0.24537037312984467\n","AUC of ROC = 0.8335464729219314\n","AUC of PRC = 0.481533532730394\n","min(+P, Se) = 0.4759725400457666\n","f1_score = 0.3464052244041206\n","Epoch 91: Validation AUROC = 0.8335\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92 Batch 0: Train Loss = 0.2422\n","Epoch 92 Batch 50: Train Loss = 0.2737\n","Epoch 92: Train Loss = 0.2755\n","Epoch 92: Validation Loss = 0.3034\n","confusion matrix:\n","[[2665   61]\n"," [ 327  105]]\n","accuracy = 0.8771374225616455\n","precision class 0 = 0.8907085657119751\n","precision class 1 = 0.6325300931930542\n","recall class 0 = 0.9776228666305542\n","recall class 1 = 0.2430555522441864\n","AUC of ROC = 0.8386456889758431\n","AUC of PRC = 0.5010814704593778\n","min(+P, Se) = 0.5023148148148148\n","f1_score = 0.35117054894723065\n","Epoch 92: Validation AUROC = 0.8386\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93 Batch 0: Train Loss = 0.2975\n","Epoch 93 Batch 50: Train Loss = 0.2762\n","Epoch 93: Train Loss = 0.2760\n","Epoch 93: Validation Loss = 0.3034\n","confusion matrix:\n","[[2602  124]\n"," [ 273  159]]\n","accuracy = 0.8742875456809998\n","precision class 0 = 0.9050434827804565\n","precision class 1 = 0.5618374347686768\n","recall class 0 = 0.9545121192932129\n","recall class 1 = 0.3680555522441864\n","AUC of ROC = 0.8371222928724764\n","AUC of PRC = 0.5049003462931007\n","min(+P, Se) = 0.5011441647597255\n","f1_score = 0.4447552214844538\n","Epoch 93: Validation AUROC = 0.8371\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94 Batch 0: Train Loss = 0.2655\n","Epoch 94 Batch 50: Train Loss = 0.2728\n","Epoch 94: Train Loss = 0.2738\n","Epoch 94: Validation Loss = 0.3031\n","confusion matrix:\n","[[2648   78]\n"," [ 306  126]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.896411657333374\n","precision class 1 = 0.6176470518112183\n","recall class 0 = 0.9713866710662842\n","recall class 1 = 0.2916666567325592\n","AUC of ROC = 0.8357746732425749\n","AUC of PRC = 0.4893282264818479\n","min(+P, Se) = 0.48758465011286684\n","f1_score = 0.39622641747088677\n","Epoch 94: Validation AUROC = 0.8358\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95 Batch 0: Train Loss = 0.2353\n","Epoch 95 Batch 50: Train Loss = 0.2726\n","Epoch 95: Train Loss = 0.2750\n","Epoch 95: Validation Loss = 0.3034\n","confusion matrix:\n","[[2636   90]\n"," [ 298  134]]\n","accuracy = 0.8771374225616455\n","precision class 0 = 0.898432195186615\n","precision class 1 = 0.5982142686843872\n","recall class 0 = 0.9669845700263977\n","recall class 1 = 0.31018519401550293\n","AUC of ROC = 0.8358145838428302\n","AUC of PRC = 0.4973705983247457\n","min(+P, Se) = 0.4919908466819222\n","f1_score = 0.4085365890534697\n","Epoch 95: Validation AUROC = 0.8358\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96 Batch 0: Train Loss = 0.2485\n","Epoch 96 Batch 50: Train Loss = 0.2698\n","Epoch 96: Train Loss = 0.2723\n","Epoch 96: Validation Loss = 0.3031\n","confusion matrix:\n","[[2646   80]\n"," [ 297  135]]\n","accuracy = 0.8806206583976746\n","precision class 0 = 0.8990825414657593\n","precision class 1 = 0.6279069781303406\n","recall class 0 = 0.9706529974937439\n","recall class 1 = 0.3125\n","AUC of ROC = 0.8328204396619657\n","AUC of PRC = 0.49336237395610766\n","min(+P, Se) = 0.49074074074074076\n","f1_score = 0.41731066491200614\n","Epoch 96: Validation AUROC = 0.8328\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97 Batch 0: Train Loss = 0.3272\n","Epoch 97 Batch 50: Train Loss = 0.2724\n","Epoch 97: Train Loss = 0.2715\n","Epoch 97: Validation Loss = 0.3047\n","confusion matrix:\n","[[2659   67]\n"," [ 314  118]]\n","accuracy = 0.8793540000915527\n","precision class 0 = 0.8943827748298645\n","precision class 1 = 0.637837827205658\n","recall class 0 = 0.9754218459129333\n","recall class 1 = 0.27314814925193787\n","AUC of ROC = 0.837399968750849\n","AUC of PRC = 0.4979733084545902\n","min(+P, Se) = 0.4897025171624714\n","f1_score = 0.3824959598197426\n","Epoch 97: Validation AUROC = 0.8374\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98 Batch 0: Train Loss = 0.2635\n","Epoch 98 Batch 50: Train Loss = 0.2779\n","Epoch 98: Train Loss = 0.2779\n","Epoch 98: Validation Loss = 0.3014\n","confusion matrix:\n","[[2644   82]\n"," [ 302  130]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8974881172180176\n","precision class 1 = 0.6132075190544128\n","recall class 0 = 0.9699193239212036\n","recall class 1 = 0.30092594027519226\n","AUC of ROC = 0.8352830086138964\n","AUC of PRC = 0.49399254835651907\n","min(+P, Se) = 0.4930555555555556\n","f1_score = 0.4037267280569563\n","Epoch 98: Validation AUROC = 0.8353\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99 Batch 0: Train Loss = 0.3127\n","Epoch 99 Batch 50: Train Loss = 0.2736\n","Epoch 99: Train Loss = 0.2729\n","Epoch 99: Validation Loss = 0.3088\n","confusion matrix:\n","[[2638   88]\n"," [ 307  125]]\n","accuracy = 0.8749208450317383\n","precision class 0 = 0.8957555294036865\n","precision class 1 = 0.5868544578552246\n","recall class 0 = 0.967718243598938\n","recall class 1 = 0.28935185074806213\n","AUC of ROC = 0.8358468519877176\n","AUC of PRC = 0.4880441170176276\n","min(+P, Se) = 0.48842592592592593\n","f1_score = 0.38759691092953846\n","Epoch 99: Validation AUROC = 0.8358\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"zbnQg6g8iCCv"}},{"cell_type":"code","source":["file_name = 'model/concare0'\n","BATCH_SIZE = 256\n","\n","checkpoint = torch.load(file_name)\n","save_epoch = checkpoint['epoch']\n","model.load_state_dict(checkpoint['net'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","model.eval()\n","\n","test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'test'),\n","                                            listfile=os.path.join(data_path, 'test_listfile.csv'),\n","                                            period_length=48.0)\n","test_raw = utils.load_data(test_reader, discretizer, normalizer, return_names=True)\n","test_dataset = Dataset(test_raw['data'][0], test_raw['data'][1], test_raw['names'])\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"id":"11s3h5lSQ8_Z","executionInfo":{"status":"ok","timestamp":1682986016729,"user_tz":300,"elapsed":2156258,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["batch_loss = []\n","y_true = []\n","y_pred = []\n","with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(test_loader):\n","        batch_x = batch_x.float().to(device)\n","        batch_y = batch_y.float().to(device)\n","        batch_demo = []\n","        for i in range(len(batch_name)):\n","            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","            cur_idx = cur_id + '_' + cur_ep\n","            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","            batch_demo.append(cur_demo)\n","\n","        batch_demo = torch.stack(batch_demo).to(device)\n","        output = model(batch_x, batch_demo)[0]\n","\n","        loss = loss_func(output, batch_y.unsqueeze(-1))\n","        batch_loss.append(loss.cpu().detach().numpy())\n","        y_pred += list(output.cpu().detach().numpy().flatten())\n","        y_true += list(batch_y.cpu().numpy().flatten())\n","\n","print(\"\\nTest Prediction Result\")\n","y_pred = np.array(y_pred)\n","y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","test_res = metrics.print_metrics_binary(y_true, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbWI5rzyMoUn","executionInfo":{"status":"ok","timestamp":1682986019522,"user_tz":300,"elapsed":2812,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"5e207a4c-fbd3-4ff9-db91-fc611d3574b0"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Prediction Result\n","confusion matrix:\n","[[2805   57]\n"," [ 299   75]]\n","accuracy = 0.8899876475334167\n","precision class 0 = 0.9036726951599121\n","precision class 1 = 0.5681818127632141\n","recall class 0 = 0.9800838828086853\n","recall class 1 = 0.20053476095199585\n","AUC of ROC = 0.8473702993680797\n","AUC of PRC = 0.4350551117589894\n","min(+P, Se) = 0.4597402597402597\n","f1_score = 0.2964426887508601\n"]}]},{"cell_type":"markdown","source":["# Comparison"],"metadata":{"id":"G5oDmsF7-ijV"}},{"cell_type":"markdown","source":["## ConCare_MC"],"metadata":{"id":"nCvD6b0w0HxI"}},{"cell_type":"code","source":["class ConCare_MC(nn.Module):\n","  def __init__(self, input_dim, hidden_dim1, hidden_dim2, d_model, n_head, ff_hidden, output_dim, dropout=0.5):\n","    super().__init__()\n","    self.input_dim = input_dim\n","    self.hidden_dim1 = hidden_dim1\n","    self.hidden_dim2 = hidden_dim2\n","    self.d_model = d_model\n","    self.n_head = n_head\n","    self.ff_hidden = ff_hidden\n","    self.output_dim = output_dim\n","    self.dropout = dropout\n","\n","    self.grus = nn.ModuleList([copy.deepcopy(nn.GRU(1, self.hidden_dim1, batch_first=True)) for _ in range(self.input_dim)])\n","    self.time_attns = nn.ModuleList([copy.deepcopy(TimeAwareSelfAttention(self.hidden_dim1, self.hidden_dim2)) for _ in range(self.input_dim)])\n","    self.multi_attn = MultiHeadAttention(self.n_head, self.d_model)\n","    self.final_attn = FinalAttention(self.hidden_dim1, self.hidden_dim1, dropout=self.dropout)\n","    self.res = ResConnect(self.d_model, dropout=self.dropout)\n","    self.pos_ff = PositionwiseFeedForward(self.d_model, self.ff_hidden, dropout=0.1)\n","    self.output_fc1 = nn.Linear(self.hidden_dim1, self.hidden_dim1)\n","    self.output_fc2 = nn.Linear(self.hidden_dim1, self.output_dim)\n","    self.dp = nn.Dropout(self.dropout)\n","  \n","  def forward(self, input):\n","    # First record embedding\n","    batch_size = input.size(0)\n","    feat_dim = input.size(2)\n","    record_embedding1 = self.grus[0](input[:, :, 0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim1).unsqueeze(0)).to(device))[0] # B*1*H\n","    time_attn_output = self.time_attns[0](record_embedding1)[0].unsqueeze(1) # B*1*H\n","\n","    # All other records embeddings\n","    for i in range(1, feat_dim):\n","      embedding = self.grus[i](input[:, :, i].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim1).unsqueeze(0)).to(device))[0] # B*1*H\n","      attn = self.time_attns[i](embedding)[0].unsqueeze(1) # B*1*H\n","      time_attn_output = torch.cat((time_attn_output, attn), 1)\n","    \n","    time_attn_output = self.dp(time_attn_output)\n","\n","    # Get multi-head attention\n","    multi_attn_output, dev_loss = self.res(time_attn_output, lambda x: self.multi_attn(time_attn_output, time_attn_output, time_attn_output))\n","    final_input = self.res(multi_attn_output, lambda x: self.pos_ff(multi_attn_output))[0]\n","\n","    # Get final output\n","    value, score = self.final_attn(final_input)\n","    output = F.sigmoid(self.output_fc2(F.relu(self.output_fc1(value))))\n","\n","    return output, dev_loss"],"metadata":{"id":"bNerr_Gs0CFS","executionInfo":{"status":"ok","timestamp":1682986877123,"user_tz":300,"elapsed":2,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"crMtkro_05Ae"}},{"cell_type":"code","source":["model = ConCare_MC(input_dim=76, hidden_dim1=64, hidden_dim2=8, d_model=64, n_head=4, ff_hidden=256, output_dim=1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.BCELoss()"],"metadata":{"id":"XKgHJzkW0uOK","executionInfo":{"status":"ok","timestamp":1682986880944,"user_tz":300,"elapsed":285,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["max_roc = 0\n","max_prc = 0\n","train_total_loss = []\n","val_total_loss = []\n","result_history = []\n","file_name = 'model/concare_mc'\n","\n","\n","for epoch in range(100):\n","  \n","  # Start training\n","  train_batch_total_loss = []\n","  model.train()\n","\n","  for step, (batch_x, batch_y, batch_name) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","    batch_x = batch_x.float().to(device)\n","    batch_y = batch_y.float().to(device)\n","\n","    # Get model outputs\n","    output, decov_loss = model(batch_x)\n","\n","    # Get loss\n","    loss = loss_func(output, batch_y.unsqueeze(-1))\n","    loss += 800 * decov_loss\n","    train_batch_total_loss.append(loss.cpu().detach().numpy())\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    if step % 50 == 0:\n","      print('Epoch %d Batch %d: Train Loss = %.4f'%(epoch, step, np.mean(np.array(train_batch_total_loss))))\n","    \n","  train_total_loss.append(np.mean(np.array(train_batch_total_loss)))\n","  print('Epoch %d: Train Loss = %.4f'%(epoch, np.mean(np.array(train_batch_total_loss))))\n","\n","  # Start Validating\n","  val_batch_total_loss = []\n","  y_true = []\n","  y_pred = []\n","\n","  with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(val_loader):\n","      batch_x = batch_x.float().to(device)\n","      batch_y = batch_y.float().to(device)\n","\n","      # Get model outputs\n","      output, decov_loss = model(batch_x)\n","\n","      # Get loss\n","      loss = loss_func(output, batch_y.unsqueeze(-1))\n","      loss += 10 * decov_loss\n","      val_batch_total_loss.append(loss.cpu().detach().numpy())\n","      y_pred += list(output.cpu().detach().numpy())\n","      y_true += list(batch_y.cpu().numpy().flatten())\n","    \n","    val_total_loss.append(np.mean(np.array(val_batch_total_loss)))\n","    print('Epoch %d: Validation Loss = %.4f'%(epoch, np.mean(np.array(val_batch_total_loss))))\n","\n","    y_pred = np.array(y_pred)\n","    y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","    result = metrics.print_metrics_binary(y_true, y_pred)\n","    result_history.append(result)\n","\n","    cur_auroc = result['auroc']\n","    print('Epoch %d: Validation AUROC = %.4f'%(epoch, cur_auroc))\n","    \n","    if cur_auroc > max_roc:\n","        max_roc = cur_auroc\n","        state = {\n","            'net': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'epoch': epoch\n","        }\n","        torch.save(state, file_name)\n","        print('\\n------------ Save best model ------------\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GKfM2ZQu1AYU","executionInfo":{"status":"ok","timestamp":1682988405652,"user_tz":300,"elapsed":1524250,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"6bef41bc-de1a-4b0c-b676-9b270d8882be"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 Batch 0: Train Loss = 0.6937\n","Epoch 0 Batch 50: Train Loss = 0.4758\n","Epoch 0: Train Loss = 0.4675\n","Epoch 0: Validation Loss = 0.4040\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7093018022608082\n","AUC of PRC = 0.30695706169131554\n","min(+P, Se) = 0.32339449541284404\n","f1_score = nan\n","Epoch 0: Validation AUROC = 0.7093\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0: Train Loss = 0.3976\n","Epoch 1 Batch 50: Train Loss = 0.4014\n","Epoch 1: Train Loss = 0.4009\n","Epoch 1: Validation Loss = 0.3977\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7385299482351024\n","AUC of PRC = 0.3351930480345954\n","min(+P, Se) = 0.3676148796498906\n","f1_score = nan\n","Epoch 1: Validation AUROC = 0.7385\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Batch 0: Train Loss = 0.4333\n","Epoch 2 Batch 50: Train Loss = 0.3974\n","Epoch 2: Train Loss = 0.3990\n","Epoch 2: Validation Loss = 0.4020\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.764068911170892\n","AUC of PRC = 0.34900873655154807\n","min(+P, Se) = 0.41244239631336405\n","f1_score = nan\n","Epoch 2: Validation AUROC = 0.7641\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Batch 0: Train Loss = 0.3727\n","Epoch 3 Batch 50: Train Loss = 0.4010\n","Epoch 3: Train Loss = 0.3993\n","Epoch 3: Validation Loss = 0.3953\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.741040919404364\n","AUC of PRC = 0.3283862495469751\n","min(+P, Se) = 0.3773148148148148\n","f1_score = nan\n","Epoch 3: Validation AUROC = 0.7410\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 Batch 0: Train Loss = 0.4225\n","Epoch 4 Batch 50: Train Loss = 0.3943\n","Epoch 4: Train Loss = 0.3945\n","Epoch 4: Validation Loss = 0.3906\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7569283103720006\n","AUC of PRC = 0.3462747304277642\n","min(+P, Se) = 0.3847926267281106\n","f1_score = nan\n","Epoch 4: Validation AUROC = 0.7569\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 Batch 0: Train Loss = 0.3974\n","Epoch 5 Batch 50: Train Loss = 0.3881\n","Epoch 5: Train Loss = 0.3880\n","Epoch 5: Validation Loss = 0.3742\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7706201937447352\n","AUC of PRC = 0.36847476497928855\n","min(+P, Se) = 0.39351851851851855\n","f1_score = nan\n","Epoch 5: Validation AUROC = 0.7706\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 Batch 0: Train Loss = 0.3761\n","Epoch 6 Batch 50: Train Loss = 0.3663\n","Epoch 6: Train Loss = 0.3643\n","Epoch 6: Validation Loss = 0.3453\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7770534428412271\n","AUC of PRC = 0.38288547938001694\n","min(+P, Se) = 0.40877598152424943\n","f1_score = nan\n","Epoch 6: Validation AUROC = 0.7771\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 Batch 0: Train Loss = 0.4061\n","Epoch 7 Batch 50: Train Loss = 0.3546\n","Epoch 7: Train Loss = 0.3530\n","Epoch 7: Validation Loss = 0.3405\n","confusion matrix:\n","[[2707   19]\n"," [ 406   26]]\n","accuracy = 0.8654211759567261\n","precision class 0 = 0.8695791959762573\n","precision class 1 = 0.5777778029441833\n","recall class 0 = 0.9930300712585449\n","recall class 1 = 0.06018518656492233\n","AUC of ROC = 0.7752727507404691\n","AUC of PRC = 0.38863056740712487\n","min(+P, Se) = 0.40046296296296297\n","f1_score = 0.10901467649059904\n","Epoch 7: Validation AUROC = 0.7753\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 Batch 0: Train Loss = 0.3488\n","Epoch 8 Batch 50: Train Loss = 0.3431\n","Epoch 8: Train Loss = 0.3439\n","Epoch 8: Validation Loss = 0.3305\n","confusion matrix:\n","[[2692   34]\n"," [ 378   54]]\n","accuracy = 0.8695377111434937\n","precision class 0 = 0.8768729567527771\n","precision class 1 = 0.6136363744735718\n","recall class 0 = 0.9875274896621704\n","recall class 1 = 0.125\n","AUC of ROC = 0.7995969878535909\n","AUC of PRC = 0.41539759387970265\n","min(+P, Se) = 0.4444444444444444\n","f1_score = 0.20769230831304245\n","Epoch 8: Validation AUROC = 0.7996\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 Batch 0: Train Loss = 0.3501\n","Epoch 9 Batch 50: Train Loss = 0.3402\n","Epoch 9: Train Loss = 0.3369\n","Epoch 9: Validation Loss = 0.3243\n","confusion matrix:\n","[[2717    9]\n"," [ 409   23]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.86916184425354\n","precision class 1 = 0.71875\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.05324074253439903\n","AUC of ROC = 0.8183328917692453\n","AUC of PRC = 0.4423479995696137\n","min(+P, Se) = 0.4423963133640553\n","f1_score = 0.09913793749283403\n","Epoch 9: Validation AUROC = 0.8183\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 Batch 0: Train Loss = 0.2846\n","Epoch 10 Batch 50: Train Loss = 0.3327\n","Epoch 10: Train Loss = 0.3321\n","Epoch 10: Validation Loss = 0.3180\n","confusion matrix:\n","[[2696   30]\n"," [ 380   52]]\n","accuracy = 0.8701710104942322\n","precision class 0 = 0.8764629364013672\n","precision class 1 = 0.6341463327407837\n","recall class 0 = 0.988994836807251\n","recall class 1 = 0.12037037312984467\n","AUC of ROC = 0.8141541670063314\n","AUC of PRC = 0.4330529648280188\n","min(+P, Se) = 0.4512471655328798\n","f1_score = 0.20233462980873607\n","Epoch 10: Validation AUROC = 0.8142\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11 Batch 0: Train Loss = 0.3458\n","Epoch 11 Batch 50: Train Loss = 0.3233\n","Epoch 11: Train Loss = 0.3253\n","Epoch 11: Validation Loss = 0.3175\n","confusion matrix:\n","[[2684   42]\n"," [ 362   70]]\n","accuracy = 0.8720709085464478\n","precision class 0 = 0.8811556100845337\n","precision class 1 = 0.625\n","recall class 0 = 0.9845927953720093\n","recall class 1 = 0.16203702986240387\n","AUC of ROC = 0.8174140988016632\n","AUC of PRC = 0.4434951661699505\n","min(+P, Se) = 0.4470046082949309\n","f1_score = 0.25735293700002043\n","Epoch 11: Validation AUROC = 0.8174\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12 Batch 0: Train Loss = 0.3521\n","Epoch 12 Batch 50: Train Loss = 0.3244\n","Epoch 12: Train Loss = 0.3220\n","Epoch 12: Validation Loss = 0.3155\n","confusion matrix:\n","[[2696   30]\n"," [ 385   47]]\n","accuracy = 0.8685877323150635\n","precision class 0 = 0.875040590763092\n","precision class 1 = 0.6103895902633667\n","recall class 0 = 0.988994836807251\n","recall class 1 = 0.10879629850387573\n","AUC of ROC = 0.8203929580717915\n","AUC of PRC = 0.4422255480698261\n","min(+P, Se) = 0.4528735632183908\n","f1_score = 0.1846758372297374\n","Epoch 12: Validation AUROC = 0.8204\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13 Batch 0: Train Loss = 0.2531\n","Epoch 13 Batch 50: Train Loss = 0.3255\n","Epoch 13: Train Loss = 0.3231\n","Epoch 13: Validation Loss = 0.3147\n","confusion matrix:\n","[[2694   32]\n"," [ 376   56]]\n","accuracy = 0.8708043098449707\n","precision class 0 = 0.8775244355201721\n","precision class 1 = 0.6363636255264282\n","recall class 0 = 0.9882611632347107\n","recall class 1 = 0.12962962687015533\n","AUC of ROC = 0.8203615390886118\n","AUC of PRC = 0.45606540991066974\n","min(+P, Se) = 0.45601851851851855\n","f1_score = 0.2153846151447861\n","Epoch 13: Validation AUROC = 0.8204\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14 Batch 0: Train Loss = 0.3397\n","Epoch 14 Batch 50: Train Loss = 0.3241\n","Epoch 14: Train Loss = 0.3236\n","Epoch 14: Validation Loss = 0.3144\n","confusion matrix:\n","[[2703   23]\n"," [ 384   48]]\n","accuracy = 0.8711209893226624\n","precision class 0 = 0.8756073713302612\n","precision class 1 = 0.6760563254356384\n","recall class 0 = 0.9915627241134644\n","recall class 1 = 0.1111111119389534\n","AUC of ROC = 0.8194002880356513\n","AUC of PRC = 0.45170747978837394\n","min(+P, Se) = 0.44675925925925924\n","f1_score = 0.19085487330126996\n","Epoch 14: Validation AUROC = 0.8194\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15 Batch 0: Train Loss = 0.3325\n","Epoch 15 Batch 50: Train Loss = 0.3147\n","Epoch 15: Train Loss = 0.3129\n","Epoch 15: Validation Loss = 0.3151\n","confusion matrix:\n","[[2708   18]\n"," [ 392   40]]\n","accuracy = 0.8701710104942322\n","precision class 0 = 0.8735483884811401\n","precision class 1 = 0.6896551847457886\n","recall class 0 = 0.9933969378471375\n","recall class 1 = 0.09259258955717087\n","AUC of ROC = 0.8233709681802125\n","AUC of PRC = 0.45774815549646913\n","min(+P, Se) = 0.45958429561200925\n","f1_score = 0.16326530019425695\n","Epoch 15: Validation AUROC = 0.8234\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16 Batch 0: Train Loss = 0.2697\n","Epoch 16 Batch 50: Train Loss = 0.3169\n","Epoch 16: Train Loss = 0.3162\n","Epoch 16: Validation Loss = 0.3152\n","confusion matrix:\n","[[2682   44]\n"," [ 356   76]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.8828176259994507\n","precision class 1 = 0.6333333253860474\n","recall class 0 = 0.983859121799469\n","recall class 1 = 0.17592592537403107\n","AUC of ROC = 0.8203742765142251\n","AUC of PRC = 0.46632522933088755\n","min(+P, Se) = 0.4537037037037037\n","f1_score = 0.27536232248371184\n","Epoch 16: Validation AUROC = 0.8204\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17 Batch 0: Train Loss = 0.3058\n","Epoch 17 Batch 50: Train Loss = 0.3124\n","Epoch 17: Train Loss = 0.3110\n","Epoch 17: Validation Loss = 0.3215\n","confusion matrix:\n","[[2705   21]\n"," [ 390   42]]\n","accuracy = 0.8698543310165405\n","precision class 0 = 0.8739902973175049\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9922963976860046\n","recall class 1 = 0.0972222238779068\n","AUC of ROC = 0.8212412706176462\n","AUC of PRC = 0.4569540321788345\n","min(+P, Se) = 0.4398148148148148\n","f1_score = 0.1696969761730226\n","Epoch 17: Validation AUROC = 0.8212\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18 Batch 0: Train Loss = 0.2931\n","Epoch 18 Batch 50: Train Loss = 0.3159\n","Epoch 18: Train Loss = 0.3138\n","Epoch 18: Validation Loss = 0.3121\n","confusion matrix:\n","[[2683   43]\n"," [ 360   72]]\n","accuracy = 0.8723875880241394\n","precision class 0 = 0.8816956877708435\n","precision class 1 = 0.626086950302124\n","recall class 0 = 0.9842259883880615\n","recall class 1 = 0.1666666716337204\n","AUC of ROC = 0.8234321078231571\n","AUC of PRC = 0.4529007490858748\n","min(+P, Se) = 0.4396355353075171\n","f1_score = 0.26325411404354365\n","Epoch 18: Validation AUROC = 0.8234\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19 Batch 0: Train Loss = 0.3081\n","Epoch 19 Batch 50: Train Loss = 0.3102\n","Epoch 19: Train Loss = 0.3096\n","Epoch 19: Validation Loss = 0.3121\n","confusion matrix:\n","[[2698   28]\n"," [ 371   61]]\n","accuracy = 0.8736541867256165\n","precision class 0 = 0.8791137337684631\n","precision class 1 = 0.6853932738304138\n","recall class 0 = 0.9897285103797913\n","recall class 1 = 0.14120370149612427\n","AUC of ROC = 0.8267591233933861\n","AUC of PRC = 0.4666577825163316\n","min(+P, Se) = 0.4539170506912442\n","f1_score = 0.234165065041931\n","Epoch 19: Validation AUROC = 0.8268\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20 Batch 0: Train Loss = 0.3953\n","Epoch 20 Batch 50: Train Loss = 0.3145\n","Epoch 20: Train Loss = 0.3118\n","Epoch 20: Validation Loss = 0.3100\n","confusion matrix:\n","[[2697   29]\n"," [ 374   58]]\n","accuracy = 0.8723875880241394\n","precision class 0 = 0.8782155513763428\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9893617033958435\n","recall class 1 = 0.13425925374031067\n","AUC of ROC = 0.8281067430232875\n","AUC of PRC = 0.46663163673498026\n","min(+P, Se) = 0.4479638009049774\n","f1_score = 0.22350672889040243\n","Epoch 20: Validation AUROC = 0.8281\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21 Batch 0: Train Loss = 0.3109\n","Epoch 21 Batch 50: Train Loss = 0.3034\n","Epoch 21: Train Loss = 0.3049\n","Epoch 21: Validation Loss = 0.3122\n","confusion matrix:\n","[[2666   60]\n"," [ 335   97]]\n","accuracy = 0.8749208450317383\n","precision class 0 = 0.8883705139160156\n","precision class 1 = 0.6178343892097473\n","recall class 0 = 0.9779897332191467\n","recall class 1 = 0.22453702986240387\n","AUC of ROC = 0.8225719070133964\n","AUC of PRC = 0.45946063522787467\n","min(+P, Se) = 0.4513888888888889\n","f1_score = 0.32937181393647935\n","Epoch 21: Validation AUROC = 0.8226\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22 Batch 0: Train Loss = 0.2921\n","Epoch 22 Batch 50: Train Loss = 0.3069\n","Epoch 22: Train Loss = 0.3054\n","Epoch 22: Validation Loss = 0.3125\n","confusion matrix:\n","[[2701   25]\n"," [ 367   65]]\n","accuracy = 0.8758708238601685\n","precision class 0 = 0.8803780674934387\n","precision class 1 = 0.7222222089767456\n","recall class 0 = 0.9908290505409241\n","recall class 1 = 0.15046297013759613\n","AUC of ROC = 0.8263464308035107\n","AUC of PRC = 0.4639833800615998\n","min(+P, Se) = 0.4383561643835616\n","f1_score = 0.24904215038177063\n","Epoch 22: Validation AUROC = 0.8263\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23 Batch 0: Train Loss = 0.2804\n","Epoch 23 Batch 50: Train Loss = 0.3040\n","Epoch 23: Train Loss = 0.3047\n","Epoch 23: Validation Loss = 0.3095\n","confusion matrix:\n","[[2679   47]\n"," [ 351   81]]\n","accuracy = 0.8739708662033081\n","precision class 0 = 0.8841584324836731\n","precision class 1 = 0.6328125\n","recall class 0 = 0.982758641242981\n","recall class 1 = 0.1875\n","AUC of ROC = 0.8258420287492186\n","AUC of PRC = 0.45970351473053456\n","min(+P, Se) = 0.4459770114942529\n","f1_score = 0.2892857142857143\n","Epoch 23: Validation AUROC = 0.8258\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24 Batch 0: Train Loss = 0.3183\n","Epoch 24 Batch 50: Train Loss = 0.3058\n","Epoch 24: Train Loss = 0.3071\n","Epoch 24: Validation Loss = 0.3110\n","confusion matrix:\n","[[2708   18]\n"," [ 385   47]]\n","accuracy = 0.8723875880241394\n","precision class 0 = 0.8755253553390503\n","precision class 1 = 0.7230769395828247\n","recall class 0 = 0.9933969378471375\n","recall class 1 = 0.10879629850387573\n","AUC of ROC = 0.8292548096519117\n","AUC of PRC = 0.47074066935759307\n","min(+P, Se) = 0.4541284403669725\n","f1_score = 0.18913481275358177\n","Epoch 24: Validation AUROC = 0.8293\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25 Batch 0: Train Loss = 0.2522\n","Epoch 25 Batch 50: Train Loss = 0.3095\n","Epoch 25: Train Loss = 0.3079\n","Epoch 25: Validation Loss = 0.3145\n","confusion matrix:\n","[[2711   15]\n"," [ 390   42]]\n","accuracy = 0.8717542886734009\n","precision class 0 = 0.874234139919281\n","precision class 1 = 0.7368420958518982\n","recall class 0 = 0.9944974184036255\n","recall class 1 = 0.0972222238779068\n","AUC of ROC = 0.8256093584413466\n","AUC of PRC = 0.4649934936100693\n","min(+P, Se) = 0.45161290322580644\n","f1_score = 0.17177914650189235\n","Epoch 25: Validation AUROC = 0.8256\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26 Batch 0: Train Loss = 0.2353\n","Epoch 26 Batch 50: Train Loss = 0.3029\n","Epoch 26: Train Loss = 0.3050\n","Epoch 26: Validation Loss = 0.3063\n","confusion matrix:\n","[[2689   37]\n"," [ 355   77]]\n","accuracy = 0.8758708238601685\n","precision class 0 = 0.8833771347999573\n","precision class 1 = 0.6754385828971863\n","recall class 0 = 0.9864270091056824\n","recall class 1 = 0.17824074625968933\n","AUC of ROC = 0.828509245672672\n","AUC of PRC = 0.4825692877775363\n","min(+P, Se) = 0.45642201834862384\n","f1_score = 0.2820512976224352\n","Epoch 26: Validation AUROC = 0.8285\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27 Batch 0: Train Loss = 0.2560\n","Epoch 27 Batch 50: Train Loss = 0.3035\n","Epoch 27: Train Loss = 0.3033\n","Epoch 27: Validation Loss = 0.3031\n","confusion matrix:\n","[[2681   45]\n"," [ 342   90]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.886867344379425\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9834923148155212\n","recall class 1 = 0.2083333283662796\n","AUC of ROC = 0.83529914268634\n","AUC of PRC = 0.4857677845345892\n","min(+P, Se) = 0.4691075514874142\n","f1_score = 0.31746031935252816\n","Epoch 27: Validation AUROC = 0.8353\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28 Batch 0: Train Loss = 0.2686\n","Epoch 28 Batch 50: Train Loss = 0.3048\n","Epoch 28: Train Loss = 0.3060\n","Epoch 28: Validation Loss = 0.3088\n","confusion matrix:\n","[[2684   42]\n"," [ 340   92]]\n","accuracy = 0.8790373802185059\n","precision class 0 = 0.8875661492347717\n","precision class 1 = 0.6865671873092651\n","recall class 0 = 0.9845927953720093\n","recall class 1 = 0.21296297013759613\n","AUC of ROC = 0.8256059617945164\n","AUC of PRC = 0.4786798993096141\n","min(+P, Se) = 0.44724770642201833\n","f1_score = 0.3250883447894561\n","Epoch 28: Validation AUROC = 0.8256\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29 Batch 0: Train Loss = 0.2418\n","Epoch 29 Batch 50: Train Loss = 0.3030\n","Epoch 29: Train Loss = 0.3042\n","Epoch 29: Validation Loss = 0.3074\n","confusion matrix:\n","[[2692   34]\n"," [ 359   73]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.8823336362838745\n","precision class 1 = 0.6822429895401001\n","recall class 0 = 0.9875274896621704\n","recall class 1 = 0.16898147761821747\n","AUC of ROC = 0.8322727303605879\n","AUC of PRC = 0.47516977991972753\n","min(+P, Se) = 0.4537037037037037\n","f1_score = 0.2708719753647796\n","Epoch 29: Validation AUROC = 0.8323\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30 Batch 0: Train Loss = 0.3341\n","Epoch 30 Batch 50: Train Loss = 0.3012\n","Epoch 30: Train Loss = 0.2998\n","Epoch 30: Validation Loss = 0.3121\n","confusion matrix:\n","[[2708   18]\n"," [ 378   54]]\n","accuracy = 0.8746041655540466\n","precision class 0 = 0.8775113224983215\n","precision class 1 = 0.75\n","recall class 0 = 0.9933969378471375\n","recall class 1 = 0.125\n","AUC of ROC = 0.834705578652754\n","AUC of PRC = 0.4808097977495727\n","min(+P, Se) = 0.46064814814814814\n","f1_score = 0.21428571428571427\n","Epoch 30: Validation AUROC = 0.8347\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31 Batch 0: Train Loss = 0.2729\n","Epoch 31 Batch 50: Train Loss = 0.2970\n","Epoch 31: Train Loss = 0.3005\n","Epoch 31: Validation Loss = 0.3056\n","confusion matrix:\n","[[2694   32]\n"," [ 353   79]]\n","accuracy = 0.8780874013900757\n","precision class 0 = 0.884148359298706\n","precision class 1 = 0.7117117047309875\n","recall class 0 = 0.9882611632347107\n","recall class 1 = 0.18287037312984467\n","AUC of ROC = 0.8319636354990353\n","AUC of PRC = 0.483117326496521\n","min(+P, Se) = 0.46296296296296297\n","f1_score = 0.2909760569948288\n","Epoch 31: Validation AUROC = 0.8320\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32 Batch 0: Train Loss = 0.3200\n","Epoch 32 Batch 50: Train Loss = 0.2993\n","Epoch 32: Train Loss = 0.2969\n","Epoch 32: Validation Loss = 0.3076\n","confusion matrix:\n","[[2666   60]\n"," [ 329  103]]\n","accuracy = 0.8768207430839539\n","precision class 0 = 0.890150249004364\n","precision class 1 = 0.6319018602371216\n","recall class 0 = 0.9779897332191467\n","recall class 1 = 0.23842592537403107\n","AUC of ROC = 0.829811010570365\n","AUC of PRC = 0.47493922319018195\n","min(+P, Se) = 0.4541387024608501\n","f1_score = 0.3462184957046729\n","Epoch 32: Validation AUROC = 0.8298\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33 Batch 0: Train Loss = 0.2743\n","Epoch 33 Batch 50: Train Loss = 0.2998\n","Epoch 33: Train Loss = 0.2976\n","Epoch 33: Validation Loss = 0.3084\n","confusion matrix:\n","[[2676   50]\n"," [ 352   80]]\n","accuracy = 0.872704267501831\n","precision class 0 = 0.883751630783081\n","precision class 1 = 0.6153846383094788\n","recall class 0 = 0.9816581010818481\n","recall class 1 = 0.18518517911434174\n","AUC of ROC = 0.8313140267927501\n","AUC of PRC = 0.46897358169664904\n","min(+P, Se) = 0.4583333333333333\n","f1_score = 0.2846974988767613\n","Epoch 33: Validation AUROC = 0.8313\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34 Batch 0: Train Loss = 0.3368\n","Epoch 34 Batch 50: Train Loss = 0.2983\n","Epoch 34: Train Loss = 0.2983\n","Epoch 34: Validation Loss = 0.3102\n","confusion matrix:\n","[[2697   29]\n"," [ 364   68]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.8810846209526062\n","precision class 1 = 0.7010309100151062\n","recall class 0 = 0.9893617033958435\n","recall class 1 = 0.15740740299224854\n","AUC of ROC = 0.8306703622184178\n","AUC of PRC = 0.46910837325561\n","min(+P, Se) = 0.45601851851851855\n","f1_score = 0.2570888397937223\n","Epoch 34: Validation AUROC = 0.8307\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35 Batch 0: Train Loss = 0.2659\n","Epoch 35 Batch 50: Train Loss = 0.2986\n","Epoch 35: Train Loss = 0.2973\n","Epoch 35: Validation Loss = 0.3069\n","confusion matrix:\n","[[2671   55]\n"," [ 348   84]]\n","accuracy = 0.8723875880241394\n","precision class 0 = 0.8847300410270691\n","precision class 1 = 0.6043165326118469\n","recall class 0 = 0.9798239469528198\n","recall class 1 = 0.1944444477558136\n","AUC of ROC = 0.8320298701122253\n","AUC of PRC = 0.4635696027494677\n","min(+P, Se) = 0.4576659038901602\n","f1_score = 0.2942206566352367\n","Epoch 35: Validation AUROC = 0.8320\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36 Batch 0: Train Loss = 0.2768\n","Epoch 36 Batch 50: Train Loss = 0.2994\n","Epoch 36: Train Loss = 0.2983\n","Epoch 36: Validation Loss = 0.3153\n","confusion matrix:\n","[[2707   19]\n"," [ 381   51]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.8766191601753235\n","precision class 1 = 0.7285714149475098\n","recall class 0 = 0.9930300712585449\n","recall class 1 = 0.1180555522441864\n","AUC of ROC = 0.8265595703921089\n","AUC of PRC = 0.47151406517621186\n","min(+P, Se) = 0.4537037037037037\n","f1_score = 0.2031872384092288\n","Epoch 36: Validation AUROC = 0.8266\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37 Batch 0: Train Loss = 0.2940\n","Epoch 37 Batch 50: Train Loss = 0.2973\n","Epoch 37: Train Loss = 0.2977\n","Epoch 37: Validation Loss = 0.3072\n","confusion matrix:\n","[[2690   36]\n"," [ 360   72]]\n","accuracy = 0.8746041655540466\n","precision class 0 = 0.8819671869277954\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9867938160896301\n","recall class 1 = 0.1666666716337204\n","AUC of ROC = 0.8306584739545122\n","AUC of PRC = 0.46839224638367843\n","min(+P, Se) = 0.45601851851851855\n","f1_score = 0.26666666984558113\n","Epoch 37: Validation AUROC = 0.8307\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38 Batch 0: Train Loss = 0.3097\n","Epoch 38 Batch 50: Train Loss = 0.2973\n","Epoch 38: Train Loss = 0.2972\n","Epoch 38: Validation Loss = 0.3042\n","confusion matrix:\n","[[2671   55]\n"," [ 328  104]]\n","accuracy = 0.8787207007408142\n","precision class 0 = 0.8906301856040955\n","precision class 1 = 0.6540880799293518\n","recall class 0 = 0.9798239469528198\n","recall class 1 = 0.24074074625968933\n","AUC of ROC = 0.8335626069943752\n","AUC of PRC = 0.47426914286839145\n","min(+P, Se) = 0.45852534562211983\n","f1_score = 0.35194587639020825\n","Epoch 38: Validation AUROC = 0.8336\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39 Batch 0: Train Loss = 0.2168\n","Epoch 39 Batch 50: Train Loss = 0.3032\n","Epoch 39: Train Loss = 0.3009\n","Epoch 39: Validation Loss = 0.3049\n","confusion matrix:\n","[[2693   33]\n"," [ 357   75]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.8829508423805237\n","precision class 1 = 0.6944444179534912\n","recall class 0 = 0.9878943562507629\n","recall class 1 = 0.1736111044883728\n","AUC of ROC = 0.832565691149697\n","AUC of PRC = 0.4825902599327337\n","min(+P, Se) = 0.4492099322799097\n","f1_score = 0.27777776718139646\n","Epoch 39: Validation AUROC = 0.8326\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40 Batch 0: Train Loss = 0.2686\n","Epoch 40 Batch 50: Train Loss = 0.2979\n","Epoch 40: Train Loss = 0.2976\n","Epoch 40: Validation Loss = 0.3044\n","confusion matrix:\n","[[2696   30]\n"," [ 361   71]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8819103837013245\n","precision class 1 = 0.7029703259468079\n","recall class 0 = 0.988994836807251\n","recall class 1 = 0.16435185074806213\n","AUC of ROC = 0.8348686177006059\n","AUC of PRC = 0.47815018366643675\n","min(+P, Se) = 0.4631336405529954\n","f1_score = 0.26641650179102233\n","Epoch 40: Validation AUROC = 0.8349\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41 Batch 0: Train Loss = 0.3292\n","Epoch 41 Batch 50: Train Loss = 0.2960\n","Epoch 41: Train Loss = 0.2971\n","Epoch 41: Validation Loss = 0.3142\n","confusion matrix:\n","[[2610  116]\n"," [ 284  148]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.9018659591674805\n","precision class 1 = 0.560606062412262\n","recall class 0 = 0.957446813583374\n","recall class 1 = 0.34259259700775146\n","AUC of ROC = 0.8361712317600066\n","AUC of PRC = 0.48475475749447733\n","min(+P, Se) = 0.46064814814814814\n","f1_score = 0.4252873602435081\n","Epoch 41: Validation AUROC = 0.8362\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42 Batch 0: Train Loss = 0.3364\n","Epoch 42 Batch 50: Train Loss = 0.2975\n","Epoch 42: Train Loss = 0.2962\n","Epoch 42: Validation Loss = 0.3042\n","confusion matrix:\n","[[2670   56]\n"," [ 336   96]]\n","accuracy = 0.8758708238601685\n","precision class 0 = 0.8882235288619995\n","precision class 1 = 0.6315789222717285\n","recall class 0 = 0.9794570803642273\n","recall class 1 = 0.2222222238779068\n","AUC of ROC = 0.8351649751365453\n","AUC of PRC = 0.47658287009377703\n","min(+P, Se) = 0.4583333333333333\n","f1_score = 0.328767127437291\n","Epoch 42: Validation AUROC = 0.8352\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43 Batch 0: Train Loss = 0.3351\n","Epoch 43 Batch 50: Train Loss = 0.2979\n","Epoch 43: Train Loss = 0.2982\n","Epoch 43: Validation Loss = 0.3087\n","confusion matrix:\n","[[2680   46]\n"," [ 348   84]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.885072648525238\n","precision class 1 = 0.6461538672447205\n","recall class 0 = 0.9831254482269287\n","recall class 1 = 0.1944444477558136\n","AUC of ROC = 0.8291605527023721\n","AUC of PRC = 0.4649112187215912\n","min(+P, Se) = 0.44803695150115475\n","f1_score = 0.298932379913618\n","Epoch 43: Validation AUROC = 0.8292\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44 Batch 0: Train Loss = 0.2513\n","Epoch 44 Batch 50: Train Loss = 0.2948\n","Epoch 44: Train Loss = 0.2939\n","Epoch 44: Validation Loss = 0.3060\n","confusion matrix:\n","[[2669   57]\n"," [ 328  104]]\n","accuracy = 0.8780874013900757\n","precision class 0 = 0.8905572295188904\n","precision class 1 = 0.6459627151489258\n","recall class 0 = 0.9790902137756348\n","recall class 1 = 0.24074074625968933\n","AUC of ROC = 0.8328943167305236\n","AUC of PRC = 0.4673176294725057\n","min(+P, Se) = 0.46485260770975056\n","f1_score = 0.3507588447374082\n","Epoch 44: Validation AUROC = 0.8329\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45 Batch 0: Train Loss = 0.2837\n","Epoch 45 Batch 50: Train Loss = 0.2961\n","Epoch 45: Train Loss = 0.2949\n","Epoch 45: Validation Loss = 0.3099\n","confusion matrix:\n","[[2672   54]\n"," [ 333   99]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.8891847133636475\n","precision class 1 = 0.6470588445663452\n","recall class 0 = 0.9801907539367676\n","recall class 1 = 0.2291666716337204\n","AUC of ROC = 0.8248340738023425\n","AUC of PRC = 0.46409847259580883\n","min(+P, Se) = 0.45622119815668205\n","f1_score = 0.3384615410009081\n","Epoch 45: Validation AUROC = 0.8248\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46 Batch 0: Train Loss = 0.2705\n","Epoch 46 Batch 50: Train Loss = 0.2952\n","Epoch 46: Train Loss = 0.2963\n","Epoch 46: Validation Loss = 0.3069\n","confusion matrix:\n","[[2686   40]\n"," [ 351   81]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8844254016876221\n","precision class 1 = 0.6694214940071106\n","recall class 0 = 0.9853264689445496\n","recall class 1 = 0.1875\n","AUC of ROC = 0.8336755455014809\n","AUC of PRC = 0.47878334577247567\n","min(+P, Se) = 0.4592760180995475\n","f1_score = 0.2929475593835244\n","Epoch 46: Validation AUROC = 0.8337\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47 Batch 0: Train Loss = 0.3183\n","Epoch 47 Batch 50: Train Loss = 0.2959\n","Epoch 47: Train Loss = 0.2955\n","Epoch 47: Validation Loss = 0.3071\n","confusion matrix:\n","[[2660   66]\n"," [ 330  102]]\n","accuracy = 0.8746041655540466\n","precision class 0 = 0.8896321058273315\n","precision class 1 = 0.6071428656578064\n","recall class 0 = 0.9757887125015259\n","recall class 1 = 0.2361111044883728\n","AUC of ROC = 0.8327049536697373\n","AUC of PRC = 0.46978746014852546\n","min(+P, Se) = 0.45727482678983833\n","f1_score = 0.33999999446868884\n","Epoch 47: Validation AUROC = 0.8327\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48 Batch 0: Train Loss = 0.3135\n","Epoch 48 Batch 50: Train Loss = 0.2915\n","Epoch 48: Train Loss = 0.2919\n","Epoch 48: Validation Loss = 0.3092\n","confusion matrix:\n","[[2630   96]\n"," [ 307  125]]\n","accuracy = 0.8723875880241394\n","precision class 0 = 0.8954715728759766\n","precision class 1 = 0.5656108856201172\n","recall class 0 = 0.9647835493087769\n","recall class 1 = 0.28935185074806213\n","AUC of ROC = 0.831479613325725\n","AUC of PRC = 0.46996096213821903\n","min(+P, Se) = 0.47126436781609193\n","f1_score = 0.38284841034718226\n","Epoch 48: Validation AUROC = 0.8315\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49 Batch 0: Train Loss = 0.3366\n","Epoch 49 Batch 50: Train Loss = 0.2950\n","Epoch 49: Train Loss = 0.2943\n","Epoch 49: Validation Loss = 0.3083\n","confusion matrix:\n","[[2685   41]\n"," [ 349   83]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.8849703073501587\n","precision class 1 = 0.6693548560142517\n","recall class 0 = 0.9849596619606018\n","recall class 1 = 0.19212962687015533\n","AUC of ROC = 0.8329308306839489\n","AUC of PRC = 0.47372948065337844\n","min(+P, Se) = 0.4537037037037037\n","f1_score = 0.2985611546330184\n","Epoch 49: Validation AUROC = 0.8329\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50 Batch 0: Train Loss = 0.2648\n","Epoch 50 Batch 50: Train Loss = 0.2958\n","Epoch 50: Train Loss = 0.2947\n","Epoch 50: Validation Loss = 0.3055\n","confusion matrix:\n","[[2655   71]\n"," [ 320  112]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8924369812011719\n","precision class 1 = 0.6120218634605408\n","recall class 0 = 0.9739544987678528\n","recall class 1 = 0.25925925374031067\n","AUC of ROC = 0.832346607429146\n","AUC of PRC = 0.48297712738396986\n","min(+P, Se) = 0.4699074074074074\n","f1_score = 0.3642276253521554\n","Epoch 50: Validation AUROC = 0.8323\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51 Batch 0: Train Loss = 0.2688\n","Epoch 51 Batch 50: Train Loss = 0.2929\n","Epoch 51: Train Loss = 0.2933\n","Epoch 51: Validation Loss = 0.3167\n","confusion matrix:\n","[[2630   96]\n"," [ 300  132]]\n","accuracy = 0.8746041655540466\n","precision class 0 = 0.8976109027862549\n","precision class 1 = 0.5789473652839661\n","recall class 0 = 0.9647835493087769\n","recall class 1 = 0.3055555522441864\n","AUC of ROC = 0.8248111464362381\n","AUC of PRC = 0.4712809216260717\n","min(+P, Se) = 0.4539170506912442\n","f1_score = 0.4000000098914159\n","Epoch 51: Validation AUROC = 0.8248\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52 Batch 0: Train Loss = 0.3243\n","Epoch 52 Batch 50: Train Loss = 0.2932\n","Epoch 52: Train Loss = 0.2936\n","Epoch 52: Validation Loss = 0.3120\n","confusion matrix:\n","[[2624  102]\n"," [ 302  130]]\n","accuracy = 0.8720709085464478\n","precision class 0 = 0.8967874050140381\n","precision class 1 = 0.5603448152542114\n","recall class 0 = 0.962582528591156\n","recall class 1 = 0.30092594027519226\n","AUC of ROC = 0.8302670104073259\n","AUC of PRC = 0.46558940677926075\n","min(+P, Se) = 0.4594594594594595\n","f1_score = 0.39156626064764544\n","Epoch 52: Validation AUROC = 0.8303\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53 Batch 0: Train Loss = 0.2850\n","Epoch 53 Batch 50: Train Loss = 0.2956\n","Epoch 53: Train Loss = 0.2918\n","Epoch 53: Validation Loss = 0.3131\n","confusion matrix:\n","[[2664   62]\n"," [ 331  101]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.8894824981689453\n","precision class 1 = 0.6196318864822388\n","recall class 0 = 0.9772560596466064\n","recall class 1 = 0.23379629850387573\n","AUC of ROC = 0.8262767995434908\n","AUC of PRC = 0.4646496818554362\n","min(+P, Se) = 0.4583333333333333\n","f1_score = 0.3394957983415515\n","Epoch 53: Validation AUROC = 0.8263\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54 Batch 0: Train Loss = 0.2974\n","Epoch 54 Batch 50: Train Loss = 0.2971\n","Epoch 54: Train Loss = 0.2961\n","Epoch 54: Validation Loss = 0.3109\n","confusion matrix:\n","[[2682   44]\n"," [ 353   79]]\n","accuracy = 0.8742875456809998\n","precision class 0 = 0.8836902976036072\n","precision class 1 = 0.642276406288147\n","recall class 0 = 0.983859121799469\n","recall class 1 = 0.18287037312984467\n","AUC of ROC = 0.825306207711747\n","AUC of PRC = 0.4571778782844132\n","min(+P, Se) = 0.45601851851851855\n","f1_score = 0.284684681268919\n","Epoch 54: Validation AUROC = 0.8253\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55 Batch 0: Train Loss = 0.3307\n","Epoch 55 Batch 50: Train Loss = 0.2936\n","Epoch 55: Train Loss = 0.2928\n","Epoch 55: Validation Loss = 0.3078\n","confusion matrix:\n","[[2677   49]\n"," [ 344   88]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.8861303925514221\n","precision class 1 = 0.6423357725143433\n","recall class 0 = 0.9820249676704407\n","recall class 1 = 0.20370370149612427\n","AUC of ROC = 0.8297498709274205\n","AUC of PRC = 0.46729579781040254\n","min(+P, Se) = 0.453125\n","f1_score = 0.30931458515592924\n","Epoch 55: Validation AUROC = 0.8297\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56 Batch 0: Train Loss = 0.3039\n","Epoch 56 Batch 50: Train Loss = 0.2910\n","Epoch 56: Train Loss = 0.2900\n","Epoch 56: Validation Loss = 0.3053\n","confusion matrix:\n","[[2657   69]\n"," [ 326  106]]\n","accuracy = 0.8749208450317383\n","precision class 0 = 0.8907140493392944\n","precision class 1 = 0.6057142615318298\n","recall class 0 = 0.9746881723403931\n","recall class 1 = 0.24537037312984467\n","AUC of ROC = 0.8326421157033776\n","AUC of PRC = 0.4721008934485031\n","min(+P, Se) = 0.4722222222222222\n","f1_score = 0.3492586417543193\n","Epoch 56: Validation AUROC = 0.8326\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57 Batch 0: Train Loss = 0.3197\n","Epoch 57 Batch 50: Train Loss = 0.2981\n","Epoch 57: Train Loss = 0.2987\n","Epoch 57: Validation Loss = 0.3072\n","confusion matrix:\n","[[2647   79]\n"," [ 325  107]]\n","accuracy = 0.8720709085464478\n","precision class 0 = 0.8906460404396057\n","precision class 1 = 0.5752688050270081\n","recall class 0 = 0.9710198044776917\n","recall class 1 = 0.24768517911434174\n","AUC of ROC = 0.8299349881796689\n","AUC of PRC = 0.47249158740194563\n","min(+P, Se) = 0.47235023041474655\n","f1_score = 0.34627830274301274\n","Epoch 57: Validation AUROC = 0.8299\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58 Batch 0: Train Loss = 0.2733\n","Epoch 58 Batch 50: Train Loss = 0.2946\n","Epoch 58: Train Loss = 0.2912\n","Epoch 58: Validation Loss = 0.3138\n","confusion matrix:\n","[[2663   63]\n"," [ 336   96]]\n","accuracy = 0.8736541867256165\n","precision class 0 = 0.8879626393318176\n","precision class 1 = 0.6037735939025879\n","recall class 0 = 0.9768891930580139\n","recall class 1 = 0.2222222238779068\n","AUC of ROC = 0.8265816485965056\n","AUC of PRC = 0.4656594095297848\n","min(+P, Se) = 0.4589041095890411\n","f1_score = 0.3248731053791805\n","Epoch 58: Validation AUROC = 0.8266\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59 Batch 0: Train Loss = 0.3477\n","Epoch 59 Batch 50: Train Loss = 0.2920\n","Epoch 59: Train Loss = 0.2903\n","Epoch 59: Validation Loss = 0.3067\n","confusion matrix:\n","[[2656   70]\n"," [ 324  108]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.89127516746521\n","precision class 1 = 0.6067415475845337\n","recall class 0 = 0.9743213653564453\n","recall class 1 = 0.25\n","AUC of ROC = 0.8296394799054373\n","AUC of PRC = 0.4739691163460813\n","min(+P, Se) = 0.45916114790286977\n","f1_score = 0.3540983563217863\n","Epoch 59: Validation AUROC = 0.8296\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60 Batch 0: Train Loss = 0.3419\n","Epoch 60 Batch 50: Train Loss = 0.2937\n","Epoch 60: Train Loss = 0.2931\n","Epoch 60: Validation Loss = 0.3089\n","confusion matrix:\n","[[2650   76]\n"," [ 318  114]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8928571343421936\n","precision class 1 = 0.6000000238418579\n","recall class 0 = 0.9721203446388245\n","recall class 1 = 0.2638888955116272\n","AUC of ROC = 0.8280490000271732\n","AUC of PRC = 0.47024511310905404\n","min(+P, Se) = 0.45057471264367815\n","f1_score = 0.36655949636921137\n","Epoch 60: Validation AUROC = 0.8280\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61 Batch 0: Train Loss = 0.2641\n","Epoch 61 Batch 50: Train Loss = 0.2909\n","Epoch 61: Train Loss = 0.2910\n","Epoch 61: Validation Loss = 0.3104\n","confusion matrix:\n","[[2687   39]\n"," [ 352   80]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8841724395751953\n","precision class 1 = 0.6722689270973206\n","recall class 0 = 0.9856933355331421\n","recall class 1 = 0.18518517911434174\n","AUC of ROC = 0.8272635254476781\n","AUC of PRC = 0.4658400991517905\n","min(+P, Se) = 0.46774193548387094\n","f1_score = 0.290381114539288\n","Epoch 61: Validation AUROC = 0.8273\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62 Batch 0: Train Loss = 0.3265\n","Epoch 62 Batch 50: Train Loss = 0.2903\n","Epoch 62: Train Loss = 0.2916\n","Epoch 62: Validation Loss = 0.3082\n","confusion matrix:\n","[[2657   69]\n"," [ 331  101]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.889223575592041\n","precision class 1 = 0.5941176414489746\n","recall class 0 = 0.9746881723403931\n","recall class 1 = 0.23379629850387573\n","AUC of ROC = 0.8286790780141844\n","AUC of PRC = 0.4697100059000892\n","min(+P, Se) = 0.4618937644341801\n","f1_score = 0.3355481741363929\n","Epoch 62: Validation AUROC = 0.8287\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63 Batch 0: Train Loss = 0.2728\n","Epoch 63 Batch 50: Train Loss = 0.2928\n","Epoch 63: Train Loss = 0.2922\n","Epoch 63: Validation Loss = 0.3150\n","confusion matrix:\n","[[2681   45]\n"," [ 353   79]]\n","accuracy = 0.8739708662033081\n","precision class 0 = 0.8836519718170166\n","precision class 1 = 0.6370967626571655\n","recall class 0 = 0.9834923148155212\n","recall class 1 = 0.18287037312984467\n","AUC of ROC = 0.8280846648188909\n","AUC of PRC = 0.4690742489295504\n","min(+P, Se) = 0.4652777777777778\n","f1_score = 0.28417265889042553\n","Epoch 63: Validation AUROC = 0.8281\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64 Batch 0: Train Loss = 0.3129\n","Epoch 64 Batch 50: Train Loss = 0.2916\n","Epoch 64: Train Loss = 0.2893\n","Epoch 64: Validation Loss = 0.3124\n","confusion matrix:\n","[[2640   86]\n"," [ 318  114]]\n","accuracy = 0.8720709085464478\n","precision class 0 = 0.8924949169158936\n","precision class 1 = 0.5699999928474426\n","recall class 0 = 0.9684519171714783\n","recall class 1 = 0.2638888955116272\n","AUC of ROC = 0.8254904758022878\n","AUC of PRC = 0.4672846837367292\n","min(+P, Se) = 0.4611872146118721\n","f1_score = 0.3607594984270329\n","Epoch 64: Validation AUROC = 0.8255\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65 Batch 0: Train Loss = 0.3185\n","Epoch 65 Batch 50: Train Loss = 0.2903\n","Epoch 65: Train Loss = 0.2913\n","Epoch 65: Validation Loss = 0.3138\n","confusion matrix:\n","[[2653   73]\n"," [ 332  100]]\n","accuracy = 0.8717542886734009\n","precision class 0 = 0.8887771964073181\n","precision class 1 = 0.5780346989631653\n","recall class 0 = 0.9732208251953125\n","recall class 1 = 0.23148147761821747\n","AUC of ROC = 0.8248901184750415\n","AUC of PRC = 0.46544210132676805\n","min(+P, Se) = 0.46296296296296297\n","f1_score = 0.3305785051329151\n","Epoch 65: Validation AUROC = 0.8249\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66 Batch 0: Train Loss = 0.2714\n","Epoch 66 Batch 50: Train Loss = 0.2919\n","Epoch 66: Train Loss = 0.2923\n","Epoch 66: Validation Loss = 0.3101\n","confusion matrix:\n","[[2671   55]\n"," [ 350   82]]\n","accuracy = 0.8717542886734009\n","precision class 0 = 0.8841443061828613\n","precision class 1 = 0.5985401272773743\n","recall class 0 = 0.9798239469528198\n","recall class 1 = 0.18981482088565826\n","AUC of ROC = 0.8269739613053994\n","AUC of PRC = 0.45914478529909275\n","min(+P, Se) = 0.4699074074074074\n","f1_score = 0.28822496634087774\n","Epoch 66: Validation AUROC = 0.8270\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67 Batch 0: Train Loss = 0.2940\n","Epoch 67 Batch 50: Train Loss = 0.2946\n","Epoch 67: Train Loss = 0.2953\n","Epoch 67: Validation Loss = 0.3100\n","confusion matrix:\n","[[2669   57]\n"," [ 333   99]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.8890739679336548\n","precision class 1 = 0.6346153616905212\n","recall class 0 = 0.9790902137756348\n","recall class 1 = 0.2291666716337204\n","AUC of ROC = 0.8302839936414771\n","AUC of PRC = 0.4797286499449307\n","min(+P, Se) = 0.46774193548387094\n","f1_score = 0.33673469020346186\n","Epoch 67: Validation AUROC = 0.8303\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68 Batch 0: Train Loss = 0.3384\n","Epoch 68 Batch 50: Train Loss = 0.2874\n","Epoch 68: Train Loss = 0.2884\n","Epoch 68: Validation Loss = 0.3078\n","confusion matrix:\n","[[2675   51]\n"," [ 335   97]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.8887042999267578\n","precision class 1 = 0.6554054021835327\n","recall class 0 = 0.9812912940979004\n","recall class 1 = 0.22453702986240387\n","AUC of ROC = 0.8310388983995001\n","AUC of PRC = 0.47830341570724\n","min(+P, Se) = 0.47235023041474655\n","f1_score = 0.3344827559048157\n","Epoch 68: Validation AUROC = 0.8310\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69 Batch 0: Train Loss = 0.2654\n","Epoch 69 Batch 50: Train Loss = 0.2897\n","Epoch 69: Train Loss = 0.2890\n","Epoch 69: Validation Loss = 0.3141\n","confusion matrix:\n","[[2692   34]\n"," [ 360   72]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8820445537567139\n","precision class 1 = 0.6792452931404114\n","recall class 0 = 0.9875274896621704\n","recall class 1 = 0.1666666716337204\n","AUC of ROC = 0.83032135675661\n","AUC of PRC = 0.47604239659160047\n","min(+P, Se) = 0.45934959349593496\n","f1_score = 0.2676579950411349\n","Epoch 69: Validation AUROC = 0.8303\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70 Batch 0: Train Loss = 0.2912\n","Epoch 70 Batch 50: Train Loss = 0.2910\n","Epoch 70: Train Loss = 0.2893\n","Epoch 70: Validation Loss = 0.3158\n","confusion matrix:\n","[[2691   35]\n"," [ 353   79]]\n","accuracy = 0.8771374225616455\n","precision class 0 = 0.8840341567993164\n","precision class 1 = 0.6929824352264404\n","recall class 0 = 0.9871606826782227\n","recall class 1 = 0.18287037312984467\n","AUC of ROC = 0.8275114806662863\n","AUC of PRC = 0.47403648435693674\n","min(+P, Se) = 0.4717832957110609\n","f1_score = 0.289377286085514\n","Epoch 70: Validation AUROC = 0.8275\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71 Batch 0: Train Loss = 0.2997\n","Epoch 71 Batch 50: Train Loss = 0.2871\n","Epoch 71: Train Loss = 0.2891\n","Epoch 71: Validation Loss = 0.3113\n","confusion matrix:\n","[[2670   56]\n"," [ 342   90]]\n","accuracy = 0.8739708662033081\n","precision class 0 = 0.886454164981842\n","precision class 1 = 0.6164383292198181\n","recall class 0 = 0.9794570803642273\n","recall class 1 = 0.2083333283662796\n","AUC of ROC = 0.8261375370234504\n","AUC of PRC = 0.46150284806230785\n","min(+P, Se) = 0.463302752293578\n","f1_score = 0.3114186817598225\n","Epoch 71: Validation AUROC = 0.8261\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72 Batch 0: Train Loss = 0.2887\n","Epoch 72 Batch 50: Train Loss = 0.2871\n","Epoch 72: Train Loss = 0.2890\n","Epoch 72: Validation Loss = 0.3116\n","confusion matrix:\n","[[2661   65]\n"," [ 342   90]]\n","accuracy = 0.8711209893226624\n","precision class 0 = 0.8861138820648193\n","precision class 1 = 0.5806451439857483\n","recall class 0 = 0.9761555194854736\n","recall class 1 = 0.2083333283662796\n","AUC of ROC = 0.8264007771527948\n","AUC of PRC = 0.4652223907456786\n","min(+P, Se) = 0.47453703703703703\n","f1_score = 0.30664395029772235\n","Epoch 72: Validation AUROC = 0.8264\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73 Batch 0: Train Loss = 0.2418\n","Epoch 73 Batch 50: Train Loss = 0.2889\n","Epoch 73: Train Loss = 0.2869\n","Epoch 73: Validation Loss = 0.3127\n","confusion matrix:\n","[[2671   55]\n"," [ 335   97]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.8885562419891357\n","precision class 1 = 0.6381579041481018\n","recall class 0 = 0.9798239469528198\n","recall class 1 = 0.22453702986240387\n","AUC of ROC = 0.8217184994972963\n","AUC of PRC = 0.4685955612172756\n","min(+P, Se) = 0.4583333333333333\n","f1_score = 0.3321917799830457\n","Epoch 73: Validation AUROC = 0.8217\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74 Batch 0: Train Loss = 0.3553\n","Epoch 74 Batch 50: Train Loss = 0.2869\n","Epoch 74: Train Loss = 0.2880\n","Epoch 74: Validation Loss = 0.3093\n","confusion matrix:\n","[[2646   80]\n"," [ 314  118]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8939189314842224\n","precision class 1 = 0.5959596037864685\n","recall class 0 = 0.9706529974937439\n","recall class 1 = 0.27314814925193787\n","AUC of ROC = 0.8272448438901117\n","AUC of PRC = 0.4732360075981356\n","min(+P, Se) = 0.47477064220183485\n","f1_score = 0.3746031900328037\n","Epoch 74: Validation AUROC = 0.8272\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75 Batch 0: Train Loss = 0.2726\n","Epoch 75 Batch 50: Train Loss = 0.2893\n","Epoch 75: Train Loss = 0.2874\n","Epoch 75: Validation Loss = 0.3156\n","confusion matrix:\n","[[2671   55]\n"," [ 340   92]]\n","accuracy = 0.8749208450317383\n","precision class 0 = 0.887080729007721\n","precision class 1 = 0.6258503198623657\n","recall class 0 = 0.9798239469528198\n","recall class 1 = 0.21296297013759613\n","AUC of ROC = 0.82282495720225\n","AUC of PRC = 0.46552629579092253\n","min(+P, Se) = 0.4651685393258427\n","f1_score = 0.3177892916115941\n","Epoch 75: Validation AUROC = 0.8228\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76 Batch 0: Train Loss = 0.2647\n","Epoch 76 Batch 50: Train Loss = 0.2855\n","Epoch 76: Train Loss = 0.2862\n","Epoch 76: Validation Loss = 0.3122\n","confusion matrix:\n","[[2665   61]\n"," [ 343   89]]\n","accuracy = 0.8720709085464478\n","precision class 0 = 0.8859707713127136\n","precision class 1 = 0.5933333039283752\n","recall class 0 = 0.9776228666305542\n","recall class 1 = 0.20601852238178253\n","AUC of ROC = 0.833615255020244\n","AUC of PRC = 0.47310460191513953\n","min(+P, Se) = 0.48267898383371827\n","f1_score = 0.305841930450523\n","Epoch 76: Validation AUROC = 0.8336\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77 Batch 0: Train Loss = 0.3456\n","Epoch 77 Batch 50: Train Loss = 0.2904\n","Epoch 77: Train Loss = 0.2890\n","Epoch 77: Validation Loss = 0.3150\n","confusion matrix:\n","[[2686   40]\n"," [ 354   78]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.883552610874176\n","precision class 1 = 0.6610169410705566\n","recall class 0 = 0.9853264689445496\n","recall class 1 = 0.1805555522441864\n","AUC of ROC = 0.8267964865085188\n","AUC of PRC = 0.4704446224211573\n","min(+P, Se) = 0.4769585253456221\n","f1_score = 0.28363634876219734\n","Epoch 77: Validation AUROC = 0.8268\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78 Batch 0: Train Loss = 0.2333\n","Epoch 78 Batch 50: Train Loss = 0.2850\n","Epoch 78: Train Loss = 0.2876\n","Epoch 78: Validation Loss = 0.3105\n","confusion matrix:\n","[[2640   86]\n"," [ 311  121]]\n","accuracy = 0.8742875456809998\n","precision class 0 = 0.8946120142936707\n","precision class 1 = 0.5845410823822021\n","recall class 0 = 0.9684519171714783\n","recall class 1 = 0.28009259700775146\n","AUC of ROC = 0.8255134031683923\n","AUC of PRC = 0.47156549292299943\n","min(+P, Se) = 0.48729792147806006\n","f1_score = 0.37871675305933117\n","Epoch 78: Validation AUROC = 0.8255\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79 Batch 0: Train Loss = 0.2873\n","Epoch 79 Batch 50: Train Loss = 0.2867\n","Epoch 79: Train Loss = 0.2877\n","Epoch 79: Validation Loss = 0.3064\n","confusion matrix:\n","[[2675   51]\n"," [ 344   88]]\n","accuracy = 0.8749208450317383\n","precision class 0 = 0.8860549926757812\n","precision class 1 = 0.633093535900116\n","recall class 0 = 0.9812912940979004\n","recall class 1 = 0.20370370149612427\n","AUC of ROC = 0.8317250210592103\n","AUC of PRC = 0.4801148656130003\n","min(+P, Se) = 0.48868778280542985\n","f1_score = 0.3082311721233761\n","Epoch 79: Validation AUROC = 0.8317\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80 Batch 0: Train Loss = 0.2440\n","Epoch 80 Batch 50: Train Loss = 0.2861\n","Epoch 80: Train Loss = 0.2859\n","Epoch 80: Validation Loss = 0.3085\n","confusion matrix:\n","[[2658   68]\n"," [ 336   96]]\n","accuracy = 0.8720709085464478\n","precision class 0 = 0.8877755403518677\n","precision class 1 = 0.5853658318519592\n","recall class 0 = 0.9750550389289856\n","recall class 1 = 0.2222222238779068\n","AUC of ROC = 0.8310575799570665\n","AUC of PRC = 0.4780067920216365\n","min(+P, Se) = 0.4837962962962963\n","f1_score = 0.322147655388261\n","Epoch 80: Validation AUROC = 0.8311\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81 Batch 0: Train Loss = 0.2895\n","Epoch 81 Batch 50: Train Loss = 0.2882\n","Epoch 81: Train Loss = 0.2896\n","Epoch 81: Validation Loss = 0.3070\n","confusion matrix:\n","[[2642   84]\n"," [ 315  117]]\n","accuracy = 0.8736541867256165\n","precision class 0 = 0.8934730887413025\n","precision class 1 = 0.5820895433425903\n","recall class 0 = 0.9691855907440186\n","recall class 1 = 0.2708333432674408\n","AUC of ROC = 0.8331541602130376\n","AUC of PRC = 0.4715742029331045\n","min(+P, Se) = 0.46485260770975056\n","f1_score = 0.3696682409885552\n","Epoch 81: Validation AUROC = 0.8332\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82 Batch 0: Train Loss = 0.2519\n","Epoch 82 Batch 50: Train Loss = 0.2832\n","Epoch 82: Train Loss = 0.2854\n","Epoch 82: Validation Loss = 0.3125\n","confusion matrix:\n","[[2645   81]\n"," [ 316  116]]\n","accuracy = 0.8742875456809998\n","precision class 0 = 0.8932793140411377\n","precision class 1 = 0.5888324975967407\n","recall class 0 = 0.9702861309051514\n","recall class 1 = 0.26851850748062134\n","AUC of ROC = 0.824714342001576\n","AUC of PRC = 0.463538142264178\n","min(+P, Se) = 0.46136363636363636\n","f1_score = 0.36883941926794916\n","Epoch 82: Validation AUROC = 0.8247\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83 Batch 0: Train Loss = 0.2631\n","Epoch 83 Batch 50: Train Loss = 0.2823\n","Epoch 83: Train Loss = 0.2842\n","Epoch 83: Validation Loss = 0.3150\n","confusion matrix:\n","[[2677   49]\n"," [ 344   88]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.8861303925514221\n","precision class 1 = 0.6423357725143433\n","recall class 0 = 0.9820249676704407\n","recall class 1 = 0.20370370149612427\n","AUC of ROC = 0.823207079970653\n","AUC of PRC = 0.4663607639184085\n","min(+P, Se) = 0.46559633027522934\n","f1_score = 0.30931458515592924\n","Epoch 83: Validation AUROC = 0.8232\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84 Batch 0: Train Loss = 0.3817\n","Epoch 84 Batch 50: Train Loss = 0.2804\n","Epoch 84: Train Loss = 0.2816\n","Epoch 84: Validation Loss = 0.3103\n","confusion matrix:\n","[[2653   73]\n"," [ 318  114]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8929653167724609\n","precision class 1 = 0.6096256971359253\n","recall class 0 = 0.9732208251953125\n","recall class 1 = 0.2638888955116272\n","AUC of ROC = 0.8267659166870465\n","AUC of PRC = 0.4649154680679991\n","min(+P, Se) = 0.46296296296296297\n","f1_score = 0.3683360375356995\n","Epoch 84: Validation AUROC = 0.8268\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85 Batch 0: Train Loss = 0.2920\n","Epoch 85 Batch 50: Train Loss = 0.2789\n","Epoch 85: Train Loss = 0.2840\n","Epoch 85: Validation Loss = 0.3149\n","confusion matrix:\n","[[2615  111]\n"," [ 300  132]]\n","accuracy = 0.8698543310165405\n","precision class 0 = 0.8970840573310852\n","precision class 1 = 0.5432098507881165\n","recall class 0 = 0.9592810273170471\n","recall class 1 = 0.3055555522441864\n","AUC of ROC = 0.8230805548762261\n","AUC of PRC = 0.4610088611910952\n","min(+P, Se) = 0.44803695150115475\n","f1_score = 0.39111111545562793\n","Epoch 85: Validation AUROC = 0.8231\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86 Batch 0: Train Loss = 0.2711\n","Epoch 86 Batch 50: Train Loss = 0.2841\n","Epoch 86: Train Loss = 0.2821\n","Epoch 86: Validation Loss = 0.3153\n","confusion matrix:\n","[[2663   63]\n"," [ 336   96]]\n","accuracy = 0.8736541867256165\n","precision class 0 = 0.8879626393318176\n","precision class 1 = 0.6037735939025879\n","recall class 0 = 0.9768891930580139\n","recall class 1 = 0.2222222238779068\n","AUC of ROC = 0.8232410464389555\n","AUC of PRC = 0.46140921761889103\n","min(+P, Se) = 0.4622425629290618\n","f1_score = 0.3248731053791805\n","Epoch 86: Validation AUROC = 0.8232\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87 Batch 0: Train Loss = 0.2815\n","Epoch 87 Batch 50: Train Loss = 0.2828\n","Epoch 87: Train Loss = 0.2837\n","Epoch 87: Validation Loss = 0.3161\n","confusion matrix:\n","[[2676   50]\n"," [ 344   88]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8860927224159241\n","precision class 1 = 0.6376811861991882\n","recall class 0 = 0.9816581010818481\n","recall class 1 = 0.20370370149612427\n","AUC of ROC = 0.8226449349202467\n","AUC of PRC = 0.45548329500565476\n","min(+P, Se) = 0.4675925925925926\n","f1_score = 0.30877193042776246\n","Epoch 87: Validation AUROC = 0.8226\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88 Batch 0: Train Loss = 0.3017\n","Epoch 88 Batch 50: Train Loss = 0.2801\n","Epoch 88: Train Loss = 0.2788\n","Epoch 88: Validation Loss = 0.3299\n","confusion matrix:\n","[[2702   24]\n"," [ 381   51]]\n","accuracy = 0.8717542886734009\n","precision class 0 = 0.8764190673828125\n","precision class 1 = 0.6800000071525574\n","recall class 0 = 0.9911959171295166\n","recall class 1 = 0.1180555522441864\n","AUC of ROC = 0.8232104766174831\n","AUC of PRC = 0.45415824672628197\n","min(+P, Se) = 0.45265588914549654\n","f1_score = 0.2011834349703553\n","Epoch 88: Validation AUROC = 0.8232\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89 Batch 0: Train Loss = 0.2844\n","Epoch 89 Batch 50: Train Loss = 0.2827\n","Epoch 89: Train Loss = 0.2830\n","Epoch 89: Validation Loss = 0.3146\n","confusion matrix:\n","[[2643   83]\n"," [ 318  114]]\n","accuracy = 0.8730208873748779\n","precision class 0 = 0.892603874206543\n","precision class 1 = 0.5786802172660828\n","recall class 0 = 0.9695524573326111\n","recall class 1 = 0.2638888955116272\n","AUC of ROC = 0.8242659846199833\n","AUC of PRC = 0.4570041415685726\n","min(+P, Se) = 0.45727482678983833\n","f1_score = 0.3624801362237044\n","Epoch 89: Validation AUROC = 0.8243\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90 Batch 0: Train Loss = 0.2652\n","Epoch 90 Batch 50: Train Loss = 0.2791\n","Epoch 90: Train Loss = 0.2797\n","Epoch 90: Validation Loss = 0.3136\n","confusion matrix:\n","[[2660   66]\n"," [ 344   88]]\n","accuracy = 0.8701710104942322\n","precision class 0 = 0.8854860067367554\n","precision class 1 = 0.5714285969734192\n","recall class 0 = 0.9757887125015259\n","recall class 1 = 0.20370370149612427\n","AUC of ROC = 0.8245003532512704\n","AUC of PRC = 0.4495268715753941\n","min(+P, Se) = 0.4636363636363636\n","f1_score = 0.3003412980572533\n","Epoch 90: Validation AUROC = 0.8245\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91 Batch 0: Train Loss = 0.2460\n","Epoch 91 Batch 50: Train Loss = 0.2753\n","Epoch 91: Train Loss = 0.2773\n","Epoch 91: Validation Loss = 0.3168\n","confusion matrix:\n","[[2673   53]\n"," [ 352   80]]\n","accuracy = 0.8717542886734009\n","precision class 0 = 0.8836363554000854\n","precision class 1 = 0.6015037298202515\n","recall class 0 = 0.9805576205253601\n","recall class 1 = 0.18518517911434174\n","AUC of ROC = 0.8267824753403441\n","AUC of PRC = 0.4556260725873024\n","min(+P, Se) = 0.45622119815668205\n","f1_score = 0.2831858249677452\n","Epoch 91: Validation AUROC = 0.8268\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92 Batch 0: Train Loss = 0.2109\n","Epoch 92 Batch 50: Train Loss = 0.2781\n","Epoch 92: Train Loss = 0.2761\n","Epoch 92: Validation Loss = 0.3230\n","confusion matrix:\n","[[2684   42]\n"," [ 352   80]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8840579986572266\n","precision class 1 = 0.6557376980781555\n","recall class 0 = 0.9845927953720093\n","recall class 1 = 0.18518517911434174\n","AUC of ROC = 0.8224428344338469\n","AUC of PRC = 0.4589369259246033\n","min(+P, Se) = 0.45393258426966293\n","f1_score = 0.2888086510959311\n","Epoch 92: Validation AUROC = 0.8224\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93 Batch 0: Train Loss = 0.2850\n","Epoch 93 Batch 50: Train Loss = 0.2760\n","Epoch 93: Train Loss = 0.2750\n","Epoch 93: Validation Loss = 0.3162\n","confusion matrix:\n","[[2635   91]\n"," [ 301  131]]\n","accuracy = 0.8758708238601685\n","precision class 0 = 0.8974795937538147\n","precision class 1 = 0.5900900959968567\n","recall class 0 = 0.96661776304245\n","recall class 1 = 0.30324074625968933\n","AUC of ROC = 0.8302593679519579\n","AUC of PRC = 0.4725237917515811\n","min(+P, Se) = 0.46296296296296297\n","f1_score = 0.4006116403372302\n","Epoch 93: Validation AUROC = 0.8303\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94 Batch 0: Train Loss = 0.2683\n","Epoch 94 Batch 50: Train Loss = 0.2781\n","Epoch 94: Train Loss = 0.2792\n","Epoch 94: Validation Loss = 0.3123\n","confusion matrix:\n","[[2674   52]\n"," [ 351   81]]\n","accuracy = 0.8723875880241394\n","precision class 0 = 0.8839669227600098\n","precision class 1 = 0.6090225577354431\n","recall class 0 = 0.9809244275093079\n","recall class 1 = 0.1875\n","AUC of ROC = 0.8287792790956767\n","AUC of PRC = 0.46885598758424873\n","min(+P, Se) = 0.45643153526970953\n","f1_score = 0.2867256638658141\n","Epoch 94: Validation AUROC = 0.8288\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95 Batch 0: Train Loss = 0.2073\n","Epoch 95 Batch 50: Train Loss = 0.2835\n","Epoch 95: Train Loss = 0.2806\n","Epoch 95: Validation Loss = 0.3165\n","confusion matrix:\n","[[2608  118]\n"," [ 303  129]]\n","accuracy = 0.8666877746582031\n","precision class 0 = 0.8959120512008667\n","precision class 1 = 0.52226722240448\n","recall class 0 = 0.9567131400108337\n","recall class 1 = 0.2986111044883728\n","AUC of ROC = 0.8271242629276379\n","AUC of PRC = 0.46195536539392046\n","min(+P, Se) = 0.45977011494252873\n","f1_score = 0.37997054377251893\n","Epoch 95: Validation AUROC = 0.8271\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96 Batch 0: Train Loss = 0.2817\n","Epoch 96 Batch 50: Train Loss = 0.2781\n","Epoch 96: Train Loss = 0.2776\n","Epoch 96: Validation Loss = 0.3140\n","confusion matrix:\n","[[2636   90]\n"," [ 312  120]]\n","accuracy = 0.872704267501831\n","precision class 0 = 0.8941655158996582\n","precision class 1 = 0.5714285969734192\n","recall class 0 = 0.9669845700263977\n","recall class 1 = 0.2777777910232544\n","AUC of ROC = 0.8247933140403794\n","AUC of PRC = 0.46619042383796744\n","min(+P, Se) = 0.4689655172413793\n","f1_score = 0.3738317931621957\n","Epoch 96: Validation AUROC = 0.8248\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97 Batch 0: Train Loss = 0.2660\n","Epoch 97 Batch 50: Train Loss = 0.2767\n","Epoch 97: Train Loss = 0.2770\n","Epoch 97: Validation Loss = 0.3134\n","confusion matrix:\n","[[2633   93]\n"," [ 307  125]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.8955782055854797\n","precision class 1 = 0.5733944773674011\n","recall class 0 = 0.9658840894699097\n","recall class 1 = 0.28935185074806213\n","AUC of ROC = 0.8253070568734545\n","AUC of PRC = 0.46214157838428915\n","min(+P, Se) = 0.45622119815668205\n","f1_score = 0.3846153662946805\n","Epoch 97: Validation AUROC = 0.8253\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98 Batch 0: Train Loss = 0.3264\n","Epoch 98 Batch 50: Train Loss = 0.2727\n","Epoch 98: Train Loss = 0.2734\n","Epoch 98: Validation Loss = 0.3241\n","confusion matrix:\n","[[2671   55]\n"," [ 352   80]]\n","accuracy = 0.8711209893226624\n","precision class 0 = 0.8835594058036804\n","precision class 1 = 0.5925925970077515\n","recall class 0 = 0.9798239469528198\n","recall class 1 = 0.18518517911434174\n","AUC of ROC = 0.8256781405396592\n","AUC of PRC = 0.463344879862744\n","min(+P, Se) = 0.4645308924485126\n","f1_score = 0.2821869368996481\n","Epoch 98: Validation AUROC = 0.8257\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99 Batch 0: Train Loss = 0.2494\n","Epoch 99 Batch 50: Train Loss = 0.2739\n","Epoch 99: Train Loss = 0.2755\n","Epoch 99: Validation Loss = 0.3172\n","confusion matrix:\n","[[2656   70]\n"," [ 329  103]]\n","accuracy = 0.8736541867256165\n","precision class 0 = 0.8897822499275208\n","precision class 1 = 0.5953757166862488\n","recall class 0 = 0.9743213653564453\n","recall class 1 = 0.23842592537403107\n","AUC of ROC = 0.82149771745333\n","AUC of PRC = 0.4492815274117013\n","min(+P, Se) = 0.4585152838427948\n","f1_score = 0.3404958723330872\n","Epoch 99: Validation AUROC = 0.8215\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"zw8mdz7VlVFT"}},{"cell_type":"code","source":["file_name = 'model/concare_mc'\n","BATCH_SIZE = 256\n","\n","checkpoint = torch.load(file_name)\n","save_epoch = checkpoint['epoch']\n","model.load_state_dict(checkpoint['net'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","model.eval()\n","\n","# test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'test'),\n","#                                             listfile=os.path.join(data_path, 'test_listfile.csv'),\n","#                                             period_length=48.0)\n","# test_raw = utils.load_data(test_reader, discretizer, normalizer, return_names=True)\n","# test_dataset = Dataset(test_raw['data'][0], test_raw['data'][1], test_raw['names'])\n","# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVUHWTHf1c2g","executionInfo":{"status":"ok","timestamp":1682988406757,"user_tz":300,"elapsed":1122,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"b49a547a-0ff6-4a6e-9c39-ce2d544eb168"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConCare_MC(\n","  (grus): ModuleList(\n","    (0-75): 76 x GRU(1, 64, batch_first=True)\n","  )\n","  (time_attns): ModuleList(\n","    (0-75): 76 x TimeAwareSelfAttention()\n","  )\n","  (multi_attn): MultiHeadAttention(\n","    (w_qs): Linear(in_features=64, out_features=64, bias=False)\n","    (w_ks): Linear(in_features=64, out_features=64, bias=False)\n","    (w_vs): Linear(in_features=64, out_features=64, bias=False)\n","    (fc): Linear(in_features=64, out_features=64, bias=False)\n","    (attn): ScaledDotProductAttention(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_attn): FinalAttention(\n","    (w_qs): Linear(in_features=64, out_features=64, bias=True)\n","    (w_ks): Linear(in_features=64, out_features=64, bias=True)\n","    (w_vs): Linear(in_features=64, out_features=64, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (res): ResConnect(\n","    (lnorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (pos_ff): PositionwiseFeedForward(\n","    (fc1): Linear(in_features=64, out_features=256, bias=True)\n","    (fc2): Linear(in_features=256, out_features=64, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (output_fc1): Linear(in_features=64, out_features=64, bias=True)\n","  (output_fc2): Linear(in_features=64, out_features=1, bias=True)\n","  (dp): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["batch_loss = []\n","y_true = []\n","y_pred = []\n","with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(test_loader):\n","        batch_x = batch_x.float().to(device)\n","        batch_y = batch_y.float().to(device)\n","        output = model(batch_x)[0]\n","\n","        loss = loss_func(output, batch_y.unsqueeze(-1))\n","        batch_loss.append(loss.cpu().detach().numpy())\n","        y_pred += list(output.cpu().detach().numpy().flatten())\n","        y_true += list(batch_y.cpu().numpy().flatten())\n","\n","print(\"\\nTest Prediction Result\")\n","y_pred = np.array(y_pred)\n","y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","test_res = metrics.print_metrics_binary(y_true, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gklFkEmklaIY","executionInfo":{"status":"ok","timestamp":1682988407924,"user_tz":300,"elapsed":1173,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"e69f37a9-de1e-49c7-e914-cc96d8ca97a1"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Prediction Result\n","confusion matrix:\n","[[2739  123]\n"," [ 252  122]]\n","accuracy = 0.8841161727905273\n","precision class 0 = 0.9157472252845764\n","precision class 1 = 0.4979591965675354\n","recall class 0 = 0.9570230841636658\n","recall class 1 = 0.32620319724082947\n","AUC of ROC = 0.8382782691883691\n","AUC of PRC = 0.40562530660724944\n","min(+P, Se) = 0.4509283819628647\n","f1_score = 0.3941841780453197\n"]}]},{"cell_type":"markdown","source":["## ConCare_PE"],"metadata":{"id":"LiJ_9MuH0jTQ"}},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","  def __init__(self, d_model, dropout, max_len=5000):\n","    super().__init__()\n","    self.dropout = nn.Dropout(p=dropout)\n","\n","    position = torch.arange(max_len).unsqueeze(1)\n","    div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n","    pe = torch.zeros(max_len, 1, d_model)\n","    pe[:, 0, 0::2] = torch.sin(position * div_term)\n","    pe[:, 0, 1::2] = torch.cos(position * div_term)\n","    self.register_buffer('pe', pe)\n","\n","  def forward(self, x):\n","    x = x + self.pe[:x.size(0)]\n","    return self.dropout(x)"],"metadata":{"id":"9CB1_pd60lx3","executionInfo":{"status":"ok","timestamp":1682988407924,"user_tz":300,"elapsed":5,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["class ConCare_PE(nn.Module):\n","  def __init__(self, demo_input_dim, input_dim, hidden_dim1, hidden_dim2, d_model, n_head, ff_hidden, output_dim, dropout=0.5):\n","    super().__init__()\n","    self.demo_input_dim = demo_input_dim\n","    self.input_dim = input_dim\n","    self.hidden_dim1 = hidden_dim1\n","    self.hidden_dim2 = hidden_dim2\n","    self.d_model = d_model\n","    self.n_head = n_head\n","    self.ff_hidden = ff_hidden\n","    self.output_dim = output_dim\n","    self.dropout = dropout\n","\n","    self.demo_embed = DemographicEmbed(self.demo_input_dim, self.hidden_dim1)\n","    self.gru = nn.GRU(self.input_dim, self.hidden_dim1, batch_first=True)\n","    self.pos_encoder = PositionalEncoding(self.d_model, self.dropout)\n","    self.time_attns = TimeAwareSelfAttention(self.hidden_dim1, self.hidden_dim2)\n","    self.multi_attn = MultiHeadAttention(self.n_head, self.d_model)\n","    self.final_attn = FinalAttention(self.hidden_dim1, self.hidden_dim1, dropout=self.dropout)\n","    self.res = ResConnect(self.d_model, dropout=self.dropout)\n","    self.pos_ff = PositionwiseFeedForward(self.d_model, self.ff_hidden, dropout=0.1)\n","    self.output_fc1 = nn.Linear(self.hidden_dim1, self.hidden_dim1)\n","    self.output_fc2 = nn.Linear(self.hidden_dim1, self.output_dim)\n","    self.dp = nn.Dropout(self.dropout)\n","  \n","  def forward(self, input, demo):\n","    # Demographic embedding\n","    demo_embedding = self.demo_embed(demo)\n","\n","    # First record embedding\n","    batch_size = input.size(0)\n","    feat_dim = input.size(2)\n","    embedding = self.gru(input)[0] * math.sqrt(self.d_model) # B*1*H\n","    embedding = self.pos_encoder(embedding)\n","    time_attn_output = self.time_attns(embedding)[0].unsqueeze(1) # B*1*H\n","\n","    # Combine with demographic embedding\n","    demo_embedding = demo_embedding.unsqueeze(1)\n","    time_attn_output = torch.cat((time_attn_output, demo_embedding), 1)\n","    time_attn_output = self.dp(time_attn_output)\n","\n","    # Get multi-head attention\n","    multi_attn_output, dev_loss = self.res(time_attn_output, lambda x: self.multi_attn(time_attn_output, time_attn_output, time_attn_output))\n","    final_input = self.res(multi_attn_output, lambda x: self.pos_ff(multi_attn_output))[0]\n","\n","    # Get final output\n","    value, score = self.final_attn(final_input)\n","    output = F.sigmoid(self.output_fc2(F.relu(self.output_fc1(value))))\n","\n","    return output, dev_loss"],"metadata":{"id":"zwwgTPWK1hpq","executionInfo":{"status":"ok","timestamp":1682988407924,"user_tz":300,"elapsed":3,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"Rl2bfPA46_3T"}},{"cell_type":"code","source":["RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic=True"],"metadata":{"id":"FXrD0xTA3Uw-","executionInfo":{"status":"ok","timestamp":1682961038191,"user_tz":300,"elapsed":4,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["model = ConCare_PE(demo_input_dim=12, input_dim=76, hidden_dim1=64, hidden_dim2=8, d_model=64, n_head=4, ff_hidden=256, output_dim=1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.BCELoss()"],"metadata":{"id":"OXgwX9hG3aIp","executionInfo":{"status":"ok","timestamp":1682988409246,"user_tz":300,"elapsed":1325,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["max_roc = 0\n","max_prc = 0\n","train_total_loss = []\n","val_total_loss = []\n","result_history = []\n","file_name = 'model/concare_pe'\n","\n","\n","for epoch in range(100):\n","  \n","  # Start training\n","  train_batch_total_loss = []\n","  model.train()\n","\n","  for step, (batch_x, batch_y, batch_name) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","    batch_x = batch_x.float().to(device)\n","    batch_y = batch_y.float().to(device)\n","\n","    # Get batch demographic data\n","    batch_demo = []\n","    for i in range(len(batch_name)):\n","      cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","      cur_idx = cur_id + '_' + cur_ep\n","      cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","      batch_demo.append(cur_demo)\n","    batch_demo = torch.stack(batch_demo).to(device)\n","\n","    # Get model outputs\n","    output, decov_loss = model(batch_x, batch_demo)\n","\n","    # Get loss\n","    loss = loss_func(output, batch_y.unsqueeze(-1))\n","    loss += 800 * decov_loss\n","    train_batch_total_loss.append(loss.cpu().detach().numpy())\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    if step % 50 == 0:\n","      print('Epoch %d Batch %d: Train Loss = %.4f'%(epoch, step, np.mean(np.array(train_batch_total_loss))))\n","    \n","  train_total_loss.append(np.mean(np.array(train_batch_total_loss)))\n","  print('Epoch %d: Train Loss = %.4f'%(epoch, np.mean(np.array(train_batch_total_loss))))\n","\n","  # Start Validating\n","  val_batch_total_loss = []\n","  y_true = []\n","  y_pred = []\n","\n","  with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(val_loader):\n","      batch_x = batch_x.float().to(device)\n","      batch_y = batch_y.float().to(device)\n","\n","      # Get batch demographic data\n","      batch_demo = []\n","      for i in range(len(batch_name)):\n","        cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","        cur_idx = cur_id + '_' + cur_ep\n","        cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","        batch_demo.append(cur_demo)\n","      batch_demo = torch.stack(batch_demo).to(device)\n","\n","      # Get model outputs\n","      output, decov_loss = model(batch_x, batch_demo)\n","\n","      # Get loss\n","      loss = loss_func(output, batch_y.unsqueeze(-1))\n","      loss += 10 * decov_loss\n","      val_batch_total_loss.append(loss.cpu().detach().numpy())\n","      y_pred += list(output.cpu().detach().numpy())\n","      y_true += list(batch_y.cpu().numpy().flatten())\n","    \n","    val_total_loss.append(np.mean(np.array(val_batch_total_loss)))\n","    print('Epoch %d: Validation Loss = %.4f'%(epoch, np.mean(np.array(val_batch_total_loss))))\n","\n","    y_pred = np.array(y_pred)\n","    y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","    result = metrics.print_metrics_binary(y_true, y_pred)\n","    result_history.append(result)\n","\n","    cur_auroc = result['auroc']\n","    print('Epoch %d: Validation AUROC = %.4f'%(epoch, cur_auroc))\n","    \n","    if cur_auroc > max_roc:\n","        max_roc = cur_auroc\n","        state = {\n","            'net': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'epoch': epoch\n","        }\n","        torch.save(state, file_name)\n","        print('\\n------------ Save best model ------------\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tXhFEmJW6xfJ","executionInfo":{"status":"ok","timestamp":1682989137977,"user_tz":300,"elapsed":728738,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"e857fd4d-1cf4-45b1-8ebf-7192b93e0d7b"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 Batch 0: Train Loss = 38071.6719\n","Epoch 0 Batch 50: Train Loss = 3104.8596\n","Epoch 0: Train Loss = 2837.4905\n","Epoch 0: Validation Loss = 1.1139\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.557770169288878\n","AUC of PRC = 0.17212789485902355\n","min(+P, Se) = 0.18518518518518517\n","f1_score = nan\n","Epoch 0: Validation AUROC = 0.5578\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n","Epoch 1 Batch 0: Train Loss = 413.3376\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 50: Train Loss = 329.7593\n","Epoch 1: Train Loss = 317.4288\n","Epoch 1: Validation Loss = 0.6970\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6409570222276568\n","AUC of PRC = 0.22587379601035673\n","min(+P, Se) = 0.2638888888888889\n","f1_score = nan\n","Epoch 1: Validation AUROC = 0.6410\n","\n","------------ Save best model ------------\n","\n","Epoch 2 Batch 0: Train Loss = 251.4026\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Batch 50: Train Loss = 174.7428\n","Epoch 2: Train Loss = 169.1352\n","Epoch 2: Validation Loss = 0.5785\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6591184682481455\n","AUC of PRC = 0.2475382959169764\n","min(+P, Se) = 0.2942528735632184\n","f1_score = nan\n","Epoch 2: Validation AUROC = 0.6591\n","\n","------------ Save best model ------------\n","\n","Epoch 3 Batch 0: Train Loss = 106.8724\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Batch 50: Train Loss = 104.3591\n","Epoch 3: Train Loss = 102.6892\n","Epoch 3: Validation Loss = 0.5138\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6635413270019836\n","AUC of PRC = 0.24232595861804787\n","min(+P, Se) = 0.2847222222222222\n","f1_score = nan\n","Epoch 3: Validation AUROC = 0.6635\n","\n","------------ Save best model ------------\n","\n","Epoch 4 Batch 0: Train Loss = 72.0868\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 Batch 50: Train Loss = 76.8797\n","Epoch 4: Train Loss = 75.4069\n","Epoch 4: Validation Loss = 0.4948\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.693253919730442\n","AUC of PRC = 0.25875947515171954\n","min(+P, Se) = 0.2926267281105991\n","f1_score = nan\n","Epoch 4: Validation AUROC = 0.6933\n","\n","------------ Save best model ------------\n","\n","Epoch 5 Batch 0: Train Loss = 52.5820\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 Batch 50: Train Loss = 58.2322\n","Epoch 5: Train Loss = 57.2178\n","Epoch 5: Validation Loss = 0.4570\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.690559529632347\n","AUC of PRC = 0.2618073264019196\n","min(+P, Se) = 0.2986111111111111\n","f1_score = nan\n","Epoch 5: Validation AUROC = 0.6906\n","Epoch 6 Batch 0: Train Loss = 47.4802\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 Batch 50: Train Loss = 42.7342\n","Epoch 6: Train Loss = 42.7554\n","Epoch 6: Validation Loss = 0.4524\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6925486909323115\n","AUC of PRC = 0.2658145209975815\n","min(+P, Se) = 0.2880658436213992\n","f1_score = nan\n","Epoch 6: Validation AUROC = 0.6925\n","Epoch 7 Batch 0: Train Loss = 37.6437\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 Batch 50: Train Loss = 36.5893\n","Epoch 7: Train Loss = 36.3707\n","Epoch 7: Validation Loss = 0.4385\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6991700293470285\n","AUC of PRC = 0.2720957093262156\n","min(+P, Se) = 0.315668202764977\n","f1_score = nan\n","Epoch 7: Validation AUROC = 0.6992\n","\n","------------ Save best model ------------\n","\n","Epoch 8 Batch 0: Train Loss = 33.3311\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 Batch 50: Train Loss = 33.1603\n","Epoch 8: Train Loss = 32.5297\n","Epoch 8: Validation Loss = 0.4251\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7029959274204506\n","AUC of PRC = 0.27352467914320555\n","min(+P, Se) = 0.29493087557603687\n","f1_score = nan\n","Epoch 8: Validation AUROC = 0.7030\n","\n","------------ Save best model ------------\n","\n","Epoch 9 Batch 0: Train Loss = 24.0960\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 Batch 50: Train Loss = 25.7395\n","Epoch 9: Train Loss = 25.5093\n","Epoch 9: Validation Loss = 0.4292\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7035325976196299\n","AUC of PRC = 0.2812235817768039\n","min(+P, Se) = 0.3101851851851852\n","f1_score = nan\n","Epoch 9: Validation AUROC = 0.7035\n","\n","------------ Save best model ------------\n","\n","Epoch 10 Batch 0: Train Loss = 20.4560\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 Batch 50: Train Loss = 21.9879\n","Epoch 10: Train Loss = 22.0802\n","Epoch 10: Validation Loss = 0.4185\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.718977150756773\n","AUC of PRC = 0.28903529577895953\n","min(+P, Se) = 0.3181818181818182\n","f1_score = nan\n","Epoch 10: Validation AUROC = 0.7190\n","\n","------------ Save best model ------------\n","\n","Epoch 11 Batch 0: Train Loss = 17.8713\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11 Batch 50: Train Loss = 19.1771\n","Epoch 11: Train Loss = 19.0861\n","Epoch 11: Validation Loss = 0.4260\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7172699111437189\n","AUC of PRC = 0.2818131003039914\n","min(+P, Se) = 0.3264367816091954\n","f1_score = nan\n","Epoch 11: Validation AUROC = 0.7173\n","Epoch 12 Batch 0: Train Loss = 26.1014\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12 Batch 50: Train Loss = 17.0800\n","Epoch 12: Train Loss = 16.9108\n","Epoch 12: Validation Loss = 0.4120\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7006348332925736\n","AUC of PRC = 0.2692801840020733\n","min(+P, Se) = 0.30751708428246016\n","f1_score = nan\n","Epoch 12: Validation AUROC = 0.7006\n","Epoch 13 Batch 0: Train Loss = 15.1777\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13 Batch 50: Train Loss = 14.8243\n","Epoch 13: Train Loss = 14.8115\n","Epoch 13: Validation Loss = 0.4090\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7056712113801256\n","AUC of PRC = 0.26652300612480684\n","min(+P, Se) = 0.31065759637188206\n","f1_score = nan\n","Epoch 13: Validation AUROC = 0.7057\n","Epoch 14 Batch 0: Train Loss = 12.2759\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14 Batch 50: Train Loss = 12.5544\n","Epoch 14: Train Loss = 12.5966\n","Epoch 14: Validation Loss = 0.4051\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7082518138094074\n","AUC of PRC = 0.2751050012344543\n","min(+P, Se) = 0.32413793103448274\n","f1_score = nan\n","Epoch 14: Validation AUROC = 0.7083\n","Epoch 15 Batch 0: Train Loss = 10.8814\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15 Batch 50: Train Loss = 11.5991\n","Epoch 15: Train Loss = 11.5744\n","Epoch 15: Validation Loss = 0.4109\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7174737099535338\n","AUC of PRC = 0.28198652732112095\n","min(+P, Se) = 0.30669546436285094\n","f1_score = nan\n","Epoch 15: Validation AUROC = 0.7175\n","Epoch 16 Batch 0: Train Loss = 9.7679\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16 Batch 50: Train Loss = 11.0991\n","Epoch 16: Train Loss = 10.9932\n","Epoch 16: Validation Loss = 0.4177\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7021972908344881\n","AUC of PRC = 0.2667616381130564\n","min(+P, Se) = 0.30344827586206896\n","f1_score = nan\n","Epoch 16: Validation AUROC = 0.7022\n","Epoch 17 Batch 0: Train Loss = 10.0015\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17 Batch 50: Train Loss = 11.8901\n","Epoch 17: Train Loss = 11.5704\n","Epoch 17: Validation Loss = 0.4173\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6992574930029075\n","AUC of PRC = 0.2651940892555986\n","min(+P, Se) = 0.31724137931034485\n","f1_score = nan\n","Epoch 17: Validation AUROC = 0.6993\n","Epoch 18 Batch 0: Train Loss = 8.8172\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18 Batch 50: Train Loss = 8.5979\n","Epoch 18: Train Loss = 8.5926\n","Epoch 18: Validation Loss = 0.4122\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6749553340941822\n","AUC of PRC = 0.23896219747095268\n","min(+P, Se) = 0.2838709677419355\n","f1_score = nan\n","Epoch 18: Validation AUROC = 0.6750\n","Epoch 19 Batch 0: Train Loss = 9.6038\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19 Batch 50: Train Loss = 8.6255\n","Epoch 19: Train Loss = 8.5276\n","Epoch 19: Validation Loss = 0.4071\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7026524415097416\n","AUC of PRC = 0.2694071360145183\n","min(+P, Se) = 0.319634703196347\n","f1_score = nan\n","Epoch 19: Validation AUROC = 0.7027\n","Epoch 20 Batch 0: Train Loss = 7.7497\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20 Batch 50: Train Loss = 7.3636\n","Epoch 20: Train Loss = 7.3652\n","Epoch 20: Validation Loss = 0.4063\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7103721705931905\n","AUC of PRC = 0.2698539053699631\n","min(+P, Se) = 0.3019271948608137\n","f1_score = nan\n","Epoch 20: Validation AUROC = 0.7104\n","Epoch 21 Batch 0: Train Loss = 5.7741\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21 Batch 50: Train Loss = 6.5523\n","Epoch 21: Train Loss = 6.5892\n","Epoch 21: Validation Loss = 0.3978\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7073066968288905\n","AUC of PRC = 0.26974857758355586\n","min(+P, Se) = 0.3173913043478261\n","f1_score = nan\n","Epoch 21: Validation AUROC = 0.7073\n","Epoch 22 Batch 0: Train Loss = 5.8558\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22 Batch 50: Train Loss = 5.9657\n","Epoch 22: Train Loss = 6.0758\n","Epoch 22: Validation Loss = 0.3997\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7037741841254314\n","AUC of PRC = 0.2654094839723768\n","min(+P, Se) = 0.3117782909930716\n","f1_score = nan\n","Epoch 22: Validation AUROC = 0.7038\n","Epoch 23 Batch 0: Train Loss = 5.3952\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23 Batch 50: Train Loss = 6.3054\n","Epoch 23: Train Loss = 6.2469\n","Epoch 23: Validation Loss = 0.4041\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7080713669465503\n","AUC of PRC = 0.26945579687518784\n","min(+P, Se) = 0.3212669683257919\n","f1_score = nan\n","Epoch 23: Validation AUROC = 0.7081\n","Epoch 24 Batch 0: Train Loss = 5.6607\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24 Batch 50: Train Loss = 5.7409\n","Epoch 24: Train Loss = 5.6954\n","Epoch 24: Validation Loss = 0.4017\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7123260916822912\n","AUC of PRC = 0.27051523024583674\n","min(+P, Se) = 0.3152804642166344\n","f1_score = nan\n","Epoch 24: Validation AUROC = 0.7123\n","Epoch 25 Batch 0: Train Loss = 5.6415\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25 Batch 50: Train Loss = 4.7567\n","Epoch 25: Train Loss = 4.8977\n","Epoch 25: Validation Loss = 0.3987\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7188875641966251\n","AUC of PRC = 0.2808016513869386\n","min(+P, Se) = 0.3235955056179775\n","f1_score = nan\n","Epoch 25: Validation AUROC = 0.7189\n","Epoch 26 Batch 0: Train Loss = 3.9846\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26 Batch 50: Train Loss = 4.4626\n","Epoch 26: Train Loss = 4.7259\n","Epoch 26: Validation Loss = 0.3975\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7176800562484715\n","AUC of PRC = 0.2813598550896223\n","min(+P, Se) = 0.3263888888888889\n","f1_score = nan\n","Epoch 26: Validation AUROC = 0.7177\n","Epoch 27 Batch 0: Train Loss = 4.2575\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27 Batch 50: Train Loss = 4.2361\n","Epoch 27: Train Loss = 4.3047\n","Epoch 27: Validation Loss = 0.3950\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7118756113964295\n","AUC of PRC = 0.2839628750224081\n","min(+P, Se) = 0.32666666666666666\n","f1_score = nan\n","Epoch 27: Validation AUROC = 0.7119\n","Epoch 28 Batch 0: Train Loss = 3.7676\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28 Batch 50: Train Loss = 4.1156\n","Epoch 28: Train Loss = 4.0982\n","Epoch 28: Validation Loss = 0.3898\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7157269843210782\n","AUC of PRC = 0.2819811422993491\n","min(+P, Se) = 0.32805429864253394\n","f1_score = nan\n","Epoch 28: Validation AUROC = 0.7157\n","Epoch 29 Batch 0: Train Loss = 3.7454\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29 Batch 50: Train Loss = 4.0918\n","Epoch 29: Train Loss = 4.0474\n","Epoch 29: Validation Loss = 0.3908\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7107088632102389\n","AUC of PRC = 0.2794026591117167\n","min(+P, Se) = 0.3257918552036199\n","f1_score = nan\n","Epoch 29: Validation AUROC = 0.7107\n","Epoch 30 Batch 0: Train Loss = 3.4064\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30 Batch 50: Train Loss = 3.7801\n","Epoch 30: Train Loss = 3.7518\n","Epoch 30: Validation Loss = 0.3918\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7157558558191354\n","AUC of PRC = 0.2739625844940883\n","min(+P, Se) = 0.3225806451612903\n","f1_score = nan\n","Epoch 30: Validation AUROC = 0.7158\n","Epoch 31 Batch 0: Train Loss = 3.7645\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31 Batch 50: Train Loss = 3.3276\n","Epoch 31: Train Loss = 3.3400\n","Epoch 31: Validation Loss = 0.3932\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7140643256976713\n","AUC of PRC = 0.27842167497002684\n","min(+P, Se) = 0.3201754385964912\n","f1_score = nan\n","Epoch 31: Validation AUROC = 0.7141\n","Epoch 32 Batch 0: Train Loss = 2.9894\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32 Batch 50: Train Loss = 3.0295\n","Epoch 32: Train Loss = 3.0420\n","Epoch 32: Validation Loss = 0.3963\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7147861131490991\n","AUC of PRC = 0.28577728722862183\n","min(+P, Se) = 0.3268398268398268\n","f1_score = nan\n","Epoch 32: Validation AUROC = 0.7148\n","Epoch 33 Batch 0: Train Loss = 3.2520\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33 Batch 50: Train Loss = 2.9473\n","Epoch 33: Train Loss = 2.9732\n","Epoch 33: Validation Loss = 0.3956\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7166109616586506\n","AUC of PRC = 0.28565199416867937\n","min(+P, Se) = 0.33640552995391704\n","f1_score = nan\n","Epoch 33: Validation AUROC = 0.7166\n","Epoch 34 Batch 0: Train Loss = 2.3470\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34 Batch 50: Train Loss = 3.2165\n","Epoch 34: Train Loss = 3.1700\n","Epoch 34: Validation Loss = 0.3878\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.708615255020244\n","AUC of PRC = 0.27690063786652713\n","min(+P, Se) = 0.315668202764977\n","f1_score = nan\n","Epoch 34: Validation AUROC = 0.7086\n","Epoch 35 Batch 0: Train Loss = 2.5123\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35 Batch 50: Train Loss = 2.6769\n","Epoch 35: Train Loss = 2.6607\n","Epoch 35: Validation Loss = 0.3965\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7041270108149236\n","AUC of PRC = 0.27453292970834814\n","min(+P, Se) = 0.3210412147505423\n","f1_score = nan\n","Epoch 35: Validation AUROC = 0.7041\n","Epoch 36 Batch 0: Train Loss = 2.1071\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36 Batch 50: Train Loss = 2.4034\n","Epoch 36: Train Loss = 2.4374\n","Epoch 36: Validation Loss = 0.3875\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7132007282410803\n","AUC of PRC = 0.2885693446099392\n","min(+P, Se) = 0.3306288032454361\n","f1_score = nan\n","Epoch 36: Validation AUROC = 0.7132\n","Epoch 37 Batch 0: Train Loss = 2.2128\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37 Batch 50: Train Loss = 2.2146\n","Epoch 37: Train Loss = 2.2516\n","Epoch 37: Validation Loss = 0.3930\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7201290386130812\n","AUC of PRC = 0.2923019804662313\n","min(+P, Se) = 0.34174311926605505\n","f1_score = nan\n","Epoch 37: Validation AUROC = 0.7201\n","\n","------------ Save best model ------------\n","\n","Epoch 38 Batch 0: Train Loss = 1.8740\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38 Batch 50: Train Loss = 2.5144\n","Epoch 38: Train Loss = 2.5019\n","Epoch 38: Validation Loss = 0.3912\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7134699125023776\n","AUC of PRC = 0.2826237547798701\n","min(+P, Se) = 0.3310657596371882\n","f1_score = nan\n","Epoch 38: Validation AUROC = 0.7135\n","Epoch 39 Batch 0: Train Loss = 2.1487\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39 Batch 50: Train Loss = 3.4392\n","Epoch 39: Train Loss = 3.3183\n","Epoch 39: Validation Loss = 0.3918\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7063836580527703\n","AUC of PRC = 0.27402402543021387\n","min(+P, Se) = 0.325635103926097\n","f1_score = nan\n","Epoch 39: Validation AUROC = 0.7064\n","Epoch 40 Batch 0: Train Loss = 1.7143\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40 Batch 50: Train Loss = 2.6825\n","Epoch 40: Train Loss = 2.5979\n","Epoch 40: Validation Loss = 0.3993\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7139811078503302\n","AUC of PRC = 0.28558988543215014\n","min(+P, Se) = 0.3235294117647059\n","f1_score = nan\n","Epoch 40: Validation AUROC = 0.7140\n","Epoch 41 Batch 0: Train Loss = 1.9779\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41 Batch 50: Train Loss = 1.9341\n","Epoch 41: Train Loss = 1.9293\n","Epoch 41: Validation Loss = 0.3987\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.713139588598136\n","AUC of PRC = 0.283677863520901\n","min(+P, Se) = 0.3310344827586207\n","f1_score = nan\n","Epoch 41: Validation AUROC = 0.7131\n","Epoch 42 Batch 0: Train Loss = 1.7674\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42 Batch 50: Train Loss = 1.8209\n","Epoch 42: Train Loss = 1.8479\n","Epoch 42: Validation Loss = 0.3997\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7170211067634031\n","AUC of PRC = 0.28976701381225123\n","min(+P, Se) = 0.3259423503325942\n","f1_score = nan\n","Epoch 42: Validation AUROC = 0.7170\n","Epoch 43 Batch 0: Train Loss = 1.7935\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43 Batch 50: Train Loss = 1.9122\n","Epoch 43: Train Loss = 1.9088\n","Epoch 43: Validation Loss = 0.4003\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7180927488383467\n","AUC of PRC = 0.2929259323667645\n","min(+P, Se) = 0.3325842696629214\n","f1_score = nan\n","Epoch 43: Validation AUROC = 0.7181\n","Epoch 44 Batch 0: Train Loss = 1.6801\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44 Batch 50: Train Loss = 1.6529\n","Epoch 44: Train Loss = 1.6508\n","Epoch 44: Validation Loss = 0.3946\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7119150974158311\n","AUC of PRC = 0.28909813275219987\n","min(+P, Se) = 0.32407407407407407\n","f1_score = nan\n","Epoch 44: Validation AUROC = 0.7119\n","Epoch 45 Batch 0: Train Loss = 1.4527\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45 Batch 50: Train Loss = 1.6963\n","Epoch 45: Train Loss = 1.6890\n","Epoch 45: Validation Loss = 0.3955\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7192773294203962\n","AUC of PRC = 0.2906137703191255\n","min(+P, Se) = 0.3348729792147806\n","f1_score = nan\n","Epoch 45: Validation AUROC = 0.7193\n","Epoch 46 Batch 0: Train Loss = 1.4050\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46 Batch 50: Train Loss = 1.5599\n","Epoch 46: Train Loss = 1.5608\n","Epoch 46: Validation Loss = 0.4020\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7246499755441429\n","AUC of PRC = 0.2871079737469503\n","min(+P, Se) = 0.32432432432432434\n","f1_score = nan\n","Epoch 46: Validation AUROC = 0.7246\n","\n","------------ Save best model ------------\n","\n","Epoch 47 Batch 0: Train Loss = 1.6708\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47 Batch 50: Train Loss = 1.4700\n","Epoch 47: Train Loss = 1.4621\n","Epoch 47: Validation Loss = 0.3964\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7198641001603218\n","AUC of PRC = 0.29607537375470405\n","min(+P, Se) = 0.3394495412844037\n","f1_score = nan\n","Epoch 47: Validation AUROC = 0.7199\n","Epoch 48 Batch 0: Train Loss = 1.5189\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48 Batch 50: Train Loss = 1.4791\n","Epoch 48: Train Loss = 1.4813\n","Epoch 48: Validation Loss = 0.4005\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7142791636096845\n","AUC of PRC = 0.28874476447118785\n","min(+P, Se) = 0.32671081677704195\n","f1_score = nan\n","Epoch 48: Validation AUROC = 0.7143\n","Epoch 49 Batch 0: Train Loss = 1.3781\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49 Batch 50: Train Loss = 1.5307\n","Epoch 49: Train Loss = 1.5169\n","Epoch 49: Validation Loss = 0.3886\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7141989178283199\n","AUC of PRC = 0.28601958070047356\n","min(+P, Se) = 0.31724137931034485\n","f1_score = nan\n","Epoch 49: Validation AUROC = 0.7142\n","Epoch 50 Batch 0: Train Loss = 1.2628\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50 Batch 50: Train Loss = 1.2827\n","Epoch 50: Train Loss = 1.2901\n","Epoch 50: Validation Loss = 0.3995\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7152624928670416\n","AUC of PRC = 0.27835906165001933\n","min(+P, Se) = 0.32175925925925924\n","f1_score = nan\n","Epoch 50: Validation AUROC = 0.7153\n","Epoch 51 Batch 0: Train Loss = 1.0778\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51 Batch 50: Train Loss = 1.3210\n","Epoch 51: Train Loss = 1.3208\n","Epoch 51: Validation Loss = 0.3980\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7116544047716095\n","AUC of PRC = 0.27650663915891527\n","min(+P, Se) = 0.3108910891089109\n","f1_score = nan\n","Epoch 51: Validation AUROC = 0.7117\n","Epoch 52 Batch 0: Train Loss = 1.1542\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52 Batch 50: Train Loss = 1.2501\n","Epoch 52: Train Loss = 1.2467\n","Epoch 52: Validation Loss = 0.3907\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7085507187304694\n","AUC of PRC = 0.2782367826495999\n","min(+P, Se) = 0.3225108225108225\n","f1_score = nan\n","Epoch 52: Validation AUROC = 0.7086\n","Epoch 53 Batch 0: Train Loss = 1.3081\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53 Batch 50: Train Loss = 1.1949\n","Epoch 53: Train Loss = 1.1918\n","Epoch 53: Validation Loss = 0.4067\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7133607952229559\n","AUC of PRC = 0.2832763849250959\n","min(+P, Se) = 0.3150684931506849\n","f1_score = nan\n","Epoch 53: Validation AUROC = 0.7134\n","Epoch 54 Batch 0: Train Loss = 1.0763\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54 Batch 50: Train Loss = 1.1950\n","Epoch 54: Train Loss = 1.2065\n","Epoch 54: Validation Loss = 0.3967\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7142952976821282\n","AUC of PRC = 0.28292410494554654\n","min(+P, Se) = 0.3227176220806794\n","f1_score = nan\n","Epoch 54: Validation AUROC = 0.7143\n","Epoch 55 Batch 0: Train Loss = 1.0284\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55 Batch 50: Train Loss = 1.0979\n","Epoch 55: Train Loss = 1.1475\n","Epoch 55: Validation Loss = 0.3904\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7118140471726311\n","AUC of PRC = 0.2839473759488061\n","min(+P, Se) = 0.32608695652173914\n","f1_score = nan\n","Epoch 55: Validation AUROC = 0.7118\n","Epoch 56 Batch 0: Train Loss = 1.5400\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56 Batch 50: Train Loss = 1.1760\n","Epoch 56: Train Loss = 1.1676\n","Epoch 56: Validation Loss = 0.3938\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7143708730741013\n","AUC of PRC = 0.28112040168399005\n","min(+P, Se) = 0.33181818181818185\n","f1_score = nan\n","Epoch 56: Validation AUROC = 0.7144\n","Epoch 57 Batch 0: Train Loss = 0.9605\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57 Batch 50: Train Loss = 1.1286\n","Epoch 57: Train Loss = 1.1304\n","Epoch 57: Validation Loss = 0.3896\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7159163473818646\n","AUC of PRC = 0.28341188001266293\n","min(+P, Se) = 0.3181818181818182\n","f1_score = nan\n","Epoch 57: Validation AUROC = 0.7159\n","Epoch 58 Batch 0: Train Loss = 1.4955\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58 Batch 50: Train Loss = 1.1596\n","Epoch 58: Train Loss = 1.1457\n","Epoch 58: Validation Loss = 0.4014\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7167625370234504\n","AUC of PRC = 0.2888429741377613\n","min(+P, Se) = 0.3325942350332594\n","f1_score = nan\n","Epoch 58: Validation AUROC = 0.7168\n","Epoch 59 Batch 0: Train Loss = 1.0053\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59 Batch 50: Train Loss = 1.0019\n","Epoch 59: Train Loss = 1.0787\n","Epoch 59: Validation Loss = 0.3950\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7185292179560339\n","AUC of PRC = 0.2907797997315183\n","min(+P, Se) = 0.3425925925925926\n","f1_score = nan\n","Epoch 59: Validation AUROC = 0.7185\n","Epoch 60 Batch 0: Train Loss = 0.9736\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60 Batch 50: Train Loss = 0.9725\n","Epoch 60: Train Loss = 0.9873\n","Epoch 60: Validation Loss = 0.4037\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7165659560881499\n","AUC of PRC = 0.2842270737142623\n","min(+P, Se) = 0.3235294117647059\n","f1_score = nan\n","Epoch 60: Validation AUROC = 0.7166\n","Epoch 61 Batch 0: Train Loss = 0.8395\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61 Batch 50: Train Loss = 0.9290\n","Epoch 61: Train Loss = 0.9392\n","Epoch 61: Validation Loss = 0.4009\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7175747601967337\n","AUC of PRC = 0.287393306800522\n","min(+P, Se) = 0.32450331125827814\n","f1_score = nan\n","Epoch 61: Validation AUROC = 0.7176\n","Epoch 62 Batch 0: Train Loss = 6.1061\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62 Batch 50: Train Loss = 1.0859\n","Epoch 62: Train Loss = 1.0719\n","Epoch 62: Validation Loss = 0.3972\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7227537974511562\n","AUC of PRC = 0.2968553174478587\n","min(+P, Se) = 0.34375\n","f1_score = nan\n","Epoch 62: Validation AUROC = 0.7228\n","Epoch 63 Batch 0: Train Loss = 0.9038\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63 Batch 50: Train Loss = 1.1798\n","Epoch 63: Train Loss = 1.1500\n","Epoch 63: Validation Loss = 0.3992\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7218375519686965\n","AUC of PRC = 0.2914658410875637\n","min(+P, Se) = 0.3387096774193548\n","f1_score = nan\n","Epoch 63: Validation AUROC = 0.7218\n","Epoch 64 Batch 0: Train Loss = 0.7994\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64 Batch 50: Train Loss = 0.8642\n","Epoch 64: Train Loss = 0.8667\n","Epoch 64: Validation Loss = 0.3973\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7188400111410016\n","AUC of PRC = 0.2830714018603978\n","min(+P, Se) = 0.3227176220806794\n","f1_score = nan\n","Epoch 64: Validation AUROC = 0.7188\n","Epoch 65 Batch 0: Train Loss = 0.8664\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65 Batch 50: Train Loss = 0.9353\n","Epoch 65: Train Loss = 0.9257\n","Epoch 65: Validation Loss = 0.4063\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7292031806200919\n","AUC of PRC = 0.2988195868362126\n","min(+P, Se) = 0.3394919168591224\n","f1_score = nan\n","Epoch 65: Validation AUROC = 0.7292\n","\n","------------ Save best model ------------\n","\n","Epoch 66 Batch 0: Train Loss = 0.9678\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66 Batch 50: Train Loss = 0.8599\n","Epoch 66: Train Loss = 0.8622\n","Epoch 66: Validation Loss = 0.3882\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7326448330208418\n","AUC of PRC = 0.3078026051105919\n","min(+P, Se) = 0.352549889135255\n","f1_score = nan\n","Epoch 66: Validation AUROC = 0.7326\n","\n","------------ Save best model ------------\n","\n","Epoch 67 Batch 0: Train Loss = 0.7732\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67 Batch 50: Train Loss = 0.8500\n","Epoch 67: Train Loss = 0.8447\n","Epoch 67: Validation Loss = 0.4004\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7335780617374528\n","AUC of PRC = 0.2959148440511451\n","min(+P, Se) = 0.33712984054669703\n","f1_score = nan\n","Epoch 67: Validation AUROC = 0.7336\n","\n","------------ Save best model ------------\n","\n","Epoch 68 Batch 0: Train Loss = 0.7553\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68 Batch 50: Train Loss = 0.8308\n","Epoch 68: Train Loss = 0.8219\n","Epoch 68: Validation Loss = 0.3902\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7322503974076792\n","AUC of PRC = 0.30332076229187954\n","min(+P, Se) = 0.35697940503432496\n","f1_score = nan\n","Epoch 68: Validation AUROC = 0.7323\n","Epoch 69 Batch 0: Train Loss = 0.7775\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69 Batch 50: Train Loss = 0.8394\n","Epoch 69: Train Loss = 0.8275\n","Epoch 69: Validation Loss = 0.3933\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7293619738594062\n","AUC of PRC = 0.30132230598092413\n","min(+P, Se) = 0.3415730337078652\n","f1_score = nan\n","Epoch 69: Validation AUROC = 0.7294\n","Epoch 70 Batch 0: Train Loss = 0.7453\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70 Batch 50: Train Loss = 0.7544\n","Epoch 70: Train Loss = 0.7758\n","Epoch 70: Validation Loss = 0.3885\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7343958044618353\n","AUC of PRC = 0.30666604681953014\n","min(+P, Se) = 0.3408662900188324\n","f1_score = nan\n","Epoch 70: Validation AUROC = 0.7344\n","\n","------------ Save best model ------------\n","\n","Epoch 71 Batch 0: Train Loss = 0.7495\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71 Batch 50: Train Loss = 0.7990\n","Epoch 71: Train Loss = 0.7987\n","Epoch 71: Validation Loss = 0.3988\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7261954498519063\n","AUC of PRC = 0.2894282003193389\n","min(+P, Se) = 0.33564814814814814\n","f1_score = nan\n","Epoch 71: Validation AUROC = 0.7262\n","Epoch 72 Batch 0: Train Loss = 0.6879\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72 Batch 50: Train Loss = 0.8544\n","Epoch 72: Train Loss = 0.8380\n","Epoch 72: Validation Loss = 0.3891\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.727464522023858\n","AUC of PRC = 0.3020776499013564\n","min(+P, Se) = 0.3462414578587699\n","f1_score = nan\n","Epoch 72: Validation AUROC = 0.7275\n","Epoch 73 Batch 0: Train Loss = 0.7250\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73 Batch 50: Train Loss = 0.7419\n","Epoch 73: Train Loss = 0.7522\n","Epoch 73: Validation Loss = 0.3975\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7286741528762805\n","AUC of PRC = 0.2985923042805515\n","min(+P, Se) = 0.3449074074074074\n","f1_score = nan\n","Epoch 73: Validation AUROC = 0.7287\n","Epoch 74 Batch 0: Train Loss = 0.6189\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74 Batch 50: Train Loss = 0.6773\n","Epoch 74: Train Loss = 0.7038\n","Epoch 74: Validation Loss = 0.3942\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7322096376457162\n","AUC of PRC = 0.30058174025777484\n","min(+P, Se) = 0.3448275862068966\n","f1_score = nan\n","Epoch 74: Validation AUROC = 0.7322\n","Epoch 75 Batch 0: Train Loss = 0.7502\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75 Batch 50: Train Loss = 0.6807\n","Epoch 75: Train Loss = 0.7004\n","Epoch 75: Validation Loss = 0.3991\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7331848998668514\n","AUC of PRC = 0.3035804662784578\n","min(+P, Se) = 0.34953703703703703\n","f1_score = nan\n","Epoch 75: Validation AUROC = 0.7332\n","Epoch 76 Batch 0: Train Loss = 0.7336\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76 Batch 50: Train Loss = 0.6683\n","Epoch 76: Train Loss = 0.6688\n","Epoch 76: Validation Loss = 0.3929\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7310369453275726\n","AUC of PRC = 0.30321616320750966\n","min(+P, Se) = 0.3541666666666667\n","f1_score = nan\n","Epoch 76: Validation AUROC = 0.7310\n","Epoch 77 Batch 0: Train Loss = 0.6491\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77 Batch 50: Train Loss = 0.6743\n","Epoch 77: Train Loss = 0.6786\n","Epoch 77: Validation Loss = 0.4064\n","confusion matrix:\n","[[2724    2]\n"," [ 432    0]]\n","accuracy = 0.8625712394714355\n","precision class 0 = 0.8631178736686707\n","precision class 1 = 0.0\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.0\n","AUC of ROC = 0.7271927902774382\n","AUC of PRC = 0.28815452688162707\n","min(+P, Se) = 0.3470319634703196\n","f1_score = nan\n","Epoch 77: Validation AUROC = 0.7272\n","Epoch 78 Batch 0: Train Loss = 1.7261\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78 Batch 50: Train Loss = 0.6691\n","Epoch 78: Train Loss = 0.6717\n","Epoch 78: Validation Loss = 0.4088\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7332655702290699\n","AUC of PRC = 0.29422775684571145\n","min(+P, Se) = 0.3425531914893617\n","f1_score = nan\n","Epoch 78: Validation AUROC = 0.7333\n","Epoch 79 Batch 0: Train Loss = 0.6201\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79 Batch 50: Train Loss = 0.6307\n","Epoch 79: Train Loss = 0.6431\n","Epoch 79: Validation Loss = 0.3911\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7339202739056003\n","AUC of PRC = 0.30452673444396583\n","min(+P, Se) = 0.3587962962962963\n","f1_score = nan\n","Epoch 79: Validation AUROC = 0.7339\n","Epoch 80 Batch 0: Train Loss = 0.5528\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80 Batch 50: Train Loss = 3.4143\n","Epoch 80: Train Loss = 3.1219\n","Epoch 80: Validation Loss = 0.3936\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7359208988886171\n","AUC of PRC = 0.3026812896446608\n","min(+P, Se) = 0.3524027459954233\n","f1_score = nan\n","Epoch 80: Validation AUROC = 0.7359\n","\n","------------ Save best model ------------\n","\n","Epoch 81 Batch 0: Train Loss = 0.7050\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81 Batch 50: Train Loss = 0.7207\n","Epoch 81: Train Loss = 0.7175\n","Epoch 81: Validation Loss = 0.4030\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.732299224205864\n","AUC of PRC = 0.30068585566167966\n","min(+P, Se) = 0.3443708609271523\n","f1_score = nan\n","Epoch 81: Validation AUROC = 0.7323\n","Epoch 82 Batch 0: Train Loss = 0.6455\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82 Batch 50: Train Loss = 0.6475\n","Epoch 82: Train Loss = 0.6556\n","Epoch 82: Validation Loss = 0.3972\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7337062851552947\n","AUC of PRC = 0.3048184979731021\n","min(+P, Se) = 0.3490990990990991\n","f1_score = nan\n","Epoch 82: Validation AUROC = 0.7337\n","Epoch 83 Batch 0: Train Loss = 0.5670\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83 Batch 50: Train Loss = 0.6190\n","Epoch 83: Train Loss = 0.6304\n","Epoch 83: Validation Loss = 0.3909\n","confusion matrix:\n","[[2724    2]\n"," [ 432    0]]\n","accuracy = 0.8625712394714355\n","precision class 0 = 0.8631178736686707\n","precision class 1 = 0.0\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.0\n","AUC of ROC = 0.7365764517268552\n","AUC of PRC = 0.3034442756008367\n","min(+P, Se) = 0.3482142857142857\n","f1_score = nan\n","Epoch 83: Validation AUROC = 0.7366\n","\n","------------ Save best model ------------\n","\n","Epoch 84 Batch 0: Train Loss = 0.6694\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84 Batch 50: Train Loss = 0.6535\n","Epoch 84: Train Loss = 0.6496\n","Epoch 84: Validation Loss = 0.3937\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7386382163528165\n","AUC of PRC = 0.3039105791916738\n","min(+P, Se) = 0.3434125269978402\n","f1_score = nan\n","Epoch 84: Validation AUROC = 0.7386\n","\n","------------ Save best model ------------\n","\n","Epoch 85 Batch 0: Train Loss = 0.6978\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85 Batch 50: Train Loss = 0.7264\n","Epoch 85: Train Loss = 0.7153\n","Epoch 85: Validation Loss = 0.3921\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7399026181353767\n","AUC of PRC = 0.31274256088842023\n","min(+P, Se) = 0.36384439359267734\n","f1_score = nan\n","Epoch 85: Validation AUROC = 0.7399\n","\n","------------ Save best model ------------\n","\n","Epoch 86 Batch 0: Train Loss = 0.5669\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86 Batch 50: Train Loss = 0.6218\n","Epoch 86: Train Loss = 0.6363\n","Epoch 86: Validation Loss = 0.3937\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7312785318333741\n","AUC of PRC = 0.3004290001655932\n","min(+P, Se) = 0.33564814814814814\n","f1_score = nan\n","Epoch 86: Validation AUROC = 0.7313\n","Epoch 87 Batch 0: Train Loss = 0.4925\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87 Batch 50: Train Loss = 0.5877\n","Epoch 87: Train Loss = 0.5911\n","Epoch 87: Validation Loss = 0.4040\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7319773919186978\n","AUC of PRC = 0.30623252347804064\n","min(+P, Se) = 0.35185185185185186\n","f1_score = nan\n","Epoch 87: Validation AUROC = 0.7320\n","Epoch 88 Batch 0: Train Loss = 0.5838\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88 Batch 50: Train Loss = 0.5772\n","Epoch 88: Train Loss = 0.5739\n","Epoch 88: Validation Loss = 0.3991\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7346649887231326\n","AUC of PRC = 0.2950310933334371\n","min(+P, Se) = 0.33640552995391704\n","f1_score = nan\n","Epoch 88: Validation AUROC = 0.7347\n","Epoch 89 Batch 0: Train Loss = 0.5037\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89 Batch 50: Train Loss = 0.5794\n","Epoch 89: Train Loss = 0.5764\n","Epoch 89: Validation Loss = 0.4003\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7325518498138637\n","AUC of PRC = 0.2972455622038098\n","min(+P, Se) = 0.3434125269978402\n","f1_score = nan\n","Epoch 89: Validation AUROC = 0.7326\n","Epoch 90 Batch 0: Train Loss = 0.5512\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90 Batch 50: Train Loss = 0.5637\n","Epoch 90: Train Loss = 0.5618\n","Epoch 90: Validation Loss = 0.4052\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7354767873155621\n","AUC of PRC = 0.3074888185851571\n","min(+P, Se) = 0.3425925925925926\n","f1_score = nan\n","Epoch 90: Validation AUROC = 0.7355\n","Epoch 91 Batch 0: Train Loss = 0.6108\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91 Batch 50: Train Loss = 0.5513\n","Epoch 91: Train Loss = 0.5534\n","Epoch 91: Validation Loss = 0.4006\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7297347558490258\n","AUC of PRC = 0.295808609220441\n","min(+P, Se) = 0.3472222222222222\n","f1_score = nan\n","Epoch 91: Validation AUROC = 0.7297\n","Epoch 92 Batch 0: Train Loss = 0.5386\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92 Batch 50: Train Loss = 0.5862\n","Epoch 92: Train Loss = 0.5873\n","Epoch 92: Validation Loss = 0.4017\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7380879595663161\n","AUC of PRC = 0.3048542001080504\n","min(+P, Se) = 0.34459459459459457\n","f1_score = nan\n","Epoch 92: Validation AUROC = 0.7381\n","Epoch 93 Batch 0: Train Loss = 0.5745\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93 Batch 50: Train Loss = 0.5298\n","Epoch 93: Train Loss = 0.7595\n","Epoch 93: Validation Loss = 0.4063\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7334281846960681\n","AUC of PRC = 0.3086284342757897\n","min(+P, Se) = 0.35402298850574715\n","f1_score = nan\n","Epoch 93: Validation AUROC = 0.7334\n","Epoch 94 Batch 0: Train Loss = 0.5429\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94 Batch 50: Train Loss = 0.5756\n","Epoch 94: Train Loss = 0.5717\n","Epoch 94: Validation Loss = 0.4132\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7395578584821065\n","AUC of PRC = 0.3169062278710024\n","min(+P, Se) = 0.3659090909090909\n","f1_score = nan\n","Epoch 94: Validation AUROC = 0.7396\n","Epoch 95 Batch 0: Train Loss = 0.4721\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95 Batch 50: Train Loss = 0.5219\n","Epoch 95: Train Loss = 0.5220\n","Epoch 95: Validation Loss = 0.4014\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7372095017798429\n","AUC of PRC = 0.307695213919639\n","min(+P, Se) = 0.3471615720524017\n","f1_score = nan\n","Epoch 95: Validation AUROC = 0.7372\n","Epoch 96 Batch 0: Train Loss = 0.4585\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96 Batch 50: Train Loss = 0.5274\n","Epoch 96: Train Loss = 0.5240\n","Epoch 96: Validation Loss = 0.3951\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7262311146436237\n","AUC of PRC = 0.29344212645471773\n","min(+P, Se) = 0.3378684807256236\n","f1_score = nan\n","Epoch 96: Validation AUROC = 0.7262\n","Epoch 97 Batch 0: Train Loss = 0.5317\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97 Batch 50: Train Loss = 0.5153\n","Epoch 97: Train Loss = 0.5158\n","Epoch 97: Validation Loss = 0.4039\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7392844284122715\n","AUC of PRC = 0.32007892290418916\n","min(+P, Se) = 0.3623853211009174\n","f1_score = nan\n","Epoch 97: Validation AUROC = 0.7393\n","Epoch 98 Batch 0: Train Loss = 0.5834\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98 Batch 50: Train Loss = 0.5135\n","Epoch 98: Train Loss = 0.5090\n","Epoch 98: Validation Loss = 0.3977\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7309516045759626\n","AUC of PRC = 0.30795859642239154\n","min(+P, Se) = 0.36574074074074076\n","f1_score = nan\n","Epoch 98: Validation AUROC = 0.7310\n","Epoch 99 Batch 0: Train Loss = 0.4161\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99 Batch 50: Train Loss = 0.5048\n","Epoch 99: Train Loss = 0.5080\n","Epoch 99: Validation Loss = 0.4063\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7356491671421973\n","AUC of PRC = 0.30679570830666325\n","min(+P, Se) = 0.3541666666666667\n","f1_score = nan\n","Epoch 99: Validation AUROC = 0.7356\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"VW54dKU77CQS"}},{"cell_type":"code","source":["file_name = 'model/concare_pe'\n","BATCH_SIZE = 256\n","\n","checkpoint = torch.load(file_name)\n","save_epoch = checkpoint['epoch']\n","model.load_state_dict(checkpoint['net'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","model.eval()\n","\n","# test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'test'),\n","#                                             listfile=os.path.join(data_path, 'test_listfile.csv'),\n","#                                             period_length=48.0)\n","# test_raw = utils.load_data(test_reader, discretizer, normalizer, return_names=True)\n","# test_dataset = Dataset(test_raw['data'][0], test_raw['data'][1], test_raw['names'])\n","# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_7wrGfxQ69Jf","executionInfo":{"status":"ok","timestamp":1682989137977,"user_tz":300,"elapsed":23,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"5b748e45-dac3-4e06-94fb-5b70f21b76ef"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConCare_PE(\n","  (demo_embed): DemographicEmbed(\n","    (fc): Linear(in_features=12, out_features=64, bias=True)\n","  )\n","  (gru): GRU(76, 64, batch_first=True)\n","  (pos_encoder): PositionalEncoding(\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (time_attns): TimeAwareSelfAttention()\n","  (multi_attn): MultiHeadAttention(\n","    (w_qs): Linear(in_features=64, out_features=64, bias=False)\n","    (w_ks): Linear(in_features=64, out_features=64, bias=False)\n","    (w_vs): Linear(in_features=64, out_features=64, bias=False)\n","    (fc): Linear(in_features=64, out_features=64, bias=False)\n","    (attn): ScaledDotProductAttention(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_attn): FinalAttention(\n","    (w_qs): Linear(in_features=64, out_features=64, bias=True)\n","    (w_ks): Linear(in_features=64, out_features=64, bias=True)\n","    (w_vs): Linear(in_features=64, out_features=64, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (res): ResConnect(\n","    (lnorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (pos_ff): PositionwiseFeedForward(\n","    (fc1): Linear(in_features=64, out_features=256, bias=True)\n","    (fc2): Linear(in_features=256, out_features=64, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (output_fc1): Linear(in_features=64, out_features=64, bias=True)\n","  (output_fc2): Linear(in_features=64, out_features=1, bias=True)\n","  (dp): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["batch_loss = []\n","y_true = []\n","y_pred = []\n","with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(test_loader):\n","        batch_x = batch_x.float().to(device)\n","        batch_y = batch_y.float().to(device)\n","        batch_demo = []\n","        for i in range(len(batch_name)):\n","            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","            cur_idx = cur_id + '_' + cur_ep\n","            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","            batch_demo.append(cur_demo)\n","\n","        batch_demo = torch.stack(batch_demo).to(device)\n","        output = model(batch_x, batch_demo)[0]\n","\n","        loss = loss_func(output, batch_y.unsqueeze(-1))\n","        batch_loss.append(loss.cpu().detach().numpy())\n","        y_pred += list(output.cpu().detach().numpy().flatten())\n","        y_true += list(batch_y.cpu().numpy().flatten())\n","\n","print(\"\\nTest Prediction Result\")\n","y_pred = np.array(y_pred)\n","y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","test_res = metrics.print_metrics_binary(y_true, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxIu1-Kl7Iv1","executionInfo":{"status":"ok","timestamp":1682989139418,"user_tz":300,"elapsed":1456,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"4fa3cb6a-0baf-42c6-8c22-677491b31ffb"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Prediction Result\n","confusion matrix:\n","[[2862    0]\n"," [ 374    0]]\n","accuracy = 0.8844252228736877\n","precision class 0 = 0.8844252228736877\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7423532401334842\n","AUC of PRC = 0.28678337166738826\n","min(+P, Se) = 0.33066666666666666\n","f1_score = nan\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]}]},{"cell_type":"markdown","source":["## ConCare without decorrelation loss"],"metadata":{"id":"3XAtVeyy7XyZ"}},{"cell_type":"code","source":["class MultiHeadAttentionNoDecov(nn.Module):\n","  def __init__(self, n_head, d_model):\n","    super().__init__()\n","    self.n_head = n_head\n","    self.d_model = d_model\n","\n","    self.w_qs = nn.Linear(self.d_model, self.d_model, bias=False)\n","    self.w_ks = nn.Linear(self.d_model, self.d_model, bias=False)\n","    self.w_vs = nn.Linear(self.d_model, self.d_model, bias=False)\n","    self.fc = nn.Linear(self.d_model, self.d_model, bias=False)\n","\n","    self.attn = ScaledDotProductAttention()\n","\n","    # self.dropout = nn.Dropout(dropout)\n","    # self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n","\n","  def forward(self, q, k, v):\n","    b, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1)\n","    q = self.w_qs(q).view(b, len_q, self.n_head, self.d_model // self.n_head)\n","    k = self.w_ks(k).view(b, len_k, self.n_head, self.d_model // self.n_head)\n","    v = self.w_vs(v).view(b, len_v, self.n_head, self.d_model // self.n_head)\n","    q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2) # B*num_heads*d_input*d_k\n","\n","    q, attn = self.attn(q, k, v)\n","\n","    q = q.transpose(1, 2).contiguous().view(b, len_q, self.d_model) # B*d_input*d_model\n","    output_q = self.fc(q)\n","\n","    return output_q"],"metadata":{"id":"xTKhsXrc7c9x","executionInfo":{"status":"ok","timestamp":1682989139418,"user_tz":300,"elapsed":4,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["class ConCare_NoDecov(nn.Module):\n","  def __init__(self, demo_input_dim, input_dim, hidden_dim1, hidden_dim2, d_model, n_head, ff_hidden, output_dim, dropout=0.5):\n","    super().__init__()\n","    self.demo_input_dim = demo_input_dim\n","    self.input_dim = input_dim\n","    self.hidden_dim1 = hidden_dim1\n","    self.hidden_dim2 = hidden_dim2\n","    self.d_model = d_model\n","    self.n_head = n_head\n","    self.ff_hidden = ff_hidden\n","    self.output_dim = output_dim\n","    self.dropout = dropout\n","\n","    self.demo_embed = DemographicEmbed(self.demo_input_dim, self.hidden_dim1)\n","    self.grus = nn.ModuleList([copy.deepcopy(nn.GRU(1, self.hidden_dim1, batch_first=True)) for _ in range(self.input_dim)])\n","    self.time_attns = nn.ModuleList([copy.deepcopy(TimeAwareSelfAttention(self.hidden_dim1, self.hidden_dim2)) for _ in range(self.input_dim)])\n","    self.multi_attn = MultiHeadAttentionNoDecov(self.n_head, self.d_model)\n","    self.final_attn = FinalAttention(self.hidden_dim1, self.hidden_dim1, dropout=self.dropout)\n","    self.res = ResConnect(self.d_model, dropout=self.dropout)\n","    self.pos_ff = PositionwiseFeedForward(self.d_model, self.ff_hidden, dropout=0.1)\n","    self.output_fc1 = nn.Linear(self.hidden_dim1, self.hidden_dim1)\n","    self.output_fc2 = nn.Linear(self.hidden_dim1, self.output_dim)\n","    self.dp = nn.Dropout(self.dropout)\n","  \n","  def forward(self, input, demo):\n","    # Demographic embedding\n","    demo_embedding = self.demo_embed(demo)\n","\n","    # First record embedding\n","    batch_size = input.size(0)\n","    feat_dim = input.size(2)\n","    record_embedding1 = self.grus[0](input[:, :, 0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim1).unsqueeze(0)).to(device))[0] # B*1*H\n","    time_attn_output = self.time_attns[0](record_embedding1)[0].unsqueeze(1) # B*1*H\n","\n","    # All other records embeddings\n","    for i in range(1, feat_dim):\n","      embedding = self.grus[i](input[:, :, i].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim1).unsqueeze(0)).to(device))[0] # B*1*H\n","      attn = self.time_attns[i](embedding)[0].unsqueeze(1) # B*1*H\n","      time_attn_output = torch.cat((time_attn_output, attn), 1)\n","    \n","    # Combine with demographic embedding\n","    demo_embedding = demo_embedding.unsqueeze(1)\n","    time_attn_output = torch.cat((time_attn_output, demo_embedding), 1)\n","    time_attn_output = self.dp(time_attn_output)\n","\n","    # Get multi-head attention\n","    multi_attn_output = self.res(time_attn_output, lambda x: self.multi_attn(time_attn_output, time_attn_output, time_attn_output))[0]\n","    final_input = self.res(multi_attn_output, lambda x: self.pos_ff(multi_attn_output))[0]\n","\n","    # Get final output\n","    value, score = self.final_attn(final_input)\n","    output = F.sigmoid(self.output_fc2(F.relu(self.output_fc1(value))))\n","\n","    return output"],"metadata":{"id":"QYWY_cLI7uh5","executionInfo":{"status":"ok","timestamp":1682989139419,"user_tz":300,"elapsed":4,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"RoaAHHUb7_MC"}},{"cell_type":"code","source":["RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed(RANDOM_SEED)\n","torch.backends.cudnn.deterministic=True"],"metadata":{"id":"DR-oOa9l8Alt","executionInfo":{"status":"ok","timestamp":1682892662774,"user_tz":300,"elapsed":4,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["model = ConCare_NoDecov(demo_input_dim=12, input_dim=76, hidden_dim1=64, hidden_dim2=8, d_model=64, n_head=4, ff_hidden=256, output_dim=1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.BCELoss()"],"metadata":{"id":"Et9fyrq88Fqf","executionInfo":{"status":"ok","timestamp":1682989139777,"user_tz":300,"elapsed":361,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["max_roc = 0\n","max_prc = 0\n","train_total_loss = []\n","val_total_loss = []\n","result_history = []\n","file_name = 'model/concare_nodecov'\n","\n","\n","for epoch in range(100):\n","  \n","  # Start training\n","  train_batch_total_loss = []\n","  model.train()\n","\n","  for step, (batch_x, batch_y, batch_name) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","    batch_x = batch_x.float().to(device)\n","    batch_y = batch_y.float().to(device)\n","\n","    # Get batch demographic data\n","    batch_demo = []\n","    for i in range(len(batch_name)):\n","      cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","      cur_idx = cur_id + '_' + cur_ep\n","      cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","      batch_demo.append(cur_demo)\n","    batch_demo = torch.stack(batch_demo).to(device)\n","\n","    # Get model outputs\n","    output = model(batch_x, batch_demo)\n","\n","    # Get loss\n","    loss = loss_func(output, batch_y.unsqueeze(-1))\n","    train_batch_total_loss.append(loss.cpu().detach().numpy())\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    if step % 50 == 0:\n","      print('Epoch %d Batch %d: Train Loss = %.4f'%(epoch, step, np.mean(np.array(train_batch_total_loss))))\n","    \n","  train_total_loss.append(np.mean(np.array(train_batch_total_loss)))\n","  print('Epoch %d: Train Loss = %.4f'%(epoch, np.mean(np.array(train_batch_total_loss))))\n","\n","  # Start Validating\n","  val_batch_total_loss = []\n","  y_true = []\n","  y_pred = []\n","\n","  with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(val_loader):\n","      batch_x = batch_x.float().to(device)\n","      batch_y = batch_y.float().to(device)\n","\n","      # Get batch demographic data\n","      batch_demo = []\n","      for i in range(len(batch_name)):\n","        cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","        cur_idx = cur_id + '_' + cur_ep\n","        cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","        batch_demo.append(cur_demo)\n","      batch_demo = torch.stack(batch_demo).to(device)\n","\n","      # Get model outputs\n","      output = model(batch_x, batch_demo)\n","\n","      # Get loss\n","      loss = loss_func(output, batch_y.unsqueeze(-1))\n","      val_batch_total_loss.append(loss.cpu().detach().numpy())\n","      y_pred += list(output.cpu().detach().numpy())\n","      y_true += list(batch_y.cpu().numpy().flatten())\n","    \n","    val_total_loss.append(np.mean(np.array(val_batch_total_loss)))\n","    print('Epoch %d: Validation Loss = %.4f'%(epoch, np.mean(np.array(val_batch_total_loss))))\n","\n","    y_pred = np.array(y_pred)\n","    y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","    result = metrics.print_metrics_binary(y_true, y_pred)\n","    result_history.append(result)\n","\n","    cur_auroc = result['auroc']\n","    print('Epoch %d: Validation AUROC = %.4f'%(epoch, cur_auroc))\n","    \n","    if cur_auroc > max_roc:\n","        max_roc = cur_auroc\n","        state = {\n","            'net': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'epoch': epoch\n","        }\n","        torch.save(state, file_name)\n","        print('\\n------------ Save best model ------------\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4CYor9RP8Kqa","executionInfo":{"status":"ok","timestamp":1682990995708,"user_tz":300,"elapsed":1855939,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"027fca41-7b9b-48ac-f985-4733b0cb1186"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 Batch 0: Train Loss = 0.6862\n","Epoch 0 Batch 50: Train Loss = 0.4609\n","Epoch 0: Train Loss = 0.4550\n","Epoch 0: Validation Loss = 0.4004\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6381369561968424\n","AUC of PRC = 0.249524842608406\n","min(+P, Se) = 0.25968109339407747\n","f1_score = nan\n","Epoch 0: Validation AUROC = 0.6381\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0: Train Loss = 0.4196\n","Epoch 1 Batch 50: Train Loss = 0.3994\n","Epoch 1: Train Loss = 0.4001\n","Epoch 1: Validation Loss = 0.3975\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6792168521235837\n","AUC of PRC = 0.2930109001021881\n","min(+P, Se) = 0.3103448275862069\n","f1_score = nan\n","Epoch 1: Validation AUROC = 0.6792\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Batch 0: Train Loss = 0.6151\n","Epoch 2 Batch 50: Train Loss = 0.3987\n","Epoch 2: Train Loss = 0.3990\n","Epoch 2: Validation Loss = 0.4005\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7228922108094888\n","AUC of PRC = 0.32009897578421737\n","min(+P, Se) = 0.3668903803131991\n","f1_score = nan\n","Epoch 2: Validation AUROC = 0.7229\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Batch 0: Train Loss = 0.3970\n","Epoch 3 Batch 50: Train Loss = 0.3992\n","Epoch 3: Train Loss = 0.3972\n","Epoch 3: Validation Loss = 0.3944\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.742218706692753\n","AUC of PRC = 0.3396921138405819\n","min(+P, Se) = 0.3716216216216216\n","f1_score = nan\n","Epoch 3: Validation AUROC = 0.7422\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 Batch 0: Train Loss = 0.3595\n","Epoch 4 Batch 50: Train Loss = 0.3939\n","Epoch 4: Train Loss = 0.3943\n","Epoch 4: Validation Loss = 0.3913\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7454773647455232\n","AUC of PRC = 0.3440431315223151\n","min(+P, Se) = 0.38073394495412843\n","f1_score = nan\n","Epoch 4: Validation AUROC = 0.7455\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 Batch 0: Train Loss = 0.3648\n","Epoch 5 Batch 50: Train Loss = 0.3816\n","Epoch 5: Train Loss = 0.3813\n","Epoch 5: Validation Loss = 0.3526\n","confusion matrix:\n","[[2725    1]\n"," [ 430    2]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8637083768844604\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7573180755957718\n","AUC of PRC = 0.3541062463451312\n","min(+P, Se) = 0.3680555555555556\n","f1_score = 0.00919540261116663\n","Epoch 5: Validation AUROC = 0.7573\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 Batch 0: Train Loss = 0.3156\n","Epoch 6 Batch 50: Train Loss = 0.3654\n","Epoch 6: Train Loss = 0.3667\n","Epoch 6: Validation Loss = 0.3503\n","confusion matrix:\n","[[2724    2]\n"," [ 425    7]]\n","accuracy = 0.8647878170013428\n","precision class 0 = 0.8650365471839905\n","precision class 1 = 0.7777777910232544\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.016203703358769417\n","AUC of ROC = 0.7553667019917937\n","AUC of PRC = 0.36414257052033144\n","min(+P, Se) = 0.4\n","f1_score = 0.03174603116954182\n","Epoch 6: Validation AUROC = 0.7554\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 Batch 0: Train Loss = 0.3701\n","Epoch 7 Batch 50: Train Loss = 0.3552\n","Epoch 7: Train Loss = 0.3588\n","Epoch 7: Validation Loss = 0.3475\n","confusion matrix:\n","[[2715   11]\n"," [ 407   25]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.8696348667144775\n","precision class 1 = 0.6944444179534912\n","recall class 0 = 0.995964765548706\n","recall class 1 = 0.05787036940455437\n","AUC of ROC = 0.7718676122931443\n","AUC of PRC = 0.3941858894402946\n","min(+P, Se) = 0.4097222222222222\n","f1_score = 0.10683760223304027\n","Epoch 7: Validation AUROC = 0.7719\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 Batch 0: Train Loss = 0.3164\n","Epoch 8 Batch 50: Train Loss = 0.3504\n","Epoch 8: Train Loss = 0.3517\n","Epoch 8: Validation Loss = 0.3426\n","confusion matrix:\n","[[2722    4]\n"," [ 421   11]]\n","accuracy = 0.8654211759567261\n","precision class 0 = 0.8660515546798706\n","precision class 1 = 0.7333333492279053\n","recall class 0 = 0.9985326528549194\n","recall class 1 = 0.025462962687015533\n","AUC of ROC = 0.7888304665634086\n","AUC of PRC = 0.4108548994547517\n","min(+P, Se) = 0.41244239631336405\n","f1_score = 0.049217000307679705\n","Epoch 8: Validation AUROC = 0.7888\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 Batch 0: Train Loss = 0.3450\n","Epoch 9 Batch 50: Train Loss = 0.3513\n","Epoch 9: Train Loss = 0.3509\n","Epoch 9: Validation Loss = 0.3346\n","confusion matrix:\n","[[2716   10]\n"," [ 414   18]]\n","accuracy = 0.865737795829773\n","precision class 0 = 0.8677316308021545\n","precision class 1 = 0.6428571343421936\n","recall class 0 = 0.9963316321372986\n","recall class 1 = 0.0416666679084301\n","AUC of ROC = 0.7919596274557756\n","AUC of PRC = 0.41895789963215113\n","min(+P, Se) = 0.4351851851851852\n","f1_score = 0.07826086956296388\n","Epoch 9: Validation AUROC = 0.7920\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 Batch 0: Train Loss = 0.3243\n","Epoch 10 Batch 50: Train Loss = 0.3460\n","Epoch 10: Train Loss = 0.3461\n","Epoch 10: Validation Loss = 0.3299\n","confusion matrix:\n","[[2713   13]\n"," [ 402   30]]\n","accuracy = 0.8685877323150635\n","precision class 0 = 0.870947003364563\n","precision class 1 = 0.6976743936538696\n","recall class 0 = 0.9952310919761658\n","recall class 1 = 0.0694444477558136\n","AUC of ROC = 0.7985304407488927\n","AUC of PRC = 0.42483716654878684\n","min(+P, Se) = 0.4444444444444444\n","f1_score = 0.1263157994500162\n","Epoch 10: Validation AUROC = 0.7985\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11 Batch 0: Train Loss = 0.3301\n","Epoch 11 Batch 50: Train Loss = 0.3454\n","Epoch 11: Train Loss = 0.3455\n","Epoch 11: Validation Loss = 0.3279\n","confusion matrix:\n","[[2703   23]\n"," [ 393   39]]\n","accuracy = 0.8682710528373718\n","precision class 0 = 0.873062014579773\n","precision class 1 = 0.6290322542190552\n","recall class 0 = 0.9915627241134644\n","recall class 1 = 0.0902777761220932\n","AUC of ROC = 0.7994169655715878\n","AUC of PRC = 0.42036307279596236\n","min(+P, Se) = 0.44212962962962965\n","f1_score = 0.1578947309176915\n","Epoch 11: Validation AUROC = 0.7994\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12 Batch 0: Train Loss = 0.2802\n","Epoch 12 Batch 50: Train Loss = 0.3412\n","Epoch 12: Train Loss = 0.3440\n","Epoch 12: Validation Loss = 0.3308\n","confusion matrix:\n","[[2720    6]\n"," [ 421   11]]\n","accuracy = 0.8647878170013428\n","precision class 0 = 0.865966260433197\n","precision class 1 = 0.6470588445663452\n","recall class 0 = 0.9977989792823792\n","recall class 1 = 0.025462962687015533\n","AUC of ROC = 0.8004554903399365\n","AUC of PRC = 0.4155387524566836\n","min(+P, Se) = 0.42824074074074076\n","f1_score = 0.04899777074945145\n","Epoch 12: Validation AUROC = 0.8005\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13 Batch 0: Train Loss = 0.2650\n","Epoch 13 Batch 50: Train Loss = 0.3399\n","Epoch 13: Train Loss = 0.3396\n","Epoch 13: Validation Loss = 0.3316\n","confusion matrix:\n","[[2721    5]\n"," [ 427    5]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8643583059310913\n","precision class 1 = 0.5\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.011574073694646358\n","AUC of ROC = 0.8043548409010626\n","AUC of PRC = 0.4182100364783585\n","min(+P, Se) = 0.43287037037037035\n","f1_score = 0.02262443296404001\n","Epoch 13: Validation AUROC = 0.8044\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14 Batch 0: Train Loss = 0.3067\n","Epoch 14 Batch 50: Train Loss = 0.3343\n","Epoch 14: Train Loss = 0.3366\n","Epoch 14: Validation Loss = 0.3266\n","confusion matrix:\n","[[2713   13]\n"," [ 405   27]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.8701090216636658\n","precision class 1 = 0.675000011920929\n","recall class 0 = 0.9952310919761658\n","recall class 1 = 0.0625\n","AUC of ROC = 0.8111795535447406\n","AUC of PRC = 0.43983720418296945\n","min(+P, Se) = 0.45601851851851855\n","f1_score = 0.11440677983224545\n","Epoch 14: Validation AUROC = 0.8112\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15 Batch 0: Train Loss = 0.2949\n","Epoch 15 Batch 50: Train Loss = 0.3327\n","Epoch 15: Train Loss = 0.3358\n","Epoch 15: Validation Loss = 0.3290\n","confusion matrix:\n","[[2679   47]\n"," [ 358   74]]\n","accuracy = 0.8717542886734009\n","precision class 0 = 0.8821204900741577\n","precision class 1 = 0.6115702390670776\n","recall class 0 = 0.982758641242981\n","recall class 1 = 0.17129629850387573\n","AUC of ROC = 0.8137015638162006\n","AUC of PRC = 0.44295529216473795\n","min(+P, Se) = 0.45958429561200925\n","f1_score = 0.2676311049195307\n","Epoch 15: Validation AUROC = 0.8137\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16 Batch 0: Train Loss = 0.3509\n","Epoch 16 Batch 50: Train Loss = 0.3314\n","Epoch 16: Train Loss = 0.3343\n","Epoch 16: Validation Loss = 0.3225\n","confusion matrix:\n","[[2709   17]\n"," [ 395   37]]\n","accuracy = 0.8695377111434937\n","precision class 0 = 0.8727448582649231\n","precision class 1 = 0.6851851940155029\n","recall class 0 = 0.9937637448310852\n","recall class 1 = 0.08564814925193787\n","AUC of ROC = 0.8143290943180892\n","AUC of PRC = 0.4328379234903179\n","min(+P, Se) = 0.45601851851851855\n","f1_score = 0.15226337056101127\n","Epoch 16: Validation AUROC = 0.8143\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17 Batch 0: Train Loss = 0.3170\n","Epoch 17 Batch 50: Train Loss = 0.3333\n","Epoch 17: Train Loss = 0.3355\n","Epoch 17: Validation Loss = 0.3199\n","confusion matrix:\n","[[2707   19]\n"," [ 395   37]]\n","accuracy = 0.8689043521881104\n","precision class 0 = 0.8726627826690674\n","precision class 1 = 0.6607142686843872\n","recall class 0 = 0.9930300712585449\n","recall class 1 = 0.08564814925193787\n","AUC of ROC = 0.8135206923724898\n","AUC of PRC = 0.44592348558452943\n","min(+P, Se) = 0.47575057736720555\n","f1_score = 0.15163933948879763\n","Epoch 17: Validation AUROC = 0.8135\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18 Batch 0: Train Loss = 0.3527\n","Epoch 18 Batch 50: Train Loss = 0.3347\n","Epoch 18: Train Loss = 0.3347\n","Epoch 18: Validation Loss = 0.3203\n","confusion matrix:\n","[[2712   14]\n"," [ 395   37]]\n","accuracy = 0.870487630367279\n","precision class 0 = 0.8728677034378052\n","precision class 1 = 0.7254902124404907\n","recall class 0 = 0.994864284992218\n","recall class 1 = 0.08564814925193787\n","AUC of ROC = 0.8160736970462757\n","AUC of PRC = 0.45437692820971903\n","min(+P, Se) = 0.45265588914549654\n","f1_score = 0.15320910623258388\n","Epoch 18: Validation AUROC = 0.8161\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19 Batch 0: Train Loss = 0.3034\n","Epoch 19 Batch 50: Train Loss = 0.3305\n","Epoch 19: Train Loss = 0.3301\n","Epoch 19: Validation Loss = 0.3196\n","confusion matrix:\n","[[2705   21]\n"," [ 382   50]]\n","accuracy = 0.8723875880241394\n","precision class 0 = 0.8762552738189697\n","precision class 1 = 0.7042253613471985\n","recall class 0 = 0.9922963976860046\n","recall class 1 = 0.11574073880910873\n","AUC of ROC = 0.8139053626260155\n","AUC of PRC = 0.44728587224279504\n","min(+P, Se) = 0.46064814814814814\n","f1_score = 0.19880715999537535\n","Epoch 19: Validation AUROC = 0.8139\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20 Batch 0: Train Loss = 0.3631\n","Epoch 20 Batch 50: Train Loss = 0.3290\n","Epoch 20: Train Loss = 0.3279\n","Epoch 20: Validation Loss = 0.3167\n","confusion matrix:\n","[[2708   18]\n"," [ 387   45]]\n","accuracy = 0.8717542886734009\n","precision class 0 = 0.8749595880508423\n","precision class 1 = 0.7142857313156128\n","recall class 0 = 0.9933969378471375\n","recall class 1 = 0.1041666641831398\n","AUC of ROC = 0.8181690035596859\n","AUC of PRC = 0.4515009996553698\n","min(+P, Se) = 0.45601851851851855\n","f1_score = 0.18181817362131192\n","Epoch 20: Validation AUROC = 0.8182\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21 Batch 0: Train Loss = 0.3600\n","Epoch 21 Batch 50: Train Loss = 0.3296\n","Epoch 21: Train Loss = 0.3304\n","Epoch 21: Validation Loss = 0.3217\n","confusion matrix:\n","[[2714   12]\n"," [ 405   27]]\n","accuracy = 0.8679543733596802\n","precision class 0 = 0.8701506853103638\n","precision class 1 = 0.692307710647583\n","recall class 0 = 0.9955979585647583\n","recall class 1 = 0.0625\n","AUC of ROC = 0.8123632849650825\n","AUC of PRC = 0.4334516119751878\n","min(+P, Se) = 0.44545454545454544\n","f1_score = 0.1146496817801486\n","Epoch 21: Validation AUROC = 0.8124\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22 Batch 0: Train Loss = 0.3220\n","Epoch 22 Batch 50: Train Loss = 0.3270\n","Epoch 22: Train Loss = 0.3287\n","Epoch 22: Validation Loss = 0.3218\n","confusion matrix:\n","[[2713   13]\n"," [ 405   27]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.8701090216636658\n","precision class 1 = 0.675000011920929\n","recall class 0 = 0.9952310919761658\n","recall class 1 = 0.0625\n","AUC of ROC = 0.8118597320724981\n","AUC of PRC = 0.4342298117126117\n","min(+P, Se) = 0.44907407407407407\n","f1_score = 0.11440677983224545\n","Epoch 22: Validation AUROC = 0.8119\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23 Batch 0: Train Loss = 0.3060\n","Epoch 23 Batch 50: Train Loss = 0.3337\n","Epoch 23: Train Loss = 0.3315\n","Epoch 23: Validation Loss = 0.3214\n","confusion matrix:\n","[[2715   11]\n"," [ 405   27]]\n","accuracy = 0.8682710528373718\n","precision class 0 = 0.870192289352417\n","precision class 1 = 0.7105262875556946\n","recall class 0 = 0.995964765548706\n","recall class 1 = 0.0625\n","AUC of ROC = 0.813951217358224\n","AUC of PRC = 0.4281399799555777\n","min(+P, Se) = 0.44675925925925924\n","f1_score = 0.11489361665215411\n","Epoch 23: Validation AUROC = 0.8140\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24 Batch 0: Train Loss = 0.3496\n","Epoch 24 Batch 50: Train Loss = 0.3278\n","Epoch 24: Train Loss = 0.3305\n","Epoch 24: Validation Loss = 0.3226\n","confusion matrix:\n","[[2710   16]\n"," [ 402   30]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.8708226084709167\n","precision class 1 = 0.6521739363670349\n","recall class 0 = 0.9941306114196777\n","recall class 1 = 0.0694444477558136\n","AUC of ROC = 0.8126265250944268\n","AUC of PRC = 0.42637025609471274\n","min(+P, Se) = 0.4444444444444444\n","f1_score = 0.12552301320969408\n","Epoch 24: Validation AUROC = 0.8126\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25 Batch 0: Train Loss = 0.2904\n","Epoch 25 Batch 50: Train Loss = 0.3299\n","Epoch 25: Train Loss = 0.3297\n","Epoch 25: Validation Loss = 0.3198\n","confusion matrix:\n","[[2717    9]\n"," [ 415   17]]\n","accuracy = 0.865737795829773\n","precision class 0 = 0.8674967885017395\n","precision class 1 = 0.6538461446762085\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.039351850748062134\n","AUC of ROC = 0.8177325344419989\n","AUC of PRC = 0.4308816609872519\n","min(+P, Se) = 0.4444444444444444\n","f1_score = 0.07423580902869091\n","Epoch 25: Validation AUROC = 0.8177\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26 Batch 0: Train Loss = 0.3097\n","Epoch 26 Batch 50: Train Loss = 0.3308\n","Epoch 26: Train Loss = 0.3291\n","Epoch 26: Validation Loss = 0.3266\n","confusion matrix:\n","[[2723    3]\n"," [ 422   10]]\n","accuracy = 0.8654211759567261\n","precision class 0 = 0.8658187389373779\n","precision class 1 = 0.7692307829856873\n","recall class 0 = 0.9988994598388672\n","recall class 1 = 0.023148147389292717\n","AUC of ROC = 0.8096595540882041\n","AUC of PRC = 0.4130981031263113\n","min(+P, Se) = 0.43187066974595845\n","f1_score = 0.04494382040260745\n","Epoch 26: Validation AUROC = 0.8097\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27 Batch 0: Train Loss = 0.3456\n","Epoch 27 Batch 50: Train Loss = 0.3235\n","Epoch 27: Train Loss = 0.3221\n","Epoch 27: Validation Loss = 0.3179\n","confusion matrix:\n","[[2703   23]\n"," [ 387   45]]\n","accuracy = 0.8701710104942322\n","precision class 0 = 0.8747572898864746\n","precision class 1 = 0.6617646813392639\n","recall class 0 = 0.9915627241134644\n","recall class 1 = 0.1041666641831398\n","AUC of ROC = 0.8175380764109671\n","AUC of PRC = 0.4335477687220514\n","min(+P, Se) = 0.4387990762124711\n","f1_score = 0.17999999013137827\n","Epoch 27: Validation AUROC = 0.8175\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28 Batch 0: Train Loss = 0.3568\n","Epoch 28 Batch 50: Train Loss = 0.3263\n","Epoch 28: Train Loss = 0.3275\n","Epoch 28: Validation Loss = 0.3176\n","confusion matrix:\n","[[2703   23]\n"," [ 386   46]]\n","accuracy = 0.870487630367279\n","precision class 0 = 0.8750404715538025\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9915627241134644\n","recall class 1 = 0.10648148506879807\n","AUC of ROC = 0.8250964647699791\n","AUC of PRC = 0.4420820860666558\n","min(+P, Se) = 0.45537757437070936\n","f1_score = 0.1836327388495268\n","Epoch 28: Validation AUROC = 0.8251\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29 Batch 0: Train Loss = 0.3589\n","Epoch 29 Batch 50: Train Loss = 0.3289\n","Epoch 29: Train Loss = 0.3283\n","Epoch 29: Validation Loss = 0.3173\n","confusion matrix:\n","[[2712   14]\n"," [ 394   38]]\n","accuracy = 0.8708043098449707\n","precision class 0 = 0.8731487393379211\n","precision class 1 = 0.7307692170143127\n","recall class 0 = 0.994864284992218\n","recall class 1 = 0.08796296268701553\n","AUC of ROC = 0.8218068123148827\n","AUC of PRC = 0.44861537077134583\n","min(+P, Se) = 0.4652777777777778\n","f1_score = 0.15702478834436487\n","Epoch 29: Validation AUROC = 0.8218\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30 Batch 0: Train Loss = 0.2861\n","Epoch 30 Batch 50: Train Loss = 0.3252\n","Epoch 30: Train Loss = 0.3258\n","Epoch 30: Validation Loss = 0.3151\n","confusion matrix:\n","[[2711   15]\n"," [ 394   38]]\n","accuracy = 0.870487630367279\n","precision class 0 = 0.87310791015625\n","precision class 1 = 0.7169811129570007\n","recall class 0 = 0.9944974184036255\n","recall class 1 = 0.08796296268701553\n","AUC of ROC = 0.822751080133692\n","AUC of PRC = 0.4452722633504904\n","min(+P, Se) = 0.44907407407407407\n","f1_score = 0.15670102568206887\n","Epoch 30: Validation AUROC = 0.8228\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31 Batch 0: Train Loss = 0.2637\n","Epoch 31 Batch 50: Train Loss = 0.3301\n","Epoch 31: Train Loss = 0.3273\n","Epoch 31: Validation Loss = 0.3205\n","confusion matrix:\n","[[2717    9]\n"," [ 417   15]]\n","accuracy = 0.8651044964790344\n","precision class 0 = 0.8669431805610657\n","precision class 1 = 0.625\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.0347222238779068\n","AUC of ROC = 0.8191056289231271\n","AUC of PRC = 0.43771509676886433\n","min(+P, Se) = 0.4537037037037037\n","f1_score = 0.06578947814217574\n","Epoch 31: Validation AUROC = 0.8191\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32 Batch 0: Train Loss = 0.3528\n","Epoch 32 Batch 50: Train Loss = 0.3255\n","Epoch 32: Train Loss = 0.3280\n","Epoch 32: Validation Loss = 0.3171\n","confusion matrix:\n","[[2716   10]\n"," [ 412   20]]\n","accuracy = 0.8663710951805115\n","precision class 0 = 0.8682864308357239\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9963316321372986\n","recall class 1 = 0.046296294778585434\n","AUC of ROC = 0.8206765780821172\n","AUC of PRC = 0.43926803420530214\n","min(+P, Se) = 0.45871559633027525\n","f1_score = 0.08658008364123948\n","Epoch 32: Validation AUROC = 0.8207\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33 Batch 0: Train Loss = 0.3363\n","Epoch 33 Batch 50: Train Loss = 0.3242\n","Epoch 33: Train Loss = 0.3251\n","Epoch 33: Validation Loss = 0.3184\n","confusion matrix:\n","[[2712   14]\n"," [ 405   27]]\n","accuracy = 0.8673210740089417\n","precision class 0 = 0.8700673580169678\n","precision class 1 = 0.6585366129875183\n","recall class 0 = 0.994864284992218\n","recall class 1 = 0.0625\n","AUC of ROC = 0.8173105010733404\n","AUC of PRC = 0.44086168058249603\n","min(+P, Se) = 0.46420323325635104\n","f1_score = 0.11416490527765302\n","Epoch 33: Validation AUROC = 0.8173\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34 Batch 0: Train Loss = 0.3723\n","Epoch 34 Batch 50: Train Loss = 0.3244\n","Epoch 34: Train Loss = 0.3250\n","Epoch 34: Validation Loss = 0.3139\n","confusion matrix:\n","[[2714   12]\n"," [ 398   34]]\n","accuracy = 0.8701710104942322\n","precision class 0 = 0.872107982635498\n","precision class 1 = 0.739130437374115\n","recall class 0 = 0.9955979585647583\n","recall class 1 = 0.07870370149612427\n","AUC of ROC = 0.8253070568734545\n","AUC of PRC = 0.45306546955838045\n","min(+P, Se) = 0.45601851851851855\n","f1_score = 0.1422594106676732\n","Epoch 34: Validation AUROC = 0.8253\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35 Batch 0: Train Loss = 0.3202\n","Epoch 35 Batch 50: Train Loss = 0.3289\n","Epoch 35: Train Loss = 0.3270\n","Epoch 35: Validation Loss = 0.3170\n","confusion matrix:\n","[[2713   13]\n"," [ 396   36]]\n","accuracy = 0.870487630367279\n","precision class 0 = 0.872627854347229\n","precision class 1 = 0.7346938848495483\n","recall class 0 = 0.9952310919761658\n","recall class 1 = 0.0833333358168602\n","AUC of ROC = 0.8186657631586098\n","AUC of PRC = 0.4431315784855222\n","min(+P, Se) = 0.45727482678983833\n","f1_score = 0.14968815793630882\n","Epoch 35: Validation AUROC = 0.8187\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36 Batch 0: Train Loss = 0.2861\n","Epoch 36 Batch 50: Train Loss = 0.3207\n","Epoch 36: Train Loss = 0.3220\n","Epoch 36: Validation Loss = 0.3184\n","confusion matrix:\n","[[2717    9]\n"," [ 409   23]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.86916184425354\n","precision class 1 = 0.71875\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.05324074253439903\n","AUC of ROC = 0.8188432379554903\n","AUC of PRC = 0.4433195553596051\n","min(+P, Se) = 0.45871559633027525\n","f1_score = 0.09913793749283403\n","Epoch 36: Validation AUROC = 0.8188\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37 Batch 0: Train Loss = 0.3926\n","Epoch 37 Batch 50: Train Loss = 0.3234\n","Epoch 37: Train Loss = 0.3207\n","Epoch 37: Validation Loss = 0.3212\n","confusion matrix:\n","[[2718    8]\n"," [ 418   14]]\n","accuracy = 0.8651044964790344\n","precision class 0 = 0.8667091727256775\n","precision class 1 = 0.6363636255264282\n","recall class 0 = 0.9970653057098389\n","recall class 1 = 0.032407406717538834\n","AUC of ROC = 0.8162532947474253\n","AUC of PRC = 0.4445960496514586\n","min(+P, Se) = 0.46296296296296297\n","f1_score = 0.06167400785396493\n","Epoch 37: Validation AUROC = 0.8163\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38 Batch 0: Train Loss = 0.3453\n","Epoch 38 Batch 50: Train Loss = 0.3223\n","Epoch 38: Train Loss = 0.3221\n","Epoch 38: Validation Loss = 0.3129\n","confusion matrix:\n","[[2710   16]\n"," [ 391   41]]\n","accuracy = 0.8711209893226624\n","precision class 0 = 0.8739116191864014\n","precision class 1 = 0.719298243522644\n","recall class 0 = 0.9941306114196777\n","recall class 1 = 0.09490741044282913\n","AUC of ROC = 0.8254412244232494\n","AUC of PRC = 0.4602981287623608\n","min(+P, Se) = 0.4618937644341801\n","f1_score = 0.1676891677698798\n","Epoch 38: Validation AUROC = 0.8254\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39 Batch 0: Train Loss = 0.3422\n","Epoch 39 Batch 50: Train Loss = 0.3194\n","Epoch 39: Train Loss = 0.3213\n","Epoch 39: Validation Loss = 0.3183\n","confusion matrix:\n","[[2697   29]\n"," [ 369   63]]\n","accuracy = 0.8739708662033081\n","precision class 0 = 0.8796477317810059\n","precision class 1 = 0.6847826242446899\n","recall class 0 = 0.9893617033958435\n","recall class 1 = 0.1458333283662796\n","AUC of ROC = 0.820721583652618\n","AUC of PRC = 0.44816641265642176\n","min(+P, Se) = 0.4622425629290618\n","f1_score = 0.24045801378756587\n","Epoch 39: Validation AUROC = 0.8207\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40 Batch 0: Train Loss = 0.2735\n","Epoch 40 Batch 50: Train Loss = 0.3252\n","Epoch 40: Train Loss = 0.3255\n","Epoch 40: Validation Loss = 0.3177\n","confusion matrix:\n","[[2715   11]\n"," [ 405   27]]\n","accuracy = 0.8682710528373718\n","precision class 0 = 0.870192289352417\n","precision class 1 = 0.7105262875556946\n","recall class 0 = 0.995964765548706\n","recall class 1 = 0.0625\n","AUC of ROC = 0.8164486019401648\n","AUC of PRC = 0.4508564363289718\n","min(+P, Se) = 0.4537037037037037\n","f1_score = 0.11489361665215411\n","Epoch 40: Validation AUROC = 0.8164\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41 Batch 0: Train Loss = 0.3445\n","Epoch 41 Batch 50: Train Loss = 0.3259\n","Epoch 41: Train Loss = 0.3249\n","Epoch 41: Validation Loss = 0.3189\n","confusion matrix:\n","[[2719    7]\n"," [ 414   18]]\n","accuracy = 0.8666877746582031\n","precision class 0 = 0.8678582906723022\n","precision class 1 = 0.7200000286102295\n","recall class 0 = 0.9974321126937866\n","recall class 1 = 0.0416666679084301\n","AUC of ROC = 0.8208234830575256\n","AUC of PRC = 0.4471174853557538\n","min(+P, Se) = 0.4699074074074074\n","f1_score = 0.07877461753188747\n","Epoch 41: Validation AUROC = 0.8208\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42 Batch 0: Train Loss = 0.3057\n","Epoch 42 Batch 50: Train Loss = 0.3210\n","Epoch 42: Train Loss = 0.3240\n","Epoch 42: Validation Loss = 0.3244\n","confusion matrix:\n","[[2714   12]\n"," [ 406   26]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.8698717951774597\n","precision class 1 = 0.6842105388641357\n","recall class 0 = 0.9955979585647583\n","recall class 1 = 0.06018518656492233\n","AUC of ROC = 0.8217711475231652\n","AUC of PRC = 0.44733225510399244\n","min(+P, Se) = 0.45727482678983833\n","f1_score = 0.11063829926032727\n","Epoch 42: Validation AUROC = 0.8218\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43 Batch 0: Train Loss = 0.2960\n","Epoch 43 Batch 50: Train Loss = 0.3212\n","Epoch 43: Train Loss = 0.3211\n","Epoch 43: Validation Loss = 0.3143\n","confusion matrix:\n","[[2711   15]\n"," [ 395   37]]\n","accuracy = 0.8701710104942322\n","precision class 0 = 0.8728268146514893\n","precision class 1 = 0.7115384340286255\n","recall class 0 = 0.9944974184036255\n","recall class 1 = 0.08564814925193787\n","AUC of ROC = 0.8273577823972176\n","AUC of PRC = 0.4620767298137824\n","min(+P, Se) = 0.4652777777777778\n","f1_score = 0.15289255739129567\n","Epoch 43: Validation AUROC = 0.8274\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44 Batch 0: Train Loss = 0.3370\n","Epoch 44 Batch 50: Train Loss = 0.3220\n","Epoch 44: Train Loss = 0.3222\n","Epoch 44: Validation Loss = 0.3140\n","confusion matrix:\n","[[2720    6]\n"," [ 416   16]]\n","accuracy = 0.8663710951805115\n","precision class 0 = 0.8673469424247742\n","precision class 1 = 0.7272727489471436\n","recall class 0 = 0.9977989792823792\n","recall class 1 = 0.03703703731298447\n","AUC of ROC = 0.8270733132251841\n","AUC of PRC = 0.4577503916514196\n","min(+P, Se) = 0.4681818181818182\n","f1_score = 0.0704845841605677\n","Epoch 44: Validation AUROC = 0.8271\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45 Batch 0: Train Loss = 0.3613\n","Epoch 45 Batch 50: Train Loss = 0.3240\n","Epoch 45: Train Loss = 0.3226\n","Epoch 45: Validation Loss = 0.3131\n","confusion matrix:\n","[[2715   11]\n"," [ 407   25]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.8696348667144775\n","precision class 1 = 0.6944444179534912\n","recall class 0 = 0.995964765548706\n","recall class 1 = 0.05787036940455437\n","AUC of ROC = 0.8276889554631669\n","AUC of PRC = 0.46185362217110404\n","min(+P, Se) = 0.47575057736720555\n","f1_score = 0.10683760223304027\n","Epoch 45: Validation AUROC = 0.8277\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46 Batch 0: Train Loss = 0.3258\n","Epoch 46 Batch 50: Train Loss = 0.3251\n","Epoch 46: Train Loss = 0.3239\n","Epoch 46: Validation Loss = 0.3158\n","confusion matrix:\n","[[2717    9]\n"," [ 406   26]]\n","accuracy = 0.8685877323150635\n","precision class 0 = 0.8699967861175537\n","precision class 1 = 0.7428571581840515\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.06018518656492233\n","AUC of ROC = 0.8228852476834869\n","AUC of PRC = 0.45520921676862586\n","min(+P, Se) = 0.4608294930875576\n","f1_score = 0.11134903790300979\n","Epoch 46: Validation AUROC = 0.8229\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47 Batch 0: Train Loss = 0.3565\n","Epoch 47 Batch 50: Train Loss = 0.3254\n","Epoch 47: Train Loss = 0.3244\n","Epoch 47: Validation Loss = 0.3130\n","confusion matrix:\n","[[2715   11]\n"," [ 403   29]]\n","accuracy = 0.8689043521881104\n","precision class 0 = 0.8707504868507385\n","precision class 1 = 0.7250000238418579\n","recall class 0 = 0.995964765548706\n","recall class 1 = 0.06712962687015533\n","AUC of ROC = 0.8261099392679547\n","AUC of PRC = 0.45992494888193564\n","min(+P, Se) = 0.46436781609195404\n","f1_score = 0.12288135396307535\n","Epoch 47: Validation AUROC = 0.8261\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48 Batch 0: Train Loss = 0.3285\n","Epoch 48 Batch 50: Train Loss = 0.3182\n","Epoch 48: Train Loss = 0.3201\n","Epoch 48: Validation Loss = 0.3117\n","confusion matrix:\n","[[2717    9]\n"," [ 402   30]]\n","accuracy = 0.8698543310165405\n","precision class 0 = 0.8711125254631042\n","precision class 1 = 0.7692307829856873\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.0694444477558136\n","AUC of ROC = 0.827787458221244\n","AUC of PRC = 0.4594465954152174\n","min(+P, Se) = 0.4583333333333333\n","f1_score = 0.12738853626509675\n","Epoch 48: Validation AUROC = 0.8278\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49 Batch 0: Train Loss = 0.3357\n","Epoch 49 Batch 50: Train Loss = 0.3210\n","Epoch 49: Train Loss = 0.3216\n","Epoch 49: Validation Loss = 0.3114\n","confusion matrix:\n","[[2716   10]\n"," [ 394   38]]\n","accuracy = 0.8720709085464478\n","precision class 0 = 0.8733118772506714\n","precision class 1 = 0.7916666865348816\n","recall class 0 = 0.9963316321372986\n","recall class 1 = 0.08796296268701553\n","AUC of ROC = 0.8259982745034102\n","AUC of PRC = 0.46173138337046615\n","min(+P, Se) = 0.4691075514874142\n","f1_score = 0.15833332926034946\n","Epoch 49: Validation AUROC = 0.8260\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50 Batch 0: Train Loss = 0.2990\n","Epoch 50 Batch 50: Train Loss = 0.3204\n","Epoch 50: Train Loss = 0.3212\n","Epoch 50: Validation Loss = 0.3158\n","confusion matrix:\n","[[2719    7]\n"," [ 412   20]]\n","accuracy = 0.8673210740089417\n","precision class 0 = 0.8684126734733582\n","precision class 1 = 0.7407407164573669\n","recall class 0 = 0.9974321126937866\n","recall class 1 = 0.046296294778585434\n","AUC of ROC = 0.8200999972826825\n","AUC of PRC = 0.45534670324515747\n","min(+P, Se) = 0.4513888888888889\n","f1_score = 0.08714596622955428\n","Epoch 50: Validation AUROC = 0.8201\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51 Batch 0: Train Loss = 0.2408\n","Epoch 51 Batch 50: Train Loss = 0.3270\n","Epoch 51: Train Loss = 0.3232\n","Epoch 51: Validation Loss = 0.3173\n","confusion matrix:\n","[[2721    5]\n"," [ 412   20]]\n","accuracy = 0.8679543733596802\n","precision class 0 = 0.8684966564178467\n","precision class 1 = 0.800000011920929\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.046296294778585434\n","AUC of ROC = 0.8197161761908643\n","AUC of PRC = 0.4539741937790426\n","min(+P, Se) = 0.4699074074074074\n","f1_score = 0.08752734927125506\n","Epoch 51: Validation AUROC = 0.8197\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52 Batch 0: Train Loss = 0.3887\n","Epoch 52 Batch 50: Train Loss = 0.3206\n","Epoch 52: Train Loss = 0.3230\n","Epoch 52: Validation Loss = 0.3132\n","confusion matrix:\n","[[2706   20]\n"," [ 381   51]]\n","accuracy = 0.8730208873748779\n","precision class 0 = 0.876579225063324\n","precision class 1 = 0.7183098793029785\n","recall class 0 = 0.9926632642745972\n","recall class 1 = 0.1180555522441864\n","AUC of ROC = 0.8211504103149372\n","AUC of PRC = 0.4593455374276294\n","min(+P, Se) = 0.45308924485125857\n","f1_score = 0.20278328889081879\n","Epoch 52: Validation AUROC = 0.8212\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53 Batch 0: Train Loss = 0.3324\n","Epoch 53 Batch 50: Train Loss = 0.3274\n","Epoch 53: Train Loss = 0.3268\n","Epoch 53: Validation Loss = 0.3152\n","confusion matrix:\n","[[2719    7]\n"," [ 408   24]]\n","accuracy = 0.8685877323150635\n","precision class 0 = 0.8695235252380371\n","precision class 1 = 0.774193525314331\n","recall class 0 = 0.9974321126937866\n","recall class 1 = 0.0555555559694767\n","AUC of ROC = 0.8243322192331729\n","AUC of PRC = 0.449658515458056\n","min(+P, Se) = 0.4490238611713666\n","f1_score = 0.1036717035191756\n","Epoch 53: Validation AUROC = 0.8243\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54 Batch 0: Train Loss = 0.3248\n","Epoch 54 Batch 50: Train Loss = 0.3260\n","Epoch 54: Train Loss = 0.3259\n","Epoch 54: Validation Loss = 0.3142\n","confusion matrix:\n","[[2720    6]\n"," [ 408   24]]\n","accuracy = 0.8689043521881104\n","precision class 0 = 0.8695651888847351\n","precision class 1 = 0.800000011920929\n","recall class 0 = 0.9977989792823792\n","recall class 1 = 0.0555555559694767\n","AUC of ROC = 0.8259430789924187\n","AUC of PRC = 0.45849546714211487\n","min(+P, Se) = 0.46296296296296297\n","f1_score = 0.10389610155373899\n","Epoch 54: Validation AUROC = 0.8259\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55 Batch 0: Train Loss = 0.3567\n","Epoch 55 Batch 50: Train Loss = 0.3283\n","Epoch 55: Train Loss = 0.3237\n","Epoch 55: Validation Loss = 0.3237\n","confusion matrix:\n","[[2719    7]\n"," [ 407   25]]\n","accuracy = 0.8689043521881104\n","precision class 0 = 0.8698016405105591\n","precision class 1 = 0.78125\n","recall class 0 = 0.9974321126937866\n","recall class 1 = 0.05787036940455437\n","AUC of ROC = 0.8188593720279342\n","AUC of PRC = 0.4439908802269007\n","min(+P, Se) = 0.4583333333333333\n","f1_score = 0.10775861662328606\n","Epoch 55: Validation AUROC = 0.8189\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56 Batch 0: Train Loss = 0.2864\n","Epoch 56 Batch 50: Train Loss = 0.3264\n","Epoch 56: Train Loss = 0.3251\n","Epoch 56: Validation Loss = 0.3178\n","confusion matrix:\n","[[2720    6]\n"," [ 417   15]]\n","accuracy = 0.8660544753074646\n","precision class 0 = 0.8670704364776611\n","precision class 1 = 0.7142857313156128\n","recall class 0 = 0.9977989792823792\n","recall class 1 = 0.0347222238779068\n","AUC of ROC = 0.8250064536289774\n","AUC of PRC = 0.4410485218362415\n","min(+P, Se) = 0.4541284403669725\n","f1_score = 0.06622516996509903\n","Epoch 56: Validation AUROC = 0.8250\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57 Batch 0: Train Loss = 0.2915\n","Epoch 57 Batch 50: Train Loss = 0.3236\n","Epoch 57: Train Loss = 0.3225\n","Epoch 57: Validation Loss = 0.3161\n","confusion matrix:\n","[[2714   12]\n"," [ 407   25]]\n","accuracy = 0.8673210740089417\n","precision class 0 = 0.86959308385849\n","precision class 1 = 0.6756756901741028\n","recall class 0 = 0.9955979585647583\n","recall class 1 = 0.05787036940455437\n","AUC of ROC = 0.8226126667753595\n","AUC of PRC = 0.44774223705550603\n","min(+P, Se) = 0.45662100456621\n","f1_score = 0.10660980393686804\n","Epoch 57: Validation AUROC = 0.8226\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58 Batch 0: Train Loss = 0.3230\n","Epoch 58 Batch 50: Train Loss = 0.3206\n","Epoch 58: Train Loss = 0.3204\n","Epoch 58: Validation Loss = 0.3151\n","confusion matrix:\n","[[2717    9]\n"," [ 406   26]]\n","accuracy = 0.8685877323150635\n","precision class 0 = 0.8699967861175537\n","precision class 1 = 0.7428571581840515\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.06018518656492233\n","AUC of ROC = 0.8251227887829135\n","AUC of PRC = 0.45229701838363007\n","min(+P, Se) = 0.45601851851851855\n","f1_score = 0.11134903790300979\n","Epoch 58: Validation AUROC = 0.8251\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59 Batch 0: Train Loss = 0.3949\n","Epoch 59 Batch 50: Train Loss = 0.3219\n","Epoch 59: Train Loss = 0.3217\n","Epoch 59: Validation Loss = 0.3135\n","confusion matrix:\n","[[2715   11]\n"," [ 400   32]]\n","accuracy = 0.8698543310165405\n","precision class 0 = 0.8715890645980835\n","precision class 1 = 0.7441860437393188\n","recall class 0 = 0.995964765548706\n","recall class 1 = 0.07407407462596893\n","AUC of ROC = 0.824388263905872\n","AUC of PRC = 0.452317740170875\n","min(+P, Se) = 0.4699074074074074\n","f1_score = 0.13473684051915222\n","Epoch 59: Validation AUROC = 0.8244\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60 Batch 0: Train Loss = 0.3399\n","Epoch 60 Batch 50: Train Loss = 0.3213\n","Epoch 60: Train Loss = 0.3211\n","Epoch 60: Validation Loss = 0.3166\n","confusion matrix:\n","[[2720    6]\n"," [ 414   18]]\n","accuracy = 0.8670044541358948\n","precision class 0 = 0.8679004311561584\n","precision class 1 = 0.75\n","recall class 0 = 0.9977989792823792\n","recall class 1 = 0.0416666679084301\n","AUC of ROC = 0.8224818958723947\n","AUC of PRC = 0.44779561010657676\n","min(+P, Se) = 0.45770065075921906\n","f1_score = 0.07894736879254971\n","Epoch 60: Validation AUROC = 0.8225\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61 Batch 0: Train Loss = 0.3739\n","Epoch 61 Batch 50: Train Loss = 0.3247\n","Epoch 61: Train Loss = 0.3233\n","Epoch 61: Validation Loss = 0.3143\n","confusion matrix:\n","[[2718    8]\n"," [ 404   28]]\n","accuracy = 0.8695377111434937\n","precision class 0 = 0.8705957531929016\n","precision class 1 = 0.7777777910232544\n","recall class 0 = 0.9970653057098389\n","recall class 1 = 0.06481481343507767\n","AUC of ROC = 0.824004442814054\n","AUC of PRC = 0.45318648125901023\n","min(+P, Se) = 0.4769585253456221\n","f1_score = 0.1196581185216734\n","Epoch 61: Validation AUROC = 0.8240\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62 Batch 0: Train Loss = 0.4190\n","Epoch 62 Batch 50: Train Loss = 0.3176\n","Epoch 62: Train Loss = 0.3197\n","Epoch 62: Validation Loss = 0.3142\n","confusion matrix:\n","[[2720    6]\n"," [ 408   24]]\n","accuracy = 0.8689043521881104\n","precision class 0 = 0.8695651888847351\n","precision class 1 = 0.800000011920929\n","recall class 0 = 0.9977989792823792\n","recall class 1 = 0.0555555559694767\n","AUC of ROC = 0.8251941183663487\n","AUC of PRC = 0.4640275912775866\n","min(+P, Se) = 0.46296296296296297\n","f1_score = 0.10389610155373899\n","Epoch 62: Validation AUROC = 0.8252\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63 Batch 0: Train Loss = 0.3596\n","Epoch 63 Batch 50: Train Loss = 0.3232\n","Epoch 63: Train Loss = 0.3210\n","Epoch 63: Validation Loss = 0.3155\n","confusion matrix:\n","[[2718    8]\n"," [ 405   27]]\n","accuracy = 0.869221031665802\n","precision class 0 = 0.8703169822692871\n","precision class 1 = 0.7714285850524902\n","recall class 0 = 0.9970653057098389\n","recall class 1 = 0.0625\n","AUC of ROC = 0.8246438615798484\n","AUC of PRC = 0.44901549696596016\n","min(+P, Se) = 0.4308755760368664\n","f1_score = 0.11563169180187263\n","Epoch 63: Validation AUROC = 0.8246\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64 Batch 0: Train Loss = 0.3972\n","Epoch 64 Batch 50: Train Loss = 0.3220\n","Epoch 64: Train Loss = 0.3204\n","Epoch 64: Validation Loss = 0.3125\n","confusion matrix:\n","[[2715   11]\n"," [ 397   35]]\n","accuracy = 0.8708043098449707\n","precision class 0 = 0.8724293112754822\n","precision class 1 = 0.760869562625885\n","recall class 0 = 0.995964765548706\n","recall class 1 = 0.08101851493120193\n","AUC of ROC = 0.8270367992717589\n","AUC of PRC = 0.461752588490871\n","min(+P, Se) = 0.46296296296296297\n","f1_score = 0.146443510032168\n","Epoch 64: Validation AUROC = 0.8270\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65 Batch 0: Train Loss = 0.3137\n","Epoch 65 Batch 50: Train Loss = 0.3173\n","Epoch 65: Train Loss = 0.3190\n","Epoch 65: Validation Loss = 0.3131\n","confusion matrix:\n","[[2715   11]\n"," [ 400   32]]\n","accuracy = 0.8698543310165405\n","precision class 0 = 0.8715890645980835\n","precision class 1 = 0.7441860437393188\n","recall class 0 = 0.995964765548706\n","recall class 1 = 0.07407407462596893\n","AUC of ROC = 0.8290450667101438\n","AUC of PRC = 0.46077403777980136\n","min(+P, Se) = 0.4541284403669725\n","f1_score = 0.13473684051915222\n","Epoch 65: Validation AUROC = 0.8290\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66 Batch 0: Train Loss = 0.2963\n","Epoch 66 Batch 50: Train Loss = 0.3174\n","Epoch 66: Train Loss = 0.3179\n","Epoch 66: Validation Loss = 0.3128\n","confusion matrix:\n","[[2718    8]\n"," [ 399   33]]\n","accuracy = 0.8711209893226624\n","precision class 0 = 0.871992290019989\n","precision class 1 = 0.8048780560493469\n","recall class 0 = 0.9970653057098389\n","recall class 1 = 0.0763888880610466\n","AUC of ROC = 0.8234473927338931\n","AUC of PRC = 0.4689762629221329\n","min(+P, Se) = 0.46064814814814814\n","f1_score = 0.13953488126938424\n","Epoch 66: Validation AUROC = 0.8234\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67 Batch 0: Train Loss = 0.2925\n","Epoch 67 Batch 50: Train Loss = 0.3220\n","Epoch 67: Train Loss = 0.3220\n","Epoch 67: Validation Loss = 0.3128\n","confusion matrix:\n","[[2709   17]\n"," [ 388   44]]\n","accuracy = 0.8717542886734009\n","precision class 0 = 0.8747174739837646\n","precision class 1 = 0.7213114500045776\n","recall class 0 = 0.9937637448310852\n","recall class 1 = 0.10185185074806213\n","AUC of ROC = 0.8255745428113366\n","AUC of PRC = 0.4592197657367913\n","min(+P, Se) = 0.44907407407407407\n","f1_score = 0.1784989897907354\n","Epoch 67: Validation AUROC = 0.8256\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68 Batch 0: Train Loss = 0.3268\n","Epoch 68 Batch 50: Train Loss = 0.3242\n","Epoch 68: Train Loss = 0.3220\n","Epoch 68: Validation Loss = 0.3165\n","confusion matrix:\n","[[2691   35]\n"," [ 360   72]]\n","accuracy = 0.8749208450317383\n","precision class 0 = 0.8820058703422546\n","precision class 1 = 0.672897219657898\n","recall class 0 = 0.9871606826782227\n","recall class 1 = 0.1666666716337204\n","AUC of ROC = 0.8164044455313715\n","AUC of PRC = 0.44321763210424714\n","min(+P, Se) = 0.4518348623853211\n","f1_score = 0.26716141350224903\n","Epoch 68: Validation AUROC = 0.8164\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69 Batch 0: Train Loss = 0.3908\n","Epoch 69 Batch 50: Train Loss = 0.3262\n","Epoch 69: Train Loss = 0.3267\n","Epoch 69: Validation Loss = 0.3199\n","confusion matrix:\n","[[2712   14]\n"," [ 392   40]]\n","accuracy = 0.8714376091957092\n","precision class 0 = 0.873711347579956\n","precision class 1 = 0.7407407164573669\n","recall class 0 = 0.994864284992218\n","recall class 1 = 0.09259258955717087\n","AUC of ROC = 0.813693072199125\n","AUC of PRC = 0.44053851765247654\n","min(+P, Se) = 0.44341801385681295\n","f1_score = 0.1646090466299175\n","Epoch 69: Validation AUROC = 0.8137\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70 Batch 0: Train Loss = 0.3327\n","Epoch 70 Batch 50: Train Loss = 0.3248\n","Epoch 70: Train Loss = 0.3260\n","Epoch 70: Validation Loss = 0.3125\n","confusion matrix:\n","[[2699   27]\n"," [ 361   71]]\n","accuracy = 0.8771374225616455\n","precision class 0 = 0.8820261359214783\n","precision class 1 = 0.7244898080825806\n","recall class 0 = 0.9900953769683838\n","recall class 1 = 0.16435185074806213\n","AUC of ROC = 0.8232283090133421\n","AUC of PRC = 0.4698786509548807\n","min(+P, Se) = 0.46543778801843316\n","f1_score = 0.26792453665035665\n","Epoch 70: Validation AUROC = 0.8232\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71 Batch 0: Train Loss = 0.3916\n","Epoch 71 Batch 50: Train Loss = 0.3202\n","Epoch 71: Train Loss = 0.3215\n","Epoch 71: Validation Loss = 0.3152\n","confusion matrix:\n","[[2719    7]\n"," [ 405   27]]\n","accuracy = 0.8695377111434937\n","precision class 0 = 0.8703585267066956\n","precision class 1 = 0.7941176295280457\n","recall class 0 = 0.9974321126937866\n","recall class 1 = 0.0625\n","AUC of ROC = 0.8265315480557593\n","AUC of PRC = 0.4682116783671249\n","min(+P, Se) = 0.4590909090909091\n","f1_score = 0.1158798281395349\n","Epoch 71: Validation AUROC = 0.8265\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72 Batch 0: Train Loss = 0.3213\n","Epoch 72 Batch 50: Train Loss = 0.3199\n","Epoch 72: Train Loss = 0.3215\n","Epoch 72: Validation Loss = 0.3113\n","confusion matrix:\n","[[2703   23]\n"," [ 372   60]]\n","accuracy = 0.8749208450317383\n","precision class 0 = 0.8790243864059448\n","precision class 1 = 0.7228915691375732\n","recall class 0 = 0.9915627241134644\n","recall class 1 = 0.1388888955116272\n","AUC of ROC = 0.8244956828618788\n","AUC of PRC = 0.46704968421613113\n","min(+P, Se) = 0.45958429561200925\n","f1_score = 0.23300971820718747\n","Epoch 72: Validation AUROC = 0.8245\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73 Batch 0: Train Loss = 0.3605\n","Epoch 73 Batch 50: Train Loss = 0.3254\n","Epoch 73: Train Loss = 0.3239\n","Epoch 73: Validation Loss = 0.3111\n","confusion matrix:\n","[[2710   16]\n"," [ 390   42]]\n","accuracy = 0.8714376091957092\n","precision class 0 = 0.874193549156189\n","precision class 1 = 0.7241379022598267\n","recall class 0 = 0.9941306114196777\n","recall class 1 = 0.0972222238779068\n","AUC of ROC = 0.8293813347463385\n","AUC of PRC = 0.46940403900206296\n","min(+P, Se) = 0.46924829157175396\n","f1_score = 0.1714285763061728\n","Epoch 73: Validation AUROC = 0.8294\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74 Batch 0: Train Loss = 0.2584\n","Epoch 74 Batch 50: Train Loss = 0.3190\n","Epoch 74: Train Loss = 0.3224\n","Epoch 74: Validation Loss = 0.3133\n","confusion matrix:\n","[[2703   23]\n"," [ 370   62]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.879596471786499\n","precision class 1 = 0.729411780834198\n","recall class 0 = 0.9915627241134644\n","recall class 1 = 0.14351852238178253\n","AUC of ROC = 0.8277925531914894\n","AUC of PRC = 0.47193972458462896\n","min(+P, Se) = 0.4700460829493088\n","f1_score = 0.2398452714827435\n","Epoch 74: Validation AUROC = 0.8278\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75 Batch 0: Train Loss = 0.3250\n","Epoch 75 Batch 50: Train Loss = 0.3171\n","Epoch 75: Train Loss = 0.3201\n","Epoch 75: Validation Loss = 0.3111\n","confusion matrix:\n","[[2698   28]\n"," [ 359   73]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.8825646042823792\n","precision class 1 = 0.7227723002433777\n","recall class 0 = 0.9897285103797913\n","recall class 1 = 0.16898147761821747\n","AUC of ROC = 0.8258513695280022\n","AUC of PRC = 0.46736257123175334\n","min(+P, Se) = 0.45496535796766746\n","f1_score = 0.27392119275042304\n","Epoch 75: Validation AUROC = 0.8259\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76 Batch 0: Train Loss = 0.2857\n","Epoch 76 Batch 50: Train Loss = 0.3179\n","Epoch 76: Train Loss = 0.3186\n","Epoch 76: Validation Loss = 0.3069\n","confusion matrix:\n","[[2692   34]\n"," [ 356   76]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.883202075958252\n","precision class 1 = 0.6909090876579285\n","recall class 0 = 0.9875274896621704\n","recall class 1 = 0.17592592537403107\n","AUC of ROC = 0.8309259598923943\n","AUC of PRC = 0.4708896388849417\n","min(+P, Se) = 0.46924829157175396\n","f1_score = 0.2804428082798934\n","Epoch 76: Validation AUROC = 0.8309\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77 Batch 0: Train Loss = 0.2941\n","Epoch 77 Batch 50: Train Loss = 0.3197\n","Epoch 77: Train Loss = 0.3200\n","Epoch 77: Validation Loss = 0.3100\n","confusion matrix:\n","[[2711   15]\n"," [ 385   47]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.8756459951400757\n","precision class 1 = 0.7580645084381104\n","recall class 0 = 0.9944974184036255\n","recall class 1 = 0.10879629850387573\n","AUC of ROC = 0.8280557933208338\n","AUC of PRC = 0.4683358437773371\n","min(+P, Se) = 0.47344110854503463\n","f1_score = 0.1902834039438722\n","Epoch 77: Validation AUROC = 0.8281\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78 Batch 0: Train Loss = 0.3188\n","Epoch 78 Batch 50: Train Loss = 0.3158\n","Epoch 78: Train Loss = 0.3158\n","Epoch 78: Validation Loss = 0.3097\n","confusion matrix:\n","[[2713   13]\n"," [ 388   44]]\n","accuracy = 0.8730208873748779\n","precision class 0 = 0.8748790621757507\n","precision class 1 = 0.7719298005104065\n","recall class 0 = 0.9952310919761658\n","recall class 1 = 0.10185185074806213\n","AUC of ROC = 0.8290064298524497\n","AUC of PRC = 0.4738727517881067\n","min(+P, Se) = 0.45727482678983833\n","f1_score = 0.17995909169008398\n","Epoch 78: Validation AUROC = 0.8290\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79 Batch 0: Train Loss = 0.3356\n","Epoch 79 Batch 50: Train Loss = 0.3215\n","Epoch 79: Train Loss = 0.3206\n","Epoch 79: Validation Loss = 0.3085\n","confusion matrix:\n","[[2711   15]\n"," [ 383   49]]\n","accuracy = 0.8739708662033081\n","precision class 0 = 0.8762120008468628\n","precision class 1 = 0.765625\n","recall class 0 = 0.9944974184036255\n","recall class 1 = 0.11342592537403107\n","AUC of ROC = 0.8294365302573299\n","AUC of PRC = 0.47565095084450515\n","min(+P, Se) = 0.4722222222222222\n","f1_score = 0.1975806476732447\n","Epoch 79: Validation AUROC = 0.8294\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80 Batch 0: Train Loss = 0.3282\n","Epoch 80 Batch 50: Train Loss = 0.3212\n","Epoch 80: Train Loss = 0.3190\n","Epoch 80: Validation Loss = 0.3156\n","confusion matrix:\n","[[2719    7]\n"," [ 413   19]]\n","accuracy = 0.8670044541358948\n","precision class 0 = 0.868135392665863\n","precision class 1 = 0.7307692170143127\n","recall class 0 = 0.9974321126937866\n","recall class 1 = 0.04398148134350777\n","AUC of ROC = 0.8260908331295344\n","AUC of PRC = 0.4777145728563039\n","min(+P, Se) = 0.4665127020785219\n","f1_score = 0.08296943078340503\n","Epoch 80: Validation AUROC = 0.8261\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81 Batch 0: Train Loss = 0.2715\n","Epoch 81 Batch 50: Train Loss = 0.3192\n","Epoch 81: Train Loss = 0.3192\n","Epoch 81: Validation Loss = 0.3093\n","confusion matrix:\n","[[2700   26]\n"," [ 374   58]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.8783344030380249\n","precision class 1 = 0.6904761791229248\n","recall class 0 = 0.9904622435569763\n","recall class 1 = 0.13425925374031067\n","AUC of ROC = 0.8267930898616885\n","AUC of PRC = 0.46917938980064894\n","min(+P, Se) = 0.48299319727891155\n","f1_score = 0.22480620133548007\n","Epoch 81: Validation AUROC = 0.8268\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82 Batch 0: Train Loss = 0.3085\n","Epoch 82 Batch 50: Train Loss = 0.3180\n","Epoch 82: Train Loss = 0.3203\n","Epoch 82: Validation Loss = 0.3096\n","confusion matrix:\n","[[2694   32]\n"," [ 365   67]]\n","accuracy = 0.8742875456809998\n","precision class 0 = 0.8806799650192261\n","precision class 1 = 0.6767676472663879\n","recall class 0 = 0.9882611632347107\n","recall class 1 = 0.15509259700775146\n","AUC of ROC = 0.8300317926143311\n","AUC of PRC = 0.46563474244204034\n","min(+P, Se) = 0.47453703703703703\n","f1_score = 0.25235405275788103\n","Epoch 82: Validation AUROC = 0.8300\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83 Batch 0: Train Loss = 0.3069\n","Epoch 83 Batch 50: Train Loss = 0.3217\n","Epoch 83: Train Loss = 0.3209\n","Epoch 83: Validation Loss = 0.3092\n","confusion matrix:\n","[[2712   14]\n"," [ 398   34]]\n","accuracy = 0.8695377111434937\n","precision class 0 = 0.872025728225708\n","precision class 1 = 0.7083333134651184\n","recall class 0 = 0.994864284992218\n","recall class 1 = 0.07870370149612427\n","AUC of ROC = 0.8303833455612619\n","AUC of PRC = 0.4657359042306672\n","min(+P, Se) = 0.4815668202764977\n","f1_score = 0.1416666626930237\n","Epoch 83: Validation AUROC = 0.8304\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84 Batch 0: Train Loss = 0.2961\n","Epoch 84 Batch 50: Train Loss = 0.3215\n","Epoch 84: Train Loss = 0.3196\n","Epoch 84: Validation Loss = 0.3074\n","confusion matrix:\n","[[2696   30]\n"," [ 374   58]]\n","accuracy = 0.8720709085464478\n","precision class 0 = 0.8781759142875671\n","precision class 1 = 0.6590909361839294\n","recall class 0 = 0.988994836807251\n","recall class 1 = 0.13425925374031067\n","AUC of ROC = 0.831025311812179\n","AUC of PRC = 0.4730496887969211\n","min(+P, Se) = 0.4760820045558087\n","f1_score = 0.22307690863073282\n","Epoch 84: Validation AUROC = 0.8310\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85 Batch 0: Train Loss = 0.3137\n","Epoch 85 Batch 50: Train Loss = 0.3222\n","Epoch 85: Train Loss = 0.3241\n","Epoch 85: Validation Loss = 0.3113\n","confusion matrix:\n","[[2709   17]\n"," [ 395   37]]\n","accuracy = 0.8695377111434937\n","precision class 0 = 0.8727448582649231\n","precision class 1 = 0.6851851940155029\n","recall class 0 = 0.9937637448310852\n","recall class 1 = 0.08564814925193787\n","AUC of ROC = 0.8290195918589168\n","AUC of PRC = 0.4670657609918052\n","min(+P, Se) = 0.47685185185185186\n","f1_score = 0.15226337056101127\n","Epoch 85: Validation AUROC = 0.8290\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86 Batch 0: Train Loss = 0.3186\n","Epoch 86 Batch 50: Train Loss = 0.3203\n","Epoch 86: Train Loss = 0.3224\n","Epoch 86: Validation Loss = 0.3130\n","confusion matrix:\n","[[2687   39]\n"," [ 355   77]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8833004832267761\n","precision class 1 = 0.6637930870056152\n","recall class 0 = 0.9856933355331421\n","recall class 1 = 0.17824074625968933\n","AUC of ROC = 0.8233471916524008\n","AUC of PRC = 0.45337630930236017\n","min(+P, Se) = 0.4590909090909091\n","f1_score = 0.2810218932499189\n","Epoch 86: Validation AUROC = 0.8233\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87 Batch 0: Train Loss = 0.3020\n","Epoch 87 Batch 50: Train Loss = 0.3202\n","Epoch 87: Train Loss = 0.3184\n","Epoch 87: Validation Loss = 0.3082\n","confusion matrix:\n","[[2698   28]\n"," [ 367   65]]\n","accuracy = 0.8749208450317383\n","precision class 0 = 0.8802610039710999\n","precision class 1 = 0.698924720287323\n","recall class 0 = 0.9897285103797913\n","recall class 1 = 0.15046297013759613\n","AUC of ROC = 0.8312894011032308\n","AUC of PRC = 0.4679105374558559\n","min(+P, Se) = 0.4675925925925926\n","f1_score = 0.24761905230697295\n","Epoch 87: Validation AUROC = 0.8313\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88 Batch 0: Train Loss = 0.3749\n","Epoch 88 Batch 50: Train Loss = 0.3210\n","Epoch 88: Train Loss = 0.3202\n","Epoch 88: Validation Loss = 0.3143\n","confusion matrix:\n","[[2707   19]\n"," [ 387   45]]\n","accuracy = 0.8714376091957092\n","precision class 0 = 0.8749191761016846\n","precision class 1 = 0.703125\n","recall class 0 = 0.9930300712585449\n","recall class 1 = 0.1041666641831398\n","AUC of ROC = 0.8225837952773023\n","AUC of PRC = 0.4594126046263483\n","min(+P, Se) = 0.4608294930875576\n","f1_score = 0.18145160411138586\n","Epoch 88: Validation AUROC = 0.8226\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89 Batch 0: Train Loss = 0.2908\n","Epoch 89 Batch 50: Train Loss = 0.3199\n","Epoch 89: Train Loss = 0.3191\n","Epoch 89: Validation Loss = 0.3128\n","confusion matrix:\n","[[2716   10]\n"," [ 408   24]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.8693982362747192\n","precision class 1 = 0.7058823704719543\n","recall class 0 = 0.9963316321372986\n","recall class 1 = 0.0555555559694767\n","AUC of ROC = 0.8319398589712237\n","AUC of PRC = 0.4635910549999061\n","min(+P, Se) = 0.46756152125279643\n","f1_score = 0.10300428921599007\n","Epoch 89: Validation AUROC = 0.8319\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90 Batch 0: Train Loss = 0.3029\n","Epoch 90 Batch 50: Train Loss = 0.3221\n","Epoch 90: Train Loss = 0.3195\n","Epoch 90: Validation Loss = 0.3084\n","confusion matrix:\n","[[2702   24]\n"," [ 375   57]]\n","accuracy = 0.8736541867256165\n","precision class 0 = 0.8781280517578125\n","precision class 1 = 0.7037037014961243\n","recall class 0 = 0.9911959171295166\n","recall class 1 = 0.1319444477558136\n","AUC of ROC = 0.829539278823945\n","AUC of PRC = 0.46670076683389755\n","min(+P, Se) = 0.4608294930875576\n","f1_score = 0.22222221888333488\n","Epoch 90: Validation AUROC = 0.8295\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91 Batch 0: Train Loss = 0.3390\n","Epoch 91 Batch 50: Train Loss = 0.3224\n","Epoch 91: Train Loss = 0.3177\n","Epoch 91: Validation Loss = 0.3186\n","confusion matrix:\n","[[2716   10]\n"," [ 411   21]]\n","accuracy = 0.8666877746582031\n","precision class 0 = 0.8685641288757324\n","precision class 1 = 0.6774193644523621\n","recall class 0 = 0.9963316321372986\n","recall class 1 = 0.0486111119389534\n","AUC of ROC = 0.8273628773674628\n","AUC of PRC = 0.46538535719823376\n","min(+P, Se) = 0.4700460829493088\n","f1_score = 0.09071274543905262\n","Epoch 91: Validation AUROC = 0.8274\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92 Batch 0: Train Loss = 0.3251\n","Epoch 92 Batch 50: Train Loss = 0.3179\n","Epoch 92: Train Loss = 0.3185\n","Epoch 92: Validation Loss = 0.3125\n","confusion matrix:\n","[[2716   10]\n"," [ 403   29]]\n","accuracy = 0.869221031665802\n","precision class 0 = 0.8707919120788574\n","precision class 1 = 0.7435897588729858\n","recall class 0 = 0.9963316321372986\n","recall class 1 = 0.06712962687015533\n","AUC of ROC = 0.8265604195538165\n","AUC of PRC = 0.47358143631862576\n","min(+P, Se) = 0.46543778801843316\n","f1_score = 0.12314224836091103\n","Epoch 92: Validation AUROC = 0.8266\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93 Batch 0: Train Loss = 0.3017\n","Epoch 93 Batch 50: Train Loss = 0.3177\n","Epoch 93: Train Loss = 0.3143\n","Epoch 93: Validation Loss = 0.3143\n","confusion matrix:\n","[[2713   13]\n"," [ 394   38]]\n","accuracy = 0.8711209893226624\n","precision class 0 = 0.8731895685195923\n","precision class 1 = 0.7450980544090271\n","recall class 0 = 0.9952310919761658\n","recall class 1 = 0.08796296268701553\n","AUC of ROC = 0.828332620037499\n","AUC of PRC = 0.46696551131441383\n","min(+P, Se) = 0.4675925925925926\n","f1_score = 0.15734989215578885\n","Epoch 93: Validation AUROC = 0.8283\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94 Batch 0: Train Loss = 0.3727\n","Epoch 94 Batch 50: Train Loss = 0.3195\n","Epoch 94: Train Loss = 0.3217\n","Epoch 94: Validation Loss = 0.3092\n","confusion matrix:\n","[[2708   18]\n"," [ 382   50]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.8763753771781921\n","precision class 1 = 0.7352941036224365\n","recall class 0 = 0.9933969378471375\n","recall class 1 = 0.11574073880910873\n","AUC of ROC = 0.8309650213309422\n","AUC of PRC = 0.47071382091728864\n","min(+P, Se) = 0.4652777777777778\n","f1_score = 0.2000000018501283\n","Epoch 94: Validation AUROC = 0.8310\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95 Batch 0: Train Loss = 0.2841\n","Epoch 95 Batch 50: Train Loss = 0.3162\n","Epoch 95: Train Loss = 0.3155\n","Epoch 95: Validation Loss = 0.3079\n","confusion matrix:\n","[[2704   22]\n"," [ 384   48]]\n","accuracy = 0.8714376091957092\n","precision class 0 = 0.8756476640701294\n","precision class 1 = 0.6857143044471741\n","recall class 0 = 0.9919295907020569\n","recall class 1 = 0.1111111119389534\n","AUC of ROC = 0.83274231678487\n","AUC of PRC = 0.47213980785320286\n","min(+P, Se) = 0.4722222222222222\n","f1_score = 0.19123506350369\n","Epoch 95: Validation AUROC = 0.8327\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96 Batch 0: Train Loss = 0.3207\n","Epoch 96 Batch 50: Train Loss = 0.3226\n","Epoch 96: Train Loss = 0.3229\n","Epoch 96: Validation Loss = 0.3126\n","confusion matrix:\n","[[2715   11]\n"," [ 407   25]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.8696348667144775\n","precision class 1 = 0.6944444179534912\n","recall class 0 = 0.995964765548706\n","recall class 1 = 0.05787036940455437\n","AUC of ROC = 0.8271098271786094\n","AUC of PRC = 0.4659579568756644\n","min(+P, Se) = 0.4759725400457666\n","f1_score = 0.10683760223304027\n","Epoch 96: Validation AUROC = 0.8271\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97 Batch 0: Train Loss = 0.2925\n","Epoch 97 Batch 50: Train Loss = 0.3236\n","Epoch 97: Train Loss = 0.3214\n","Epoch 97: Validation Loss = 0.3093\n","confusion matrix:\n","[[2703   23]\n"," [ 368   64]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8801693320274353\n","precision class 1 = 0.7356321811676025\n","recall class 0 = 0.9915627241134644\n","recall class 1 = 0.14814814925193787\n","AUC of ROC = 0.826186788402489\n","AUC of PRC = 0.47241315633732994\n","min(+P, Se) = 0.4700460829493088\n","f1_score = 0.24662812408003223\n","Epoch 97: Validation AUROC = 0.8262\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98 Batch 0: Train Loss = 0.3478\n","Epoch 98 Batch 50: Train Loss = 0.3213\n","Epoch 98: Train Loss = 0.3199\n","Epoch 98: Validation Loss = 0.3077\n","confusion matrix:\n","[[2694   32]\n"," [ 358   74]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.8826998472213745\n","precision class 1 = 0.698113203048706\n","recall class 0 = 0.9882611632347107\n","recall class 1 = 0.17129629850387573\n","AUC of ROC = 0.8284124412380098\n","AUC of PRC = 0.4726881667729642\n","min(+P, Se) = 0.48148148148148145\n","f1_score = 0.27509293930046963\n","Epoch 98: Validation AUROC = 0.8284\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99 Batch 0: Train Loss = 0.2942\n","Epoch 99 Batch 50: Train Loss = 0.3222\n","Epoch 99: Train Loss = 0.3212\n","Epoch 99: Validation Loss = 0.3098\n","confusion matrix:\n","[[2709   17]\n"," [ 390   42]]\n","accuracy = 0.8711209893226624\n","precision class 0 = 0.8741529583930969\n","precision class 1 = 0.7118644118309021\n","recall class 0 = 0.9937637448310852\n","recall class 1 = 0.0972222238779068\n","AUC of ROC = 0.8298645077579413\n","AUC of PRC = 0.47147945837359523\n","min(+P, Se) = 0.4618937644341801\n","f1_score = 0.17107943559529498\n","Epoch 99: Validation AUROC = 0.8299\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"IW0R1nGs8iQC"}},{"cell_type":"code","source":["file_name = 'model/concare_nodecov'\n","BATCH_SIZE = 256\n","\n","checkpoint = torch.load(file_name)\n","save_epoch = checkpoint['epoch']\n","model.load_state_dict(checkpoint['net'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6qOWCnDE8jQd","executionInfo":{"status":"ok","timestamp":1682990996091,"user_tz":300,"elapsed":401,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"a3e78600-796e-4c1f-9336-d951612733e6"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConCare_NoDecov(\n","  (demo_embed): DemographicEmbed(\n","    (fc): Linear(in_features=12, out_features=64, bias=True)\n","  )\n","  (grus): ModuleList(\n","    (0-75): 76 x GRU(1, 64, batch_first=True)\n","  )\n","  (time_attns): ModuleList(\n","    (0-75): 76 x TimeAwareSelfAttention()\n","  )\n","  (multi_attn): MultiHeadAttentionNoDecov(\n","    (w_qs): Linear(in_features=64, out_features=64, bias=False)\n","    (w_ks): Linear(in_features=64, out_features=64, bias=False)\n","    (w_vs): Linear(in_features=64, out_features=64, bias=False)\n","    (fc): Linear(in_features=64, out_features=64, bias=False)\n","    (attn): ScaledDotProductAttention(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_attn): FinalAttention(\n","    (w_qs): Linear(in_features=64, out_features=64, bias=True)\n","    (w_ks): Linear(in_features=64, out_features=64, bias=True)\n","    (w_vs): Linear(in_features=64, out_features=64, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (res): ResConnect(\n","    (lnorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (pos_ff): PositionwiseFeedForward(\n","    (fc1): Linear(in_features=64, out_features=256, bias=True)\n","    (fc2): Linear(in_features=256, out_features=64, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (output_fc1): Linear(in_features=64, out_features=64, bias=True)\n","  (output_fc2): Linear(in_features=64, out_features=1, bias=True)\n","  (dp): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["batch_loss = []\n","y_true = []\n","y_pred = []\n","with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(test_loader):\n","        batch_x = batch_x.float().to(device)\n","        batch_y = batch_y.float().to(device)\n","        batch_demo = []\n","        for i in range(len(batch_name)):\n","            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","            cur_idx = cur_id + '_' + cur_ep\n","            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","            batch_demo.append(cur_demo)\n","\n","        batch_demo = torch.stack(batch_demo).to(device)\n","        output = model(batch_x, batch_demo)\n","\n","        loss = loss_func(output, batch_y.unsqueeze(-1))\n","        batch_loss.append(loss.cpu().detach().numpy())\n","        y_pred += list(output.cpu().detach().numpy().flatten())\n","        y_true += list(batch_y.cpu().numpy().flatten())\n","\n","print(\"\\nTest Prediction Result\")\n","y_pred = np.array(y_pred)\n","y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","test_res = metrics.print_metrics_binary(y_true, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8PZ0El48pyV","executionInfo":{"status":"ok","timestamp":1682990998521,"user_tz":300,"elapsed":2432,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"92637daf-bfd1-4fea-b8e5-29f1a5bb28c6"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-2ab15b308a62>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-21-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Prediction Result\n","confusion matrix:\n","[[2836   26]\n"," [ 336   38]]\n","accuracy = 0.8881335258483887\n","precision class 0 = 0.8940731287002563\n","precision class 1 = 0.59375\n","recall class 0 = 0.9909154176712036\n","recall class 1 = 0.10160427540540695\n","AUC of ROC = 0.8287564883014384\n","AUC of PRC = 0.388782436737815\n","min(+P, Se) = 0.4074074074074074\n","f1_score = 0.17351597598329485\n"]}]},{"cell_type":"markdown","source":["## Fixed time decay rate"],"metadata":{"id":"YJ-894BnJryQ"}},{"cell_type":"code","source":["class FixedDecaySelfAttention(nn.Module):\n","  def __init__(self, input_dim, hidden_dim):\n","    super().__init__()\n","    self.input_dim = input_dim\n","    self.hidden_dim = hidden_dim\n","\n","    self.w_qs = nn.Parameter(torch.randn(input_dim, hidden_dim))\n","    self.w_ks = nn.Parameter(torch.randn(input_dim, hidden_dim))\n","    # self.beta = nn.Parameter(torch.zeros(1)+0.8)\n","\n","    nn.init.kaiming_uniform_(self.w_qs, a=math.sqrt(5))\n","    nn.init.kaiming_uniform_(self.w_ks, a=math.sqrt(5))\n","  \n","  def forward(self, input):\n","    b, time_step, input_dim = input.size()\n","    time_decays = torch.tensor(range(47, -1, -1), dtype=torch.float32).unsqueeze(-1).unsqueeze(0).to(device) # 1*T*1\n","    b_time_decays = time_decays.repeat(b, 1, 1)+1 # B*T*1\n","\n","    q = torch.matmul(input[:, -1, :], self.w_qs).reshape(b, 1, self.hidden_dim) # B*1*H\n","    k = torch.matmul(input, self.w_ks) # B*T*H\n","    v = input # B*T*H\n","    product = torch.matmul(q, k.transpose(1, 2)).squeeze() # B*T\n","    denominator = 0.8 * torch.log(math.e + (1 - F.sigmoid(product)) * (b_time_decays.squeeze()))\n","    weights = F.softmax(F.tanh(product / denominator)) # B*T\n","    output = torch.matmul(weights.unsqueeze(1), v).squeeze() # B*H\n","\n","    return output, weights"],"metadata":{"id":"8MkrEry2rKzD","executionInfo":{"status":"ok","timestamp":1682894433681,"user_tz":300,"elapsed":5,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["class ConCare_FD(nn.Module):\n","  def __init__(self, demo_input_dim, input_dim, hidden_dim1, hidden_dim2, d_model, n_head, ff_hidden, output_dim, dropout=0.5):\n","    super().__init__()\n","    self.demo_input_dim = demo_input_dim\n","    self.input_dim = input_dim\n","    self.hidden_dim1 = hidden_dim1\n","    self.hidden_dim2 = hidden_dim2\n","    self.d_model = d_model\n","    self.n_head = n_head\n","    self.ff_hidden = ff_hidden\n","    self.output_dim = output_dim\n","    self.dropout = dropout\n","\n","    self.demo_embed = DemographicEmbed(self.demo_input_dim, self.hidden_dim1)\n","    self.grus = nn.ModuleList([copy.deepcopy(nn.GRU(1, self.hidden_dim1, batch_first=True)) for _ in range(self.input_dim)])\n","    self.time_attns = nn.ModuleList([copy.deepcopy(FixedDecaySelfAttention(self.hidden_dim1, self.hidden_dim2)) for _ in range(self.input_dim)])\n","    self.multi_attn = MultiHeadAttention(self.n_head, self.d_model)\n","    self.final_attn = FinalAttention(self.hidden_dim1, self.hidden_dim1, dropout=self.dropout)\n","    self.res = ResConnect(self.d_model, dropout=self.dropout)\n","    self.pos_ff = PositionwiseFeedForward(self.d_model, self.ff_hidden, dropout=0.1)\n","    self.output_fc1 = nn.Linear(self.hidden_dim1, self.hidden_dim1)\n","    self.output_fc2 = nn.Linear(self.hidden_dim1, self.output_dim)\n","    self.dp = nn.Dropout(self.dropout)\n","  \n","  def forward(self, input, demo):\n","    # Demographic embedding\n","    demo_embedding = self.demo_embed(demo)\n","\n","    # First record embedding\n","    batch_size = input.size(0)\n","    feat_dim = input.size(2)\n","    record_embedding1 = self.grus[0](input[:, :, 0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim1).unsqueeze(0)).to(device))[0] # B*1*H\n","    time_attn_output = self.time_attns[0](record_embedding1)[0].unsqueeze(1) # B*1*H\n","\n","    # All other records embeddings\n","    for i in range(1, feat_dim):\n","      embedding = self.grus[i](input[:, :, i].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim1).unsqueeze(0)).to(device))[0] # B*1*H\n","      attn = self.time_attns[i](embedding)[0].unsqueeze(1) # B*1*H\n","      time_attn_output = torch.cat((time_attn_output, attn), 1)\n","    \n","    # Combine with demographic embedding\n","    demo_embedding = demo_embedding.unsqueeze(1)\n","    time_attn_output = torch.cat((time_attn_output, demo_embedding), 1)\n","    time_attn_output = self.dp(time_attn_output)\n","\n","    # Get multi-head attention\n","    multi_attn_output, dev_loss = self.res(time_attn_output, lambda x: self.multi_attn(time_attn_output, time_attn_output, time_attn_output))\n","    final_input = self.res(multi_attn_output, lambda x: self.pos_ff(multi_attn_output))[0]\n","\n","    # Get final output\n","    value, score = self.final_attn(final_input)\n","    output = F.sigmoid(self.output_fc2(F.relu(self.output_fc1(value))))\n","\n","    return output, dev_loss"],"metadata":{"id":"P_8a0haMKO1E","executionInfo":{"status":"ok","timestamp":1682894433681,"user_tz":300,"elapsed":4,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"b20AXbPTKfBG"}},{"cell_type":"code","source":["model = ConCare_FD(demo_input_dim=12, input_dim=76, hidden_dim1=64, hidden_dim2=8, d_model=64, n_head=4, ff_hidden=256, output_dim=1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.BCELoss()"],"metadata":{"id":"fkMADpv8KeVA","executionInfo":{"status":"ok","timestamp":1682894433681,"user_tz":300,"elapsed":4,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["max_roc = 0\n","max_prc = 0\n","train_total_loss = []\n","val_total_loss = []\n","result_history = []\n","file_name = 'model/concare_fd'\n","\n","\n","for epoch in range(100):\n","  \n","  # Start training\n","  train_batch_total_loss = []\n","  model.train()\n","\n","  for step, (batch_x, batch_y, batch_name) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","    batch_x = batch_x.float().to(device)\n","    batch_y = batch_y.float().to(device)\n","\n","    # Get batch demographic data\n","    batch_demo = []\n","    for i in range(len(batch_name)):\n","      cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","      cur_idx = cur_id + '_' + cur_ep\n","      cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","      batch_demo.append(cur_demo)\n","    batch_demo = torch.stack(batch_demo).to(device)\n","\n","    # Get model outputs\n","    output, decov_loss = model(batch_x, batch_demo)\n","\n","    # Get loss\n","    loss = loss_func(output, batch_y.unsqueeze(-1))\n","    loss += 800 * decov_loss\n","    train_batch_total_loss.append(loss.cpu().detach().numpy())\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    if step % 50 == 0:\n","      print('Epoch %d Batch %d: Train Loss = %.4f'%(epoch, step, np.mean(np.array(train_batch_total_loss))))\n","    \n","  train_total_loss.append(np.mean(np.array(train_batch_total_loss)))\n","  print('Epoch %d: Train Loss = %.4f'%(epoch, np.mean(np.array(train_batch_total_loss))))\n","\n","  # Start Validating\n","  val_batch_total_loss = []\n","  y_true = []\n","  y_pred = []\n","\n","  with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(val_loader):\n","      batch_x = batch_x.float().to(device)\n","      batch_y = batch_y.float().to(device)\n","\n","      # Get batch demographic data\n","      batch_demo = []\n","      for i in range(len(batch_name)):\n","        cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","        cur_idx = cur_id + '_' + cur_ep\n","        cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","        batch_demo.append(cur_demo)\n","      batch_demo = torch.stack(batch_demo).to(device)\n","\n","      # Get model outputs\n","      output, decov_loss = model(batch_x, batch_demo)\n","\n","      # Get loss\n","      loss = loss_func(output, batch_y.unsqueeze(-1))\n","      loss += 10 * decov_loss\n","      val_batch_total_loss.append(loss.cpu().detach().numpy())\n","      y_pred += list(output.cpu().detach().numpy())\n","      y_true += list(batch_y.cpu().numpy().flatten())\n","    \n","    val_total_loss.append(np.mean(np.array(val_batch_total_loss)))\n","    print('Epoch %d: Validation Loss = %.4f'%(epoch, np.mean(np.array(val_batch_total_loss))))\n","\n","    y_pred = np.array(y_pred)\n","    y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","    result = metrics.print_metrics_binary(y_true, y_pred)\n","    result_history.append(result)\n","\n","    cur_auroc = result['auroc']\n","    print('Epoch %d: Validation AUROC = %.4f'%(epoch, cur_auroc))\n","    \n","    if cur_auroc > max_roc:\n","        max_roc = cur_auroc\n","        state = {\n","            'net': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'epoch': epoch\n","        }\n","        torch.save(state, file_name)\n","        print('\\n------------ Save best model ------------\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zEMLbolqKlqp","executionInfo":{"status":"ok","timestamp":1682896523824,"user_tz":300,"elapsed":2090146,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"40b4be12-d110-4214-d04d-a5a8065725ac"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 Batch 0: Train Loss = 0.6829\n","Epoch 0 Batch 50: Train Loss = 0.4698\n","Epoch 0: Train Loss = 0.4609\n","Epoch 0: Validation Loss = 0.3991\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6890085357734844\n","AUC of PRC = 0.2500454733183925\n","min(+P, Se) = 0.25925925925925924\n","f1_score = nan\n","Epoch 0: Validation AUROC = 0.6890\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0: Train Loss = 0.4573\n","Epoch 1 Batch 50: Train Loss = 0.4003\n","Epoch 1: Train Loss = 0.3994\n","Epoch 1: Validation Loss = 0.3974\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.748746637319638\n","AUC of PRC = 0.3429031289278273\n","min(+P, Se) = 0.36009174311926606\n","f1_score = nan\n","Epoch 1: Validation AUROC = 0.7487\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Batch 0: Train Loss = 0.4108\n","Epoch 2 Batch 50: Train Loss = 0.4016\n","Epoch 2: Train Loss = 0.3985\n","Epoch 2: Validation Loss = 0.3959\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7175985367245454\n","AUC of PRC = 0.3561162793965117\n","min(+P, Se) = 0.38636363636363635\n","f1_score = nan\n","Epoch 2: Validation AUROC = 0.7176\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Batch 0: Train Loss = 0.3594\n","Epoch 3 Batch 50: Train Loss = 0.3974\n","Epoch 3: Train Loss = 0.3964\n","Epoch 3: Validation Loss = 0.3927\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.767615435042526\n","AUC of PRC = 0.36323356740492085\n","min(+P, Se) = 0.41898148148148145\n","f1_score = nan\n","Epoch 3: Validation AUROC = 0.7676\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 Batch 0: Train Loss = 0.3970\n","Epoch 4 Batch 50: Train Loss = 0.3908\n","Epoch 4: Train Loss = 0.3893\n","Epoch 4: Validation Loss = 0.3688\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7344960055433276\n","AUC of PRC = 0.31889342934547105\n","min(+P, Se) = 0.36818181818181817\n","f1_score = nan\n","Epoch 4: Validation AUROC = 0.7345\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 Batch 0: Train Loss = 0.3851\n","Epoch 5 Batch 50: Train Loss = 0.3710\n","Epoch 5: Train Loss = 0.3698\n","Epoch 5: Validation Loss = 0.3439\n","confusion matrix:\n","[[2726    0]\n"," [ 430    2]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8637515902519226\n","precision class 1 = 1.0\n","recall class 0 = 1.0\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7816830724708567\n","AUC of PRC = 0.37571396475465024\n","min(+P, Se) = 0.41435185185185186\n","f1_score = 0.00921659009244084\n","Epoch 5: Validation AUROC = 0.7817\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 Batch 0: Train Loss = 0.3954\n","Epoch 6 Batch 50: Train Loss = 0.3507\n","Epoch 6: Train Loss = 0.3521\n","Epoch 6: Validation Loss = 0.3288\n","confusion matrix:\n","[[2724    2]\n"," [ 421   11]]\n","accuracy = 0.8660544753074646\n","precision class 0 = 0.8661367297172546\n","precision class 1 = 0.8461538553237915\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.025462962687015533\n","AUC of ROC = 0.8088112415423494\n","AUC of PRC = 0.4309076065321146\n","min(+P, Se) = 0.45852534562211983\n","f1_score = 0.04943820047492924\n","Epoch 6: Validation AUROC = 0.8088\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 Batch 0: Train Loss = 0.3413\n","Epoch 7 Batch 50: Train Loss = 0.3361\n","Epoch 7: Train Loss = 0.3384\n","Epoch 7: Validation Loss = 0.3202\n","confusion matrix:\n","[[2693   33]\n"," [ 365   67]]\n","accuracy = 0.8739708662033081\n","precision class 0 = 0.8806409239768982\n","precision class 1 = 0.6700000166893005\n","recall class 0 = 0.9878943562507629\n","recall class 1 = 0.15509259700775146\n","AUC of ROC = 0.8154219654357218\n","AUC of PRC = 0.4507886339029481\n","min(+P, Se) = 0.47685185185185186\n","f1_score = 0.25187970625012446\n","Epoch 7: Validation AUROC = 0.8154\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 Batch 0: Train Loss = 0.3706\n","Epoch 8 Batch 50: Train Loss = 0.3357\n","Epoch 8: Train Loss = 0.3321\n","Epoch 8: Validation Loss = 0.3224\n","confusion matrix:\n","[[2711   15]\n"," [ 403   29]]\n","accuracy = 0.8676377534866333\n","precision class 0 = 0.8705844283103943\n","precision class 1 = 0.6590909361839294\n","recall class 0 = 0.9944974184036255\n","recall class 1 = 0.06712962687015533\n","AUC of ROC = 0.8174658976658243\n","AUC of PRC = 0.45456756100519924\n","min(+P, Se) = 0.46697038724373574\n","f1_score = 0.12184873791318769\n","Epoch 8: Validation AUROC = 0.8175\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 Batch 0: Train Loss = 0.3006\n","Epoch 9 Batch 50: Train Loss = 0.3262\n","Epoch 9: Train Loss = 0.3269\n","Epoch 9: Validation Loss = 0.3109\n","confusion matrix:\n","[[2684   42]\n"," [ 363   69]]\n","accuracy = 0.8717542886734009\n","precision class 0 = 0.8808664083480835\n","precision class 1 = 0.6216216087341309\n","recall class 0 = 0.9845927953720093\n","recall class 1 = 0.1597222238779068\n","AUC of ROC = 0.8245546996005543\n","AUC of PRC = 0.45181357861715976\n","min(+P, Se) = 0.4840182648401826\n","f1_score = 0.2541436522745148\n","Epoch 9: Validation AUROC = 0.8246\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 Batch 0: Train Loss = 0.3160\n","Epoch 10 Batch 50: Train Loss = 0.3175\n","Epoch 10: Train Loss = 0.3195\n","Epoch 10: Validation Loss = 0.3095\n","confusion matrix:\n","[[2675   51]\n"," [ 335   97]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.8887042999267578\n","precision class 1 = 0.6554054021835327\n","recall class 0 = 0.9812912940979004\n","recall class 1 = 0.22453702986240387\n","AUC of ROC = 0.8276541398331567\n","AUC of PRC = 0.46537471869129265\n","min(+P, Se) = 0.47477064220183485\n","f1_score = 0.3344827559048157\n","Epoch 10: Validation AUROC = 0.8277\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11 Batch 0: Train Loss = 0.3429\n","Epoch 11 Batch 50: Train Loss = 0.3122\n","Epoch 11: Train Loss = 0.3149\n","Epoch 11: Validation Loss = 0.3078\n","confusion matrix:\n","[[2690   36]\n"," [ 362   70]]\n","accuracy = 0.8739708662033081\n","precision class 0 = 0.8813892602920532\n","precision class 1 = 0.6603773832321167\n","recall class 0 = 0.9867938160896301\n","recall class 1 = 0.16203702986240387\n","AUC of ROC = 0.8273764639547838\n","AUC of PRC = 0.4711945555310887\n","min(+P, Se) = 0.4735632183908046\n","f1_score = 0.2602230457110269\n","Epoch 11: Validation AUROC = 0.8274\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12 Batch 0: Train Loss = 0.2788\n","Epoch 12 Batch 50: Train Loss = 0.3167\n","Epoch 12: Train Loss = 0.3176\n","Epoch 12: Validation Loss = 0.3083\n","confusion matrix:\n","[[2697   29]\n"," [ 365   67]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8807968497276306\n","precision class 1 = 0.6979166865348816\n","recall class 0 = 0.9893617033958435\n","recall class 1 = 0.15509259700775146\n","AUC of ROC = 0.8285763294475694\n","AUC of PRC = 0.47555249800155597\n","min(+P, Se) = 0.47465437788018433\n","f1_score = 0.2537878860126842\n","Epoch 12: Validation AUROC = 0.8286\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13 Batch 0: Train Loss = 0.3321\n","Epoch 13 Batch 50: Train Loss = 0.3129\n","Epoch 13: Train Loss = 0.3147\n","Epoch 13: Validation Loss = 0.3105\n","confusion matrix:\n","[[2659   67]\n"," [ 325  107]]\n","accuracy = 0.8758708238601685\n","precision class 0 = 0.8910858035087585\n","precision class 1 = 0.6149425506591797\n","recall class 0 = 0.9754218459129333\n","recall class 1 = 0.24768517911434174\n","AUC of ROC = 0.8304529768212819\n","AUC of PRC = 0.4728010727856471\n","min(+P, Se) = 0.47671840354767187\n","f1_score = 0.3531353048758932\n","Epoch 13: Validation AUROC = 0.8305\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14 Batch 0: Train Loss = 0.2534\n","Epoch 14 Batch 50: Train Loss = 0.3094\n","Epoch 14: Train Loss = 0.3077\n","Epoch 14: Validation Loss = 0.3049\n","confusion matrix:\n","[[2686   40]\n"," [ 348   84]]\n","accuracy = 0.8771374225616455\n","precision class 0 = 0.8852999210357666\n","precision class 1 = 0.6774193644523621\n","recall class 0 = 0.9853264689445496\n","recall class 1 = 0.1944444477558136\n","AUC of ROC = 0.8332365288986713\n","AUC of PRC = 0.48675536567141026\n","min(+P, Se) = 0.48322147651006714\n","f1_score = 0.302158268007283\n","Epoch 14: Validation AUROC = 0.8332\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15 Batch 0: Train Loss = 0.3618\n","Epoch 15 Batch 50: Train Loss = 0.3050\n","Epoch 15: Train Loss = 0.3057\n","Epoch 15: Validation Loss = 0.3034\n","confusion matrix:\n","[[2687   39]\n"," [ 345   87]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8862137198448181\n","precision class 1 = 0.6904761791229248\n","recall class 0 = 0.9856933355331421\n","recall class 1 = 0.2013888955116272\n","AUC of ROC = 0.8323491549142688\n","AUC of PRC = 0.4928726765510333\n","min(+P, Se) = 0.4782608695652174\n","f1_score = 0.31182796377049016\n","Epoch 15: Validation AUROC = 0.8323\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16 Batch 0: Train Loss = 0.2478\n","Epoch 16 Batch 50: Train Loss = 0.3035\n","Epoch 16: Train Loss = 0.3052\n","Epoch 16: Validation Loss = 0.3059\n","confusion matrix:\n","[[2635   91]\n"," [ 300  132]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8977853655815125\n","precision class 1 = 0.591928243637085\n","recall class 0 = 0.96661776304245\n","recall class 1 = 0.3055555522441864\n","AUC of ROC = 0.8371392761066274\n","AUC of PRC = 0.4955711191530609\n","min(+P, Se) = 0.4769585253456221\n","f1_score = 0.4030534171146726\n","Epoch 16: Validation AUROC = 0.8371\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17 Batch 0: Train Loss = 0.2584\n","Epoch 17 Batch 50: Train Loss = 0.3104\n","Epoch 17: Train Loss = 0.3067\n","Epoch 17: Validation Loss = 0.3119\n","confusion matrix:\n","[[2710   16]\n"," [ 375   57]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8784440755844116\n","precision class 1 = 0.7808219194412231\n","recall class 0 = 0.9941306114196777\n","recall class 1 = 0.1319444477558136\n","AUC of ROC = 0.8343786513953425\n","AUC of PRC = 0.4966177359936694\n","min(+P, Se) = 0.48148148148148145\n","f1_score = 0.22574258654272575\n","Epoch 17: Validation AUROC = 0.8344\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18 Batch 0: Train Loss = 0.2429\n","Epoch 18 Batch 50: Train Loss = 0.2995\n","Epoch 18: Train Loss = 0.2997\n","Epoch 18: Validation Loss = 0.3009\n","confusion matrix:\n","[[2677   49]\n"," [ 344   88]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.8861303925514221\n","precision class 1 = 0.6423357725143433\n","recall class 0 = 0.9820249676704407\n","recall class 1 = 0.20370370149612427\n","AUC of ROC = 0.8377133094209397\n","AUC of PRC = 0.4920025657791237\n","min(+P, Se) = 0.4840182648401826\n","f1_score = 0.30931458515592924\n","Epoch 18: Validation AUROC = 0.8377\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19 Batch 0: Train Loss = 0.2882\n","Epoch 19 Batch 50: Train Loss = 0.2993\n","Epoch 19: Train Loss = 0.3015\n","Epoch 19: Validation Loss = 0.3028\n","confusion matrix:\n","[[2696   30]\n"," [ 358   74]]\n","accuracy = 0.8771374225616455\n","precision class 0 = 0.88277667760849\n","precision class 1 = 0.7115384340286255\n","recall class 0 = 0.988994836807251\n","recall class 1 = 0.17129629850387573\n","AUC of ROC = 0.8361483043939024\n","AUC of PRC = 0.4938093150482167\n","min(+P, Se) = 0.4735632183908046\n","f1_score = 0.27611940378175054\n","Epoch 19: Validation AUROC = 0.8361\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20 Batch 0: Train Loss = 0.2386\n","Epoch 20 Batch 50: Train Loss = 0.3032\n","Epoch 20: Train Loss = 0.3012\n","Epoch 20: Validation Loss = 0.3013\n","confusion matrix:\n","[[2648   78]\n"," [ 306  126]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.896411657333374\n","precision class 1 = 0.6176470518112183\n","recall class 0 = 0.9713866710662842\n","recall class 1 = 0.2916666567325592\n","AUC of ROC = 0.8376207507948153\n","AUC of PRC = 0.4869607607425982\n","min(+P, Se) = 0.47113163972286376\n","f1_score = 0.39622641747088677\n","Epoch 20: Validation AUROC = 0.8376\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21 Batch 0: Train Loss = 0.3450\n","Epoch 21 Batch 50: Train Loss = 0.3009\n","Epoch 21: Train Loss = 0.3011\n","Epoch 21: Validation Loss = 0.3019\n","confusion matrix:\n","[[2696   30]\n"," [ 359   73]]\n","accuracy = 0.8768207430839539\n","precision class 0 = 0.8824877142906189\n","precision class 1 = 0.708737850189209\n","recall class 0 = 0.988994836807251\n","recall class 1 = 0.16898147761821747\n","AUC of ROC = 0.8385828510094834\n","AUC of PRC = 0.5037626287843948\n","min(+P, Se) = 0.49015317286652077\n","f1_score = 0.27289718556127157\n","Epoch 21: Validation AUROC = 0.8386\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22 Batch 0: Train Loss = 0.2877\n","Epoch 22 Batch 50: Train Loss = 0.2988\n","Epoch 22: Train Loss = 0.2995\n","Epoch 22: Validation Loss = 0.3002\n","confusion matrix:\n","[[2686   40]\n"," [ 346   86]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.8858839273452759\n","precision class 1 = 0.682539701461792\n","recall class 0 = 0.9853264689445496\n","recall class 1 = 0.19907407462596893\n","AUC of ROC = 0.8389165715605554\n","AUC of PRC = 0.49378070185424777\n","min(+P, Se) = 0.48409090909090907\n","f1_score = 0.30824372497979374\n","Epoch 22: Validation AUROC = 0.8389\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23 Batch 0: Train Loss = 0.3255\n","Epoch 23 Batch 50: Train Loss = 0.3002\n","Epoch 23: Train Loss = 0.3001\n","Epoch 23: Validation Loss = 0.3051\n","confusion matrix:\n","[[2706   20]\n"," [ 371   61]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8794280290603638\n","precision class 1 = 0.7530864477157593\n","recall class 0 = 0.9926632642745972\n","recall class 1 = 0.14120370149612427\n","AUC of ROC = 0.8378882367326975\n","AUC of PRC = 0.4929127995339981\n","min(+P, Se) = 0.47161572052401746\n","f1_score = 0.23781676239584282\n","Epoch 23: Validation AUROC = 0.8379\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24 Batch 0: Train Loss = 0.2704\n","Epoch 24 Batch 50: Train Loss = 0.2980\n","Epoch 24: Train Loss = 0.2952\n","Epoch 24: Validation Loss = 0.3065\n","confusion matrix:\n","[[2687   39]\n"," [ 353   79]]\n","accuracy = 0.8758708238601685\n","precision class 0 = 0.8838815689086914\n","precision class 1 = 0.6694915294647217\n","recall class 0 = 0.9856933355331421\n","recall class 1 = 0.18287037312984467\n","AUC of ROC = 0.8389097782668947\n","AUC of PRC = 0.48990055391196086\n","min(+P, Se) = 0.48847926267281105\n","f1_score = 0.2872727260274336\n","Epoch 24: Validation AUROC = 0.8389\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25 Batch 0: Train Loss = 0.3556\n","Epoch 25 Batch 50: Train Loss = 0.2995\n","Epoch 25: Train Loss = 0.2988\n","Epoch 25: Validation Loss = 0.2990\n","confusion matrix:\n","[[2679   47]\n"," [ 337   95]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8882625699043274\n","precision class 1 = 0.6690140962600708\n","recall class 0 = 0.982758641242981\n","recall class 1 = 0.21990740299224854\n","AUC of ROC = 0.838692392869759\n","AUC of PRC = 0.49903270908373537\n","min(+P, Se) = 0.4896073903002309\n","f1_score = 0.33101044939852037\n","Epoch 25: Validation AUROC = 0.8387\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26 Batch 0: Train Loss = 0.2828\n","Epoch 26 Batch 50: Train Loss = 0.2948\n","Epoch 26: Train Loss = 0.2951\n","Epoch 26: Validation Loss = 0.3028\n","confusion matrix:\n","[[2657   69]\n"," [ 318  114]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.8931092619895935\n","precision class 1 = 0.6229507923126221\n","recall class 0 = 0.9746881723403931\n","recall class 1 = 0.2638888955116272\n","AUC of ROC = 0.8359708295970218\n","AUC of PRC = 0.4888899598316502\n","min(+P, Se) = 0.4791666666666667\n","f1_score = 0.3707317090077031\n","Epoch 26: Validation AUROC = 0.8360\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27 Batch 0: Train Loss = 0.2920\n","Epoch 27 Batch 50: Train Loss = 0.2980\n","Epoch 27: Train Loss = 0.2963\n","Epoch 27: Validation Loss = 0.3047\n","confusion matrix:\n","[[2694   32]\n"," [ 347   85]]\n","accuracy = 0.879987359046936\n","precision class 0 = 0.8858928084373474\n","precision class 1 = 0.7264957427978516\n","recall class 0 = 0.9882611632347107\n","recall class 1 = 0.19675925374031067\n","AUC of ROC = 0.8410267384038477\n","AUC of PRC = 0.5016400834307173\n","min(+P, Se) = 0.4976851851851852\n","f1_score = 0.3096539208530834\n","Epoch 27: Validation AUROC = 0.8410\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28 Batch 0: Train Loss = 0.2928\n","Epoch 28 Batch 50: Train Loss = 0.2976\n","Epoch 28: Train Loss = 0.2991\n","Epoch 28: Validation Loss = 0.2999\n","confusion matrix:\n","[[2677   49]\n"," [ 338   94]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.8878938555717468\n","precision class 1 = 0.6573426723480225\n","recall class 0 = 0.9820249676704407\n","recall class 1 = 0.21759259700775146\n","AUC of ROC = 0.8391942474389283\n","AUC of PRC = 0.4939570801144586\n","min(+P, Se) = 0.4861111111111111\n","f1_score = 0.32695652857962537\n","Epoch 28: Validation AUROC = 0.8392\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29 Batch 0: Train Loss = 0.2810\n","Epoch 29 Batch 50: Train Loss = 0.2927\n","Epoch 29: Train Loss = 0.2930\n","Epoch 29: Validation Loss = 0.2978\n","confusion matrix:\n","[[2684   42]\n"," [ 336   96]]\n","accuracy = 0.8803039789199829\n","precision class 0 = 0.8887417316436768\n","precision class 1 = 0.695652186870575\n","recall class 0 = 0.9845927953720093\n","recall class 1 = 0.2222222238779068\n","AUC of ROC = 0.8420270508953561\n","AUC of PRC = 0.49990006262329584\n","min(+P, Se) = 0.4930555555555556\n","f1_score = 0.3368421141526706\n","Epoch 29: Validation AUROC = 0.8420\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30 Batch 0: Train Loss = 0.3024\n","Epoch 30 Batch 50: Train Loss = 0.2946\n","Epoch 30: Train Loss = 0.2951\n","Epoch 30: Validation Loss = 0.2977\n","confusion matrix:\n","[[2673   53]\n"," [ 335   97]]\n","accuracy = 0.8771374225616455\n","precision class 0 = 0.8886303305625916\n","precision class 1 = 0.6466666460037231\n","recall class 0 = 0.9805576205253601\n","recall class 1 = 0.22453702986240387\n","AUC of ROC = 0.843769530719274\n","AUC of PRC = 0.497927187154469\n","min(+P, Se) = 0.4908675799086758\n","f1_score = 0.33333332838370056\n","Epoch 30: Validation AUROC = 0.8438\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31 Batch 0: Train Loss = 0.2372\n","Epoch 31 Batch 50: Train Loss = 0.2944\n","Epoch 31: Train Loss = 0.2970\n","Epoch 31: Validation Loss = 0.2969\n","confusion matrix:\n","[[2680   46]\n"," [ 340   92]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.887417197227478\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9831254482269287\n","recall class 1 = 0.21296297013759613\n","AUC of ROC = 0.8439070949158991\n","AUC of PRC = 0.5012981716062791\n","min(+P, Se) = 0.4838709677419355\n","f1_score = 0.3228070226468539\n","Epoch 31: Validation AUROC = 0.8439\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["\n","------------ Save best model ------------\n","\n","Epoch 32 Batch 0: Train Loss = 0.2853\n","Epoch 32 Batch 50: Train Loss = 0.2911\n","Epoch 32: Train Loss = 0.2917\n","Epoch 32: Validation Loss = 0.3003\n","confusion matrix:\n","[[2645   81]\n"," [ 301  131]]\n","accuracy = 0.8790373802185059\n","precision class 0 = 0.8978275656700134\n","precision class 1 = 0.6179245114326477\n","recall class 0 = 0.9702861309051514\n","recall class 1 = 0.30324074625968933\n","AUC of ROC = 0.8399576438140267\n","AUC of PRC = 0.5003173996847081\n","min(+P, Se) = 0.4930555555555556\n","f1_score = 0.40683231260953073\n","Epoch 32: Validation AUROC = 0.8400\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33 Batch 0: Train Loss = 0.2683\n","Epoch 33 Batch 50: Train Loss = 0.2902\n","Epoch 33: Train Loss = 0.2896\n","Epoch 33: Validation Loss = 0.3016\n","confusion matrix:\n","[[2680   46]\n"," [ 338   94]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8880053162574768\n","precision class 1 = 0.6714285612106323\n","recall class 0 = 0.9831254482269287\n","recall class 1 = 0.21759259700775146\n","AUC of ROC = 0.8411778891877939\n","AUC of PRC = 0.4941274084398594\n","min(+P, Se) = 0.4817351598173516\n","f1_score = 0.3286713324838806\n","Epoch 33: Validation AUROC = 0.8412\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34 Batch 0: Train Loss = 0.2149\n","Epoch 34 Batch 50: Train Loss = 0.2867\n","Epoch 34: Train Loss = 0.2892\n","Epoch 34: Validation Loss = 0.3040\n","confusion matrix:\n","[[2609  117]\n"," [ 274  158]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.9049600958824158\n","precision class 1 = 0.5745454430580139\n","recall class 0 = 0.9570799469947815\n","recall class 1 = 0.36574074625968933\n","AUC of ROC = 0.8399542471671966\n","AUC of PRC = 0.4950329914362613\n","min(+P, Se) = 0.47453703703703703\n","f1_score = 0.4469589964239063\n","Epoch 34: Validation AUROC = 0.8400\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35 Batch 0: Train Loss = 0.2942\n","Epoch 35 Batch 50: Train Loss = 0.2911\n","Epoch 35: Train Loss = 0.2894\n","Epoch 35: Validation Loss = 0.3055\n","confusion matrix:\n","[[2696   30]\n"," [ 352   80]]\n","accuracy = 0.8790373802185059\n","precision class 0 = 0.8845144510269165\n","precision class 1 = 0.7272727489471436\n","recall class 0 = 0.988994836807251\n","recall class 1 = 0.18518517911434174\n","AUC of ROC = 0.841051364093367\n","AUC of PRC = 0.4997796495376739\n","min(+P, Se) = 0.48036951501154734\n","f1_score = 0.29520294128070274\n","Epoch 35: Validation AUROC = 0.8411\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36 Batch 0: Train Loss = 0.2401\n","Epoch 36 Batch 50: Train Loss = 0.2950\n","Epoch 36: Train Loss = 0.2954\n","Epoch 36: Validation Loss = 0.3026\n","confusion matrix:\n","[[2678   48]\n"," [ 335   97]]\n","accuracy = 0.8787207007408142\n","precision class 0 = 0.8888151049613953\n","precision class 1 = 0.6689655184745789\n","recall class 0 = 0.9823917746543884\n","recall class 1 = 0.22453702986240387\n","AUC of ROC = 0.8370747398168528\n","AUC of PRC = 0.4885070408867724\n","min(+P, Se) = 0.4837962962962963\n","f1_score = 0.33622183480789003\n","Epoch 36: Validation AUROC = 0.8371\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37 Batch 0: Train Loss = 0.3216\n","Epoch 37 Batch 50: Train Loss = 0.2905\n","Epoch 37: Train Loss = 0.2907\n","Epoch 37: Validation Loss = 0.3016\n","confusion matrix:\n","[[2688   38]\n"," [ 348   84]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.8853754997253418\n","precision class 1 = 0.688524603843689\n","recall class 0 = 0.9860601425170898\n","recall class 1 = 0.1944444477558136\n","AUC of ROC = 0.8374398793511046\n","AUC of PRC = 0.49495548996466127\n","min(+P, Se) = 0.4896551724137931\n","f1_score = 0.3032491130621543\n","Epoch 37: Validation AUROC = 0.8374\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38 Batch 0: Train Loss = 0.2955\n","Epoch 38 Batch 50: Train Loss = 0.2874\n","Epoch 38: Train Loss = 0.2877\n","Epoch 38: Validation Loss = 0.3000\n","confusion matrix:\n","[[2660   66]\n"," [ 306  126]]\n","accuracy = 0.8822039365768433\n","precision class 0 = 0.8968307375907898\n","precision class 1 = 0.65625\n","recall class 0 = 0.9757887125015259\n","recall class 1 = 0.2916666567325592\n","AUC of ROC = 0.8389012866498192\n","AUC of PRC = 0.5008587598975985\n","min(+P, Se) = 0.48081264108352145\n","f1_score = 0.4038461570203658\n","Epoch 38: Validation AUROC = 0.8389\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39 Batch 0: Train Loss = 0.3014\n","Epoch 39 Batch 50: Train Loss = 0.2896\n","Epoch 39: Train Loss = 0.2893\n","Epoch 39: Validation Loss = 0.3025\n","confusion matrix:\n","[[2684   42]\n"," [ 341   91]]\n","accuracy = 0.8787207007408142\n","precision class 0 = 0.8872727155685425\n","precision class 1 = 0.6842105388641357\n","recall class 0 = 0.9845927953720093\n","recall class 1 = 0.21064814925193787\n","AUC of ROC = 0.8363283266759056\n","AUC of PRC = 0.489427659521066\n","min(+P, Se) = 0.48842592592592593\n","f1_score = 0.32212388575856643\n","Epoch 39: Validation AUROC = 0.8363\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40 Batch 0: Train Loss = 0.2575\n","Epoch 40 Batch 50: Train Loss = 0.2880\n","Epoch 40: Train Loss = 0.2880\n","Epoch 40: Validation Loss = 0.3007\n","confusion matrix:\n","[[2692   34]\n"," [ 347   85]]\n","accuracy = 0.8793540000915527\n","precision class 0 = 0.8858177065849304\n","precision class 1 = 0.7142857313156128\n","recall class 0 = 0.9875274896621704\n","recall class 1 = 0.19675925374031067\n","AUC of ROC = 0.8388061805385724\n","AUC of PRC = 0.4938186015000784\n","min(+P, Se) = 0.4838709677419355\n","f1_score = 0.30852995044989906\n","Epoch 40: Validation AUROC = 0.8388\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41 Batch 0: Train Loss = 0.2604\n","Epoch 41 Batch 50: Train Loss = 0.2900\n","Epoch 41: Train Loss = 0.2894\n","Epoch 41: Validation Loss = 0.3007\n","confusion matrix:\n","[[2682   44]\n"," [ 337   95]]\n","accuracy = 0.8793540000915527\n","precision class 0 = 0.888373613357544\n","precision class 1 = 0.6834532618522644\n","recall class 0 = 0.983859121799469\n","recall class 1 = 0.21990740299224854\n","AUC of ROC = 0.8380011752398033\n","AUC of PRC = 0.4934629238864926\n","min(+P, Se) = 0.48558758314855877\n","f1_score = 0.33274956001406547\n","Epoch 41: Validation AUROC = 0.8380\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42 Batch 0: Train Loss = 0.2796\n","Epoch 42 Batch 50: Train Loss = 0.2901\n","Epoch 42: Train Loss = 0.2895\n","Epoch 42: Validation Loss = 0.3048\n","confusion matrix:\n","[[2696   30]\n"," [ 361   71]]\n","accuracy = 0.8761874437332153\n","precision class 0 = 0.8819103837013245\n","precision class 1 = 0.7029703259468079\n","recall class 0 = 0.988994836807251\n","recall class 1 = 0.16435185074806213\n","AUC of ROC = 0.8399967052525747\n","AUC of PRC = 0.49837614056783536\n","min(+P, Se) = 0.4783599088838269\n","f1_score = 0.26641650179102233\n","Epoch 42: Validation AUROC = 0.8400\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43 Batch 0: Train Loss = 0.2741\n","Epoch 43 Batch 50: Train Loss = 0.2920\n","Epoch 43: Train Loss = 0.2903\n","Epoch 43: Validation Loss = 0.3024\n","confusion matrix:\n","[[2692   34]\n"," [ 353   79]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.8840722441673279\n","precision class 1 = 0.6991150379180908\n","recall class 0 = 0.9875274896621704\n","recall class 1 = 0.18287037312984467\n","AUC of ROC = 0.8391280128257385\n","AUC of PRC = 0.5016008455876125\n","min(+P, Se) = 0.4815668202764977\n","f1_score = 0.28990825490612\n","Epoch 43: Validation AUROC = 0.8391\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44 Batch 0: Train Loss = 0.2823\n","Epoch 44 Batch 50: Train Loss = 0.2885\n","Epoch 44: Train Loss = 0.2875\n","Epoch 44: Validation Loss = 0.3009\n","confusion matrix:\n","[[2675   51]\n"," [ 328  104]]\n","accuracy = 0.879987359046936\n","precision class 0 = 0.8907759189605713\n","precision class 1 = 0.6709677577018738\n","recall class 0 = 0.9812912940979004\n","recall class 1 = 0.24074074625968933\n","AUC of ROC = 0.8379442814053967\n","AUC of PRC = 0.4925224507167936\n","min(+P, Se) = 0.47453703703703703\n","f1_score = 0.3543441424174511\n","Epoch 44: Validation AUROC = 0.8379\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45 Batch 0: Train Loss = 0.3477\n","Epoch 45 Batch 50: Train Loss = 0.2853\n","Epoch 45: Train Loss = 0.2854\n","Epoch 45: Validation Loss = 0.3024\n","confusion matrix:\n","[[2681   45]\n"," [ 335   97]]\n","accuracy = 0.8796706795692444\n","precision class 0 = 0.8889257311820984\n","precision class 1 = 0.6830986142158508\n","recall class 0 = 0.9834923148155212\n","recall class 1 = 0.22453702986240387\n","AUC of ROC = 0.8384665158555474\n","AUC of PRC = 0.4983475289504236\n","min(+P, Se) = 0.47453703703703703\n","f1_score = 0.33797909427203465\n","Epoch 45: Validation AUROC = 0.8385\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46 Batch 0: Train Loss = 0.2843\n","Epoch 46 Batch 50: Train Loss = 0.2867\n","Epoch 46: Train Loss = 0.2852\n","Epoch 46: Validation Loss = 0.3024\n","confusion matrix:\n","[[2671   55]\n"," [ 327  105]]\n","accuracy = 0.8790373802185059\n","precision class 0 = 0.890927255153656\n","precision class 1 = 0.65625\n","recall class 0 = 0.9798239469528198\n","recall class 1 = 0.2430555522441864\n","AUC of ROC = 0.8386966386782969\n","AUC of PRC = 0.4981810878965144\n","min(+P, Se) = 0.4791666666666667\n","f1_score = 0.3547297144476043\n","Epoch 46: Validation AUROC = 0.8387\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47 Batch 0: Train Loss = 0.3049\n","Epoch 47 Batch 50: Train Loss = 0.2859\n","Epoch 47: Train Loss = 0.2868\n","Epoch 47: Validation Loss = 0.3095\n","confusion matrix:\n","[[2699   27]\n"," [ 362   70]]\n","accuracy = 0.8768207430839539\n","precision class 0 = 0.881738007068634\n","precision class 1 = 0.7216494679450989\n","recall class 0 = 0.9900953769683838\n","recall class 1 = 0.16203702986240387\n","AUC of ROC = 0.8397411075785984\n","AUC of PRC = 0.5016082877370853\n","min(+P, Se) = 0.4815668202764977\n","f1_score = 0.2646502773314486\n","Epoch 47: Validation AUROC = 0.8397\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48 Batch 0: Train Loss = 0.2672\n","Epoch 48 Batch 50: Train Loss = 0.2845\n","Epoch 48: Train Loss = 0.2862\n","Epoch 48: Validation Loss = 0.3047\n","confusion matrix:\n","[[2651   75]\n"," [ 314  118]]\n","accuracy = 0.8768207430839539\n","precision class 0 = 0.8940978050231934\n","precision class 1 = 0.6113989353179932\n","recall class 0 = 0.9724871516227722\n","recall class 1 = 0.27314814925193787\n","AUC of ROC = 0.836682427107959\n","AUC of PRC = 0.48680902580033886\n","min(+P, Se) = 0.47685185185185186\n","f1_score = 0.37759998291381836\n","Epoch 48: Validation AUROC = 0.8367\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49 Batch 0: Train Loss = 0.2978\n","Epoch 49 Batch 50: Train Loss = 0.2872\n","Epoch 49: Train Loss = 0.2863\n","Epoch 49: Validation Loss = 0.2990\n","confusion matrix:\n","[[2662   64]\n"," [ 319  113]]\n","accuracy = 0.8787207007408142\n","precision class 0 = 0.892988920211792\n","precision class 1 = 0.6384180784225464\n","recall class 0 = 0.9765223860740662\n","recall class 1 = 0.26157405972480774\n","AUC of ROC = 0.840028973397462\n","AUC of PRC = 0.4939994844265373\n","min(+P, Se) = 0.4853273137697517\n","f1_score = 0.3711001619375877\n","Epoch 49: Validation AUROC = 0.8400\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50 Batch 0: Train Loss = 0.2789\n","Epoch 50 Batch 50: Train Loss = 0.2849\n","Epoch 50: Train Loss = 0.2869\n","Epoch 50: Validation Loss = 0.2997\n","confusion matrix:\n","[[2668   58]\n"," [ 317  115]]\n","accuracy = 0.8812539577484131\n","precision class 0 = 0.8938023447990417\n","precision class 1 = 0.6647399067878723\n","recall class 0 = 0.978723406791687\n","recall class 1 = 0.26620370149612427\n","AUC of ROC = 0.8407252859976632\n","AUC of PRC = 0.5008059223502617\n","min(+P, Se) = 0.48036951501154734\n","f1_score = 0.3801652906673965\n","Epoch 50: Validation AUROC = 0.8407\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51 Batch 0: Train Loss = 0.3571\n","Epoch 51 Batch 50: Train Loss = 0.2872\n","Epoch 51: Train Loss = 0.2857\n","Epoch 51: Validation Loss = 0.2985\n","confusion matrix:\n","[[2676   50]\n"," [ 328  104]]\n","accuracy = 0.8803039789199829\n","precision class 0 = 0.8908122777938843\n","precision class 1 = 0.6753246784210205\n","recall class 0 = 0.9816581010818481\n","recall class 1 = 0.24074074625968933\n","AUC of ROC = 0.8418928833455612\n","AUC of PRC = 0.49862585325263703\n","min(+P, Se) = 0.48291571753986334\n","f1_score = 0.35494880033962145\n","Epoch 51: Validation AUROC = 0.8419\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52 Batch 0: Train Loss = 0.2322\n","Epoch 52 Batch 50: Train Loss = 0.2832\n","Epoch 52: Train Loss = 0.2840\n","Epoch 52: Validation Loss = 0.3018\n","confusion matrix:\n","[[2635   91]\n"," [ 308  124]]\n","accuracy = 0.8736541867256165\n","precision class 0 = 0.8953449130058289\n","precision class 1 = 0.5767441987991333\n","recall class 0 = 0.96661776304245\n","recall class 1 = 0.28703704476356506\n","AUC of ROC = 0.8367367734572431\n","AUC of PRC = 0.4918359815498862\n","min(+P, Se) = 0.48623853211009177\n","f1_score = 0.3833075963464011\n","Epoch 52: Validation AUROC = 0.8367\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53 Batch 0: Train Loss = 0.3150\n","Epoch 53 Batch 50: Train Loss = 0.2898\n","Epoch 53: Train Loss = 0.2890\n","Epoch 53: Validation Loss = 0.3016\n","confusion matrix:\n","[[2682   44]\n"," [ 340   92]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8874917030334473\n","precision class 1 = 0.6764705777168274\n","recall class 0 = 0.983859121799469\n","recall class 1 = 0.21296297013759613\n","AUC of ROC = 0.8386023817287573\n","AUC of PRC = 0.4891564057652554\n","min(+P, Se) = 0.4722222222222222\n","f1_score = 0.3239436636390109\n","Epoch 53: Validation AUROC = 0.8386\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54 Batch 0: Train Loss = 0.2675\n","Epoch 54 Batch 50: Train Loss = 0.2839\n","Epoch 54: Train Loss = 0.2846\n","Epoch 54: Validation Loss = 0.3022\n","confusion matrix:\n","[[2675   51]\n"," [ 338   94]]\n","accuracy = 0.8768207430839539\n","precision class 0 = 0.8878194689750671\n","precision class 1 = 0.6482758522033691\n","recall class 0 = 0.9812912940979004\n","recall class 1 = 0.21759259700775146\n","AUC of ROC = 0.8383289516589222\n","AUC of PRC = 0.48999210461502196\n","min(+P, Se) = 0.4863636363636364\n","f1_score = 0.32582322727398594\n","Epoch 54: Validation AUROC = 0.8383\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55 Batch 0: Train Loss = 0.3164\n","Epoch 55 Batch 50: Train Loss = 0.2835\n","Epoch 55: Train Loss = 0.2853\n","Epoch 55: Validation Loss = 0.3045\n","confusion matrix:\n","[[2695   31]\n"," [ 362   70]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.8815832734107971\n","precision class 1 = 0.6930692791938782\n","recall class 0 = 0.9886280298233032\n","recall class 1 = 0.16203702986240387\n","AUC of ROC = 0.8377625607999782\n","AUC of PRC = 0.4848516910249227\n","min(+P, Se) = 0.4861111111111111\n","f1_score = 0.2626641582621325\n","Epoch 55: Validation AUROC = 0.8378\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56 Batch 0: Train Loss = 0.2216\n","Epoch 56 Batch 50: Train Loss = 0.2845\n","Epoch 56: Train Loss = 0.2832\n","Epoch 56: Validation Loss = 0.3017\n","confusion matrix:\n","[[2673   53]\n"," [ 323  109]]\n","accuracy = 0.8809372782707214\n","precision class 0 = 0.8921895623207092\n","precision class 1 = 0.6728395223617554\n","recall class 0 = 0.9805576205253601\n","recall class 1 = 0.25231480598449707\n","AUC of ROC = 0.8372106056900627\n","AUC of PRC = 0.4872720308781166\n","min(+P, Se) = 0.4920273348519362\n","f1_score = 0.36700336007047263\n","Epoch 56: Validation AUROC = 0.8372\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57 Batch 0: Train Loss = 0.2999\n","Epoch 57 Batch 50: Train Loss = 0.2857\n","Epoch 57: Train Loss = 0.2863\n","Epoch 57: Validation Loss = 0.3018\n","confusion matrix:\n","[[2687   39]\n"," [ 343   89]]\n","accuracy = 0.8790373802185059\n","precision class 0 = 0.8867986798286438\n","precision class 1 = 0.6953125\n","recall class 0 = 0.9856933355331421\n","recall class 1 = 0.20601852238178253\n","AUC of ROC = 0.8377617116382706\n","AUC of PRC = 0.48970305482295867\n","min(+P, Se) = 0.48\n","f1_score = 0.3178571527101557\n","Epoch 57: Validation AUROC = 0.8378\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58 Batch 0: Train Loss = 0.3202\n","Epoch 58 Batch 50: Train Loss = 0.2824\n","Epoch 58: Train Loss = 0.2819\n","Epoch 58: Validation Loss = 0.3051\n","confusion matrix:\n","[[2666   60]\n"," [ 325  107]]\n","accuracy = 0.8780874013900757\n","precision class 0 = 0.8913406729698181\n","precision class 1 = 0.6407185792922974\n","recall class 0 = 0.9779897332191467\n","recall class 1 = 0.24768517911434174\n","AUC of ROC = 0.8344007295997391\n","AUC of PRC = 0.4898387051531161\n","min(+P, Se) = 0.48451327433628316\n","f1_score = 0.3572620937505103\n","Epoch 58: Validation AUROC = 0.8344\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59 Batch 0: Train Loss = 0.2192\n","Epoch 59 Batch 50: Train Loss = 0.2840\n","Epoch 59: Train Loss = 0.2852\n","Epoch 59: Validation Loss = 0.2994\n","confusion matrix:\n","[[2644   82]\n"," [ 304  128]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.896879255771637\n","precision class 1 = 0.6095238327980042\n","recall class 0 = 0.9699193239212036\n","recall class 1 = 0.29629629850387573\n","AUC of ROC = 0.840828034564278\n","AUC of PRC = 0.494340797844016\n","min(+P, Se) = 0.48423423423423423\n","f1_score = 0.39875390106064224\n","Epoch 59: Validation AUROC = 0.8408\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60 Batch 0: Train Loss = 0.2143\n","Epoch 60 Batch 50: Train Loss = 0.2814\n","Epoch 60: Train Loss = 0.2808\n","Epoch 60: Validation Loss = 0.3056\n","confusion matrix:\n","[[2653   73]\n"," [ 323  109]]\n","accuracy = 0.8746041655540466\n","precision class 0 = 0.8914650678634644\n","precision class 1 = 0.598901093006134\n","recall class 0 = 0.9732208251953125\n","recall class 1 = 0.25231480598449707\n","AUC of ROC = 0.8343650648080214\n","AUC of PRC = 0.4770209454993541\n","min(+P, Se) = 0.46543778801843316\n","f1_score = 0.35504885015642584\n","Epoch 60: Validation AUROC = 0.8344\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61 Batch 0: Train Loss = 0.3017\n","Epoch 61 Batch 50: Train Loss = 0.2796\n","Epoch 61: Train Loss = 0.2804\n","Epoch 61: Validation Loss = 0.3010\n","confusion matrix:\n","[[2657   69]\n"," [ 315  117]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8940107822418213\n","precision class 1 = 0.6290322542190552\n","recall class 0 = 0.9746881723403931\n","recall class 1 = 0.2708333432674408\n","AUC of ROC = 0.8400111410016033\n","AUC of PRC = 0.4936244066873079\n","min(+P, Se) = 0.48148148148148145\n","f1_score = 0.37864077317073086\n","Epoch 61: Validation AUROC = 0.8400\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62 Batch 0: Train Loss = 0.2369\n","Epoch 62 Batch 50: Train Loss = 0.2819\n","Epoch 62: Train Loss = 0.2792\n","Epoch 62: Validation Loss = 0.3045\n","confusion matrix:\n","[[2647   79]\n"," [ 305  127]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8966802358627319\n","precision class 1 = 0.6165048480033875\n","recall class 0 = 0.9710198044776917\n","recall class 1 = 0.29398149251937866\n","AUC of ROC = 0.8414445259639685\n","AUC of PRC = 0.49829905411791614\n","min(+P, Se) = 0.4837962962962963\n","f1_score = 0.39811913105122904\n","Epoch 62: Validation AUROC = 0.8414\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63 Batch 0: Train Loss = 0.2925\n","Epoch 63 Batch 50: Train Loss = 0.2827\n","Epoch 63: Train Loss = 0.2810\n","Epoch 63: Validation Loss = 0.3044\n","confusion matrix:\n","[[2677   49]\n"," [ 324  108]]\n","accuracy = 0.8818872570991516\n","precision class 0 = 0.892035961151123\n","precision class 1 = 0.6878980994224548\n","recall class 0 = 0.9820249676704407\n","recall class 1 = 0.25\n","AUC of ROC = 0.8347803048830194\n","AUC of PRC = 0.48260322681990336\n","min(+P, Se) = 0.4791666666666667\n","f1_score = 0.3667232612189178\n","Epoch 63: Validation AUROC = 0.8348\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64 Batch 0: Train Loss = 0.3023\n","Epoch 64 Batch 50: Train Loss = 0.2789\n","Epoch 64: Train Loss = 0.2800\n","Epoch 64: Validation Loss = 0.2991\n","confusion matrix:\n","[[2649   77]\n"," [ 305  127]]\n","accuracy = 0.8790373802185059\n","precision class 0 = 0.8967501521110535\n","precision class 1 = 0.6225489974021912\n","recall class 0 = 0.9717534780502319\n","recall class 1 = 0.29398149251937866\n","AUC of ROC = 0.8432116314774053\n","AUC of PRC = 0.49270052343514986\n","min(+P, Se) = 0.4837962962962963\n","f1_score = 0.3993710747983961\n","Epoch 64: Validation AUROC = 0.8432\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65 Batch 0: Train Loss = 0.2368\n","Epoch 65 Batch 50: Train Loss = 0.2771\n","Epoch 65: Train Loss = 0.2782\n","Epoch 65: Validation Loss = 0.2987\n","confusion matrix:\n","[[2665   61]\n"," [ 320  112]]\n","accuracy = 0.8793540000915527\n","precision class 0 = 0.8927972912788391\n","precision class 1 = 0.647398829460144\n","recall class 0 = 0.9776228666305542\n","recall class 1 = 0.25925925374031067\n","AUC of ROC = 0.8432150281242359\n","AUC of PRC = 0.5003093884996732\n","min(+P, Se) = 0.4976851851851852\n","f1_score = 0.3702479380602463\n","Epoch 65: Validation AUROC = 0.8432\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66 Batch 0: Train Loss = 0.3627\n","Epoch 66 Batch 50: Train Loss = 0.2777\n","Epoch 66: Train Loss = 0.2767\n","Epoch 66: Validation Loss = 0.3022\n","confusion matrix:\n","[[2657   69]\n"," [ 317  115]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.8934095501899719\n","precision class 1 = 0.625\n","recall class 0 = 0.9746881723403931\n","recall class 1 = 0.26620370149612427\n","AUC of ROC = 0.8401351186109073\n","AUC of PRC = 0.4880584155283624\n","min(+P, Se) = 0.4781609195402299\n","f1_score = 0.3733766212051605\n","Epoch 66: Validation AUROC = 0.8401\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67 Batch 0: Train Loss = 0.2246\n","Epoch 67 Batch 50: Train Loss = 0.2818\n","Epoch 67: Train Loss = 0.2822\n","Epoch 67: Validation Loss = 0.3048\n","confusion matrix:\n","[[2652   74]\n"," [ 310  122]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8953409790992737\n","precision class 1 = 0.6224489808082581\n","recall class 0 = 0.9728540182113647\n","recall class 1 = 0.28240740299224854\n","AUC of ROC = 0.8348091763810765\n","AUC of PRC = 0.48173505716217613\n","min(+P, Se) = 0.47465437788018433\n","f1_score = 0.3885350279055714\n","Epoch 67: Validation AUROC = 0.8348\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68 Batch 0: Train Loss = 0.3264\n","Epoch 68 Batch 50: Train Loss = 0.2796\n","Epoch 68: Train Loss = 0.2798\n","Epoch 68: Validation Loss = 0.3034\n","confusion matrix:\n","[[2635   91]\n"," [ 308  124]]\n","accuracy = 0.8736541867256165\n","precision class 0 = 0.8953449130058289\n","precision class 1 = 0.5767441987991333\n","recall class 0 = 0.96661776304245\n","recall class 1 = 0.28703704476356506\n","AUC of ROC = 0.8373362816227822\n","AUC of PRC = 0.48420868799169503\n","min(+P, Se) = 0.48036951501154734\n","f1_score = 0.3833075963464011\n","Epoch 68: Validation AUROC = 0.8373\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69 Batch 0: Train Loss = 0.2680\n","Epoch 69 Batch 50: Train Loss = 0.2774\n","Epoch 69: Train Loss = 0.2778\n","Epoch 69: Validation Loss = 0.3061\n","confusion matrix:\n","[[2614  112]\n"," [ 289  143]]\n","accuracy = 0.8730208873748779\n","precision class 0 = 0.9004477858543396\n","precision class 1 = 0.5607843399047852\n","recall class 0 = 0.9589141607284546\n","recall class 1 = 0.33101850748062134\n","AUC of ROC = 0.8350732656721286\n","AUC of PRC = 0.4866519393668778\n","min(+P, Se) = 0.48623853211009177\n","f1_score = 0.41630276413227135\n","Epoch 69: Validation AUROC = 0.8351\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70 Batch 0: Train Loss = 0.2878\n","Epoch 70 Batch 50: Train Loss = 0.2769\n","Epoch 70: Train Loss = 0.2759\n","Epoch 70: Validation Loss = 0.3057\n","confusion matrix:\n","[[2617  109]\n"," [ 302  130]]\n","accuracy = 0.8698543310165405\n","precision class 0 = 0.8965399265289307\n","precision class 1 = 0.5439330339431763\n","recall class 0 = 0.9600147008895874\n","recall class 1 = 0.30092594027519226\n","AUC of ROC = 0.8369634996331621\n","AUC of PRC = 0.4805902254400356\n","min(+P, Se) = 0.47608695652173916\n","f1_score = 0.38748136412612516\n","Epoch 70: Validation AUROC = 0.8370\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71 Batch 0: Train Loss = 0.2503\n","Epoch 71 Batch 50: Train Loss = 0.2749\n","Epoch 71: Train Loss = 0.2749\n","Epoch 71: Validation Loss = 0.3047\n","confusion matrix:\n","[[2670   56]\n"," [ 325  107]]\n","accuracy = 0.8793540000915527\n","precision class 0 = 0.8914858102798462\n","precision class 1 = 0.6564416885375977\n","recall class 0 = 0.9794570803642273\n","recall class 1 = 0.24768517911434174\n","AUC of ROC = 0.8360633882231461\n","AUC of PRC = 0.487151142937872\n","min(+P, Se) = 0.49074074074074076\n","f1_score = 0.35966384882711777\n","Epoch 71: Validation AUROC = 0.8361\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72 Batch 0: Train Loss = 0.2908\n","Epoch 72 Batch 50: Train Loss = 0.2807\n","Epoch 72: Train Loss = 0.2777\n","Epoch 72: Validation Loss = 0.3018\n","confusion matrix:\n","[[2660   66]\n"," [ 320  112]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.8926174640655518\n","precision class 1 = 0.6292135119438171\n","recall class 0 = 0.9757887125015259\n","recall class 1 = 0.25925925374031067\n","AUC of ROC = 0.8361262261895057\n","AUC of PRC = 0.48405340418580617\n","min(+P, Se) = 0.4769585253456221\n","f1_score = 0.36721310180478545\n","Epoch 72: Validation AUROC = 0.8361\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73 Batch 0: Train Loss = 0.2708\n","Epoch 73 Batch 50: Train Loss = 0.2744\n","Epoch 73: Train Loss = 0.2736\n","Epoch 73: Validation Loss = 0.3099\n","confusion matrix:\n","[[2608  118]\n"," [ 282  150]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.9024221301078796\n","precision class 1 = 0.5597015023231506\n","recall class 0 = 0.9567131400108337\n","recall class 1 = 0.3472222089767456\n","AUC of ROC = 0.831393847993261\n","AUC of PRC = 0.47196693873037654\n","min(+P, Se) = 0.4722222222222222\n","f1_score = 0.42857142135075127\n","Epoch 73: Validation AUROC = 0.8314\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74 Batch 0: Train Loss = 0.2658\n","Epoch 74 Batch 50: Train Loss = 0.2745\n","Epoch 74: Train Loss = 0.2770\n","Epoch 74: Validation Loss = 0.3064\n","confusion matrix:\n","[[2670   56]\n"," [ 334   98]]\n","accuracy = 0.876504123210907\n","precision class 0 = 0.8888149261474609\n","precision class 1 = 0.6363636255264282\n","recall class 0 = 0.9794570803642273\n","recall class 1 = 0.22685185074806213\n","AUC of ROC = 0.835675745903644\n","AUC of PRC = 0.4844211624287609\n","min(+P, Se) = 0.49191685912240185\n","f1_score = 0.3344709986119821\n","Epoch 74: Validation AUROC = 0.8357\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75 Batch 0: Train Loss = 0.2554\n","Epoch 75 Batch 50: Train Loss = 0.2760\n","Epoch 75: Train Loss = 0.2748\n","Epoch 75: Validation Loss = 0.3125\n","confusion matrix:\n","[[2665   61]\n"," [ 333   99]]\n","accuracy = 0.8752374649047852\n","precision class 0 = 0.8889259696006775\n","precision class 1 = 0.6187499761581421\n","recall class 0 = 0.9776228666305542\n","recall class 1 = 0.2291666716337204\n","AUC of ROC = 0.8350520366294394\n","AUC of PRC = 0.4766503041827412\n","min(+P, Se) = 0.48498845265588914\n","f1_score = 0.33445945538857946\n","Epoch 75: Validation AUROC = 0.8351\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76 Batch 0: Train Loss = 0.2384\n","Epoch 76 Batch 50: Train Loss = 0.2714\n","Epoch 76: Train Loss = 0.2747\n","Epoch 76: Validation Loss = 0.3060\n","confusion matrix:\n","[[2645   81]\n"," [ 308  124]]\n","accuracy = 0.8768207430839539\n","precision class 0 = 0.8956992626190186\n","precision class 1 = 0.6048780679702759\n","recall class 0 = 0.9702861309051514\n","recall class 1 = 0.28703704476356506\n","AUC of ROC = 0.8383824488464988\n","AUC of PRC = 0.4842071341343542\n","min(+P, Se) = 0.48853211009174313\n","f1_score = 0.3893249848445799\n","Epoch 76: Validation AUROC = 0.8384\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77 Batch 0: Train Loss = 0.2777\n","Epoch 77 Batch 50: Train Loss = 0.2727\n","Epoch 77: Train Loss = 0.2742\n","Epoch 77: Validation Loss = 0.3078\n","confusion matrix:\n","[[2682   44]\n"," [ 333   99]]\n","accuracy = 0.8806206583976746\n","precision class 0 = 0.8895522356033325\n","precision class 1 = 0.692307710647583\n","recall class 0 = 0.983859121799469\n","recall class 1 = 0.2291666716337204\n","AUC of ROC = 0.8392817110948071\n","AUC of PRC = 0.4922791392880486\n","min(+P, Se) = 0.48498845265588914\n","f1_score = 0.344347828394524\n","Epoch 77: Validation AUROC = 0.8393\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78 Batch 0: Train Loss = 0.2572\n","Epoch 78 Batch 50: Train Loss = 0.2700\n","Epoch 78: Train Loss = 0.2742\n","Epoch 78: Validation Loss = 0.3062\n","confusion matrix:\n","[[2604  122]\n"," [ 281  151]]\n","accuracy = 0.8723875880241394\n","precision class 0 = 0.9025996327400208\n","precision class 1 = 0.553113579750061\n","recall class 0 = 0.9552457928657532\n","recall class 1 = 0.34953704476356506\n","AUC of ROC = 0.837342225754735\n","AUC of PRC = 0.4899315020281288\n","min(+P, Se) = 0.49191685912240185\n","f1_score = 0.4283688222601062\n","Epoch 78: Validation AUROC = 0.8373\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79 Batch 0: Train Loss = 0.2424\n","Epoch 79 Batch 50: Train Loss = 0.2734\n","Epoch 79: Train Loss = 0.2740\n","Epoch 79: Validation Loss = 0.2995\n","confusion matrix:\n","[[2647   79]\n"," [ 301  131]]\n","accuracy = 0.8796706795692444\n","precision class 0 = 0.8978968858718872\n","precision class 1 = 0.6238095164299011\n","recall class 0 = 0.9710198044776917\n","recall class 1 = 0.30324074625968933\n","AUC of ROC = 0.8401291744789543\n","AUC of PRC = 0.49271220985388114\n","min(+P, Se) = 0.4930875576036866\n","f1_score = 0.40809970501156667\n","Epoch 79: Validation AUROC = 0.8401\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80 Batch 0: Train Loss = 0.2913\n","Epoch 80 Batch 50: Train Loss = 0.2737\n","Epoch 80: Train Loss = 0.2716\n","Epoch 80: Validation Loss = 0.3032\n","confusion matrix:\n","[[2687   39]\n"," [ 348   84]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.8853377103805542\n","precision class 1 = 0.6829268336296082\n","recall class 0 = 0.9856933355331421\n","recall class 1 = 0.1944444477558136\n","AUC of ROC = 0.8429246148202496\n","AUC of PRC = 0.493371922204551\n","min(+P, Se) = 0.4861111111111111\n","f1_score = 0.3027026968615349\n","Epoch 80: Validation AUROC = 0.8429\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81 Batch 0: Train Loss = 0.2099\n","Epoch 81 Batch 50: Train Loss = 0.2746\n","Epoch 81: Train Loss = 0.2732\n","Epoch 81: Validation Loss = 0.3015\n","confusion matrix:\n","[[2671   55]\n"," [ 333   99]]\n","accuracy = 0.8771374225616455\n","precision class 0 = 0.8891478180885315\n","precision class 1 = 0.6428571343421936\n","recall class 0 = 0.9798239469528198\n","recall class 1 = 0.2291666716337204\n","AUC of ROC = 0.841655118067444\n","AUC of PRC = 0.4876732862631038\n","min(+P, Se) = 0.4837962962962963\n","f1_score = 0.33788395749331057\n","Epoch 81: Validation AUROC = 0.8417\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82 Batch 0: Train Loss = 0.3129\n","Epoch 82 Batch 50: Train Loss = 0.2766\n","Epoch 82: Train Loss = 0.2757\n","Epoch 82: Validation Loss = 0.3025\n","confusion matrix:\n","[[2677   49]\n"," [ 335   97]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8887782096862793\n","precision class 1 = 0.664383590221405\n","recall class 0 = 0.9820249676704407\n","recall class 1 = 0.22453702986240387\n","AUC of ROC = 0.8405537553327356\n","AUC of PRC = 0.48176992070201463\n","min(+P, Se) = 0.4837962962962963\n","f1_score = 0.33564013966575285\n","Epoch 82: Validation AUROC = 0.8406\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83 Batch 0: Train Loss = 0.2699\n","Epoch 83 Batch 50: Train Loss = 0.2745\n","Epoch 83: Train Loss = 0.2738\n","Epoch 83: Validation Loss = 0.3044\n","confusion matrix:\n","[[2672   54]\n"," [ 328  104]]\n","accuracy = 0.8790373802185059\n","precision class 0 = 0.890666663646698\n","precision class 1 = 0.6582278609275818\n","recall class 0 = 0.9801907539367676\n","recall class 1 = 0.24074074625968933\n","AUC of ROC = 0.8354952990407869\n","AUC of PRC = 0.4769245780541533\n","min(+P, Se) = 0.49078341013824883\n","f1_score = 0.3525423923260661\n","Epoch 83: Validation AUROC = 0.8355\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84 Batch 0: Train Loss = 0.2265\n","Epoch 84 Batch 50: Train Loss = 0.2687\n","Epoch 84: Train Loss = 0.2705\n","Epoch 84: Validation Loss = 0.3021\n","confusion matrix:\n","[[2651   75]\n"," [ 318  114]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.8928932547569275\n","precision class 1 = 0.60317462682724\n","recall class 0 = 0.9724871516227722\n","recall class 1 = 0.2638888955116272\n","AUC of ROC = 0.8371014884106411\n","AUC of PRC = 0.48080069038920564\n","min(+P, Se) = 0.4897959183673469\n","f1_score = 0.36714976924578946\n","Epoch 84: Validation AUROC = 0.8371\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85 Batch 0: Train Loss = 0.2434\n","Epoch 85 Batch 50: Train Loss = 0.2710\n","Epoch 85: Train Loss = 0.2709\n","Epoch 85: Validation Loss = 0.3125\n","confusion matrix:\n","[[2670   56]\n"," [ 328  104]]\n","accuracy = 0.8784040808677673\n","precision class 0 = 0.8905937075614929\n","precision class 1 = 0.6499999761581421\n","recall class 0 = 0.9794570803642273\n","recall class 1 = 0.24074074625968933\n","AUC of ROC = 0.8347667182956986\n","AUC of PRC = 0.4836663621200445\n","min(+P, Se) = 0.49547511312217196\n","f1_score = 0.35135134199050483\n","Epoch 85: Validation AUROC = 0.8348\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86 Batch 0: Train Loss = 0.2404\n","Epoch 86 Batch 50: Train Loss = 0.2714\n","Epoch 86: Train Loss = 0.2717\n","Epoch 86: Validation Loss = 0.3105\n","confusion matrix:\n","[[2663   63]\n"," [ 323  109]]\n","accuracy = 0.877770721912384\n","precision class 0 = 0.8918285369873047\n","precision class 1 = 0.6337209343910217\n","recall class 0 = 0.9768891930580139\n","recall class 1 = 0.25231480598449707\n","AUC of ROC = 0.8353135784353686\n","AUC of PRC = 0.47876163129835914\n","min(+P, Se) = 0.48036951501154734\n","f1_score = 0.36092714395791164\n","Epoch 86: Validation AUROC = 0.8353\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87 Batch 0: Train Loss = 0.2316\n","Epoch 87 Batch 50: Train Loss = 0.2713\n","Epoch 87: Train Loss = 0.2703\n","Epoch 87: Validation Loss = 0.3099\n","confusion matrix:\n","[[2610  116]\n"," [ 284  148]]\n","accuracy = 0.8733375668525696\n","precision class 0 = 0.9018659591674805\n","precision class 1 = 0.560606062412262\n","recall class 0 = 0.957446813583374\n","recall class 1 = 0.34259259700775146\n","AUC of ROC = 0.8319483505882993\n","AUC of PRC = 0.47700772784422985\n","min(+P, Se) = 0.4768211920529801\n","f1_score = 0.4252873602435081\n","Epoch 87: Validation AUROC = 0.8319\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88 Batch 0: Train Loss = 0.2118\n","Epoch 88 Batch 50: Train Loss = 0.2666\n","Epoch 88: Train Loss = 0.2685\n","Epoch 88: Validation Loss = 0.3076\n","confusion matrix:\n","[[2663   63]\n"," [ 326  106]]\n","accuracy = 0.8768207430839539\n","precision class 0 = 0.8909333944320679\n","precision class 1 = 0.6272189617156982\n","recall class 0 = 0.9768891930580139\n","recall class 1 = 0.24537037312984467\n","AUC of ROC = 0.8397733757234859\n","AUC of PRC = 0.4859603080474595\n","min(+P, Se) = 0.4942528735632184\n","f1_score = 0.35274542535952136\n","Epoch 88: Validation AUROC = 0.8398\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89 Batch 0: Train Loss = 0.2244\n","Epoch 89 Batch 50: Train Loss = 0.2588\n","Epoch 89: Train Loss = 0.2639\n","Epoch 89: Validation Loss = 0.3068\n","confusion matrix:\n","[[2613  113]\n"," [ 286  146]]\n","accuracy = 0.8736541867256165\n","precision class 0 = 0.9013453125953674\n","precision class 1 = 0.5637065768241882\n","recall class 0 = 0.9585472941398621\n","recall class 1 = 0.33796295523643494\n","AUC of ROC = 0.8356337123991197\n","AUC of PRC = 0.47433723012161805\n","min(+P, Se) = 0.49078341013824883\n","f1_score = 0.4225759884582217\n","Epoch 89: Validation AUROC = 0.8356\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90 Batch 0: Train Loss = 0.2929\n","Epoch 90 Batch 50: Train Loss = 0.2686\n","Epoch 90: Train Loss = 0.2674\n","Epoch 90: Validation Loss = 0.3058\n","confusion matrix:\n","[[2654   72]\n"," [ 326  106]]\n","accuracy = 0.8739708662033081\n","precision class 0 = 0.8906040191650391\n","precision class 1 = 0.5955055952072144\n","recall class 0 = 0.973587691783905\n","recall class 1 = 0.24537037312984467\n","AUC of ROC = 0.836758002499932\n","AUC of PRC = 0.4732635617986698\n","min(+P, Se) = 0.4864864864864865\n","f1_score = 0.3475409763380262\n","Epoch 90: Validation AUROC = 0.8368\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91 Batch 0: Train Loss = 0.2479\n","Epoch 91 Batch 50: Train Loss = 0.2706\n","Epoch 91: Train Loss = 0.2673\n","Epoch 91: Validation Loss = 0.3102\n","confusion matrix:\n","[[2653   73]\n"," [ 314  118]]\n","accuracy = 0.8774541020393372\n","precision class 0 = 0.8941692113876343\n","precision class 1 = 0.6178010702133179\n","recall class 0 = 0.9732208251953125\n","recall class 1 = 0.27314814925193787\n","AUC of ROC = 0.8302389880709763\n","AUC of PRC = 0.469323785634118\n","min(+P, Se) = 0.48623853211009177\n","f1_score = 0.37881219176818315\n","Epoch 91: Validation AUROC = 0.8302\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92 Batch 0: Train Loss = 0.2362\n","Epoch 92 Batch 50: Train Loss = 0.2635\n","Epoch 92: Train Loss = 0.2632\n","Epoch 92: Validation Loss = 0.3057\n","confusion matrix:\n","[[2631   95]\n"," [ 297  135]]\n","accuracy = 0.8758708238601685\n","precision class 0 = 0.8985655903816223\n","precision class 1 = 0.5869565010070801\n","recall class 0 = 0.9651504158973694\n","recall class 1 = 0.3125\n","AUC of ROC = 0.8365338238091357\n","AUC of PRC = 0.4801386673592648\n","min(+P, Se) = 0.4792626728110599\n","f1_score = 0.4078549798891691\n","Epoch 92: Validation AUROC = 0.8365\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93 Batch 0: Train Loss = 0.3162\n","Epoch 93 Batch 50: Train Loss = 0.2656\n","Epoch 93: Train Loss = 0.2654\n","Epoch 93: Validation Loss = 0.3150\n","confusion matrix:\n","[[2645   81]\n"," [ 315  117]]\n","accuracy = 0.8746041655540466\n","precision class 0 = 0.8935810923576355\n","precision class 1 = 0.5909090638160706\n","recall class 0 = 0.9702861309051514\n","recall class 1 = 0.2708333432674408\n","AUC of ROC = 0.8345799027200347\n","AUC of PRC = 0.4741793436215045\n","min(+P, Se) = 0.5011547344110855\n","f1_score = 0.37142858826384284\n","Epoch 93: Validation AUROC = 0.8346\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94 Batch 0: Train Loss = 0.3005\n","Epoch 94 Batch 50: Train Loss = 0.2601\n","Epoch 94: Train Loss = 0.2623\n","Epoch 94: Validation Loss = 0.3030\n","confusion matrix:\n","[[2643   83]\n"," [ 306  126]]\n","accuracy = 0.8768207430839539\n","precision class 0 = 0.896236002445221\n","precision class 1 = 0.6028708219528198\n","recall class 0 = 0.9695524573326111\n","recall class 1 = 0.2916666567325592\n","AUC of ROC = 0.8389233648542159\n","AUC of PRC = 0.4878182492500776\n","min(+P, Se) = 0.496551724137931\n","f1_score = 0.39313573132157653\n","Epoch 94: Validation AUROC = 0.8389\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95 Batch 0: Train Loss = 0.2672\n","Epoch 95 Batch 50: Train Loss = 0.2699\n","Epoch 95: Train Loss = 0.2713\n","Epoch 95: Validation Loss = 0.3072\n","confusion matrix:\n","[[2664   62]\n"," [ 347   85]]\n","accuracy = 0.870487630367279\n","precision class 0 = 0.8847559094429016\n","precision class 1 = 0.5782312750816345\n","recall class 0 = 0.9772560596466064\n","recall class 1 = 0.19675925374031067\n","AUC of ROC = 0.8353178242439063\n","AUC of PRC = 0.46875350649237385\n","min(+P, Se) = 0.4793577981651376\n","f1_score = 0.2936096521648854\n","Epoch 95: Validation AUROC = 0.8353\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96 Batch 0: Train Loss = 0.2683\n","Epoch 96 Batch 50: Train Loss = 0.2704\n","Epoch 96: Train Loss = 0.2686\n","Epoch 96: Validation Loss = 0.3070\n","confusion matrix:\n","[[2658   68]\n"," [ 328  104]]\n","accuracy = 0.8746041655540466\n","precision class 0 = 0.8901540637016296\n","precision class 1 = 0.604651153087616\n","recall class 0 = 0.9750550389289856\n","recall class 1 = 0.24074074625968933\n","AUC of ROC = 0.838628281160838\n","AUC of PRC = 0.47682981190140156\n","min(+P, Se) = 0.49537037037037035\n","f1_score = 0.34437087713995085\n","Epoch 96: Validation AUROC = 0.8386\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97 Batch 0: Train Loss = 0.3133\n","Epoch 97 Batch 50: Train Loss = 0.2677\n","Epoch 97: Train Loss = 0.2627\n","Epoch 97: Validation Loss = 0.3142\n","confusion matrix:\n","[[2667   59]\n"," [ 334   98]]\n","accuracy = 0.8755541443824768\n","precision class 0 = 0.8887037634849548\n","precision class 1 = 0.6242038011550903\n","recall class 0 = 0.9783565402030945\n","recall class 1 = 0.22685185074806213\n","AUC of ROC = 0.8329104508029674\n","AUC of PRC = 0.4654725271311766\n","min(+P, Se) = 0.47453703703703703\n","f1_score = 0.3327674099290096\n","Epoch 97: Validation AUROC = 0.8329\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98 Batch 0: Train Loss = 0.2419\n","Epoch 98 Batch 50: Train Loss = 0.2676\n","Epoch 98: Train Loss = 0.2660\n","Epoch 98: Validation Loss = 0.3147\n","confusion matrix:\n","[[2663   63]\n"," [ 329  103]]\n","accuracy = 0.8758708238601685\n","precision class 0 = 0.8900400996208191\n","precision class 1 = 0.6204819083213806\n","recall class 0 = 0.9768891930580139\n","recall class 1 = 0.23842592537403107\n","AUC of ROC = 0.8330616015869136\n","AUC of PRC = 0.4701161645144195\n","min(+P, Se) = 0.47235023041474655\n","f1_score = 0.3444816077633317\n","Epoch 98: Validation AUROC = 0.8331\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99 Batch 0: Train Loss = 0.2634\n","Epoch 99 Batch 50: Train Loss = 0.2592\n","Epoch 99: Train Loss = 0.2598\n","Epoch 99: Validation Loss = 0.3128\n","confusion matrix:\n","[[2615  111]\n"," [ 284  148]]\n","accuracy = 0.8749208450317383\n","precision class 0 = 0.9020351767539978\n","precision class 1 = 0.5714285969734192\n","recall class 0 = 0.9592810273170471\n","recall class 1 = 0.34259259700775146\n","AUC of ROC = 0.8323041493437678\n","AUC of PRC = 0.46908943636424966\n","min(+P, Se) = 0.4793577981651376\n","f1_score = 0.4283646994856278\n","Epoch 99: Validation AUROC = 0.8323\n"]}]},{"cell_type":"markdown","source":["### Test"],"metadata":{"id":"VhfSLc_NKuvb"}},{"cell_type":"code","source":["file_name = 'model/concare_fd'\n","BATCH_SIZE = 256\n","\n","checkpoint = torch.load(file_name)\n","save_epoch = checkpoint['epoch']\n","model.load_state_dict(checkpoint['net'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zoXoRRJ-KuDB","executionInfo":{"status":"ok","timestamp":1682896523824,"user_tz":300,"elapsed":24,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"064037b9-d626-47c5-bd6b-b6b19f33f089"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ConCare_FD(\n","  (demo_embed): DemographicEmbed(\n","    (fc): Linear(in_features=12, out_features=64, bias=True)\n","  )\n","  (grus): ModuleList(\n","    (0-75): 76 x GRU(1, 64, batch_first=True)\n","  )\n","  (time_attns): ModuleList(\n","    (0-75): 76 x FixedDecaySelfAttention()\n","  )\n","  (multi_attn): MultiHeadAttention(\n","    (w_qs): Linear(in_features=64, out_features=64, bias=False)\n","    (w_ks): Linear(in_features=64, out_features=64, bias=False)\n","    (w_vs): Linear(in_features=64, out_features=64, bias=False)\n","    (fc): Linear(in_features=64, out_features=64, bias=False)\n","    (attn): ScaledDotProductAttention(\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","  )\n","  (final_attn): FinalAttention(\n","    (w_qs): Linear(in_features=64, out_features=64, bias=True)\n","    (w_ks): Linear(in_features=64, out_features=64, bias=True)\n","    (w_vs): Linear(in_features=64, out_features=64, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (res): ResConnect(\n","    (lnorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (pos_ff): PositionwiseFeedForward(\n","    (fc1): Linear(in_features=64, out_features=256, bias=True)\n","    (fc2): Linear(in_features=256, out_features=64, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (output_fc1): Linear(in_features=64, out_features=64, bias=True)\n","  (output_fc2): Linear(in_features=64, out_features=1, bias=True)\n","  (dp): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["batch_loss = []\n","y_true = []\n","y_pred = []\n","with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(test_loader):\n","        batch_x = batch_x.float().to(device)\n","        batch_y = batch_y.float().to(device)\n","        batch_demo = []\n","        for i in range(len(batch_name)):\n","            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","            cur_idx = cur_id + '_' + cur_ep\n","            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","            batch_demo.append(cur_demo)\n","\n","        batch_demo = torch.stack(batch_demo).to(device)\n","        output = model(batch_x, batch_demo)[0]\n","\n","        loss = loss_func(output, batch_y.unsqueeze(-1))\n","        batch_loss.append(loss.cpu().detach().numpy())\n","        y_pred += list(output.cpu().detach().numpy().flatten())\n","        y_true += list(batch_y.cpu().numpy().flatten())\n","\n","print(\"\\nTest Prediction Result\")\n","y_pred = np.array(y_pred)\n","y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","test_res = metrics.print_metrics_binary(y_true, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qGKWXO4DK2GJ","executionInfo":{"status":"ok","timestamp":1682896527871,"user_tz":300,"elapsed":4063,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"bdfb3462-d7c4-401c-b727-0ad8d443a517"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-40-b992205c8f48>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-20-515625ac3faf>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Prediction Result\n","confusion matrix:\n","[[2812   50]\n"," [ 293   81]]\n","accuracy = 0.8940049409866333\n","precision class 0 = 0.9056360721588135\n","precision class 1 = 0.6183205842971802\n","recall class 0 = 0.9825296998023987\n","recall class 1 = 0.21657754480838776\n","AUC of ROC = 0.8509858107527365\n","AUC of PRC = 0.44539100869934967\n","min(+P, Se) = 0.45910290237467016\n","f1_score = 0.3207920865390409\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PIIvAO5xK7_M"},"execution_count":null,"outputs":[]}]}