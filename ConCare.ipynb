{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyMjKt0+dLAfiCWhw9l6gKnt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Preparation"],"metadata":{"id":"bNXOeEc_OGqg"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"AP1-sbhoIHb3","executionInfo":{"status":"ok","timestamp":1681415755432,"user_tz":300,"elapsed":3,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ICirv2eqN8ua","executionInfo":{"status":"ok","timestamp":1681415785842,"user_tz":300,"elapsed":18032,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"8fc32448-a6f9-4ca0-8570-9a173a2d4764"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'CS598_DL4H'\n","GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","print(os.listdir(GOOGLE_DRIVE_PATH))\n","os.chdir(GOOGLE_DRIVE_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ki7zFjNON_2c","executionInfo":{"status":"ok","timestamp":1681415786068,"user_tz":300,"elapsed":228,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"ee8c9bed-f0ad-47d0-d6ed-4f929c264c4b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["['mimic3-benchmarks-master', 'prepare_dataset.ipynb']\n"]}]},{"cell_type":"code","source":["%cd mimic3-benchmarks-master"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VeIQbaG-OB1O","executionInfo":{"status":"ok","timestamp":1681415786068,"user_tz":300,"elapsed":6,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"8d160f68-1b22-4973-c458-8bb7cd8a1c23"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import argparse\n","import os\n","import imp\n","import re\n","import pickle\n","import datetime\n","import random\n","import math\n","import copy\n","\n","\n","import torch\n","from torch import nn\n","import torch.nn.utils.rnn as rnn_utils\n","from torch.utils.data import DataLoader, Dataset\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","\n","from utils import utils\n","from utils.readers import InHospitalMortalityReader\n","from utils.preprocessing import Discretizer, Normalizer\n","from utils import metrics\n","from utils import common_utils\n"],"metadata":{"id":"MXyamQovODig","executionInfo":{"status":"ok","timestamp":1681415794917,"user_tz":300,"elapsed":8852,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Data Preprocessing"],"metadata":{"id":"6hvVGcvwVDwY"}},{"cell_type":"code","source":["TIMESTEP = 1.0\n","data_path = 'data/hospital-mortality/'\n","# Build readers, discretizers, normalizers\n","train_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'train'),\n","                                         listfile=os.path.join(data_path, 'train_listfile.csv'),\n","                                         period_length=48.0)\n","\n","val_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'train'),\n","                                       listfile=os.path.join(data_path, 'val_listfile.csv'),\n","                                       period_length=48.0)\n","\n","discretizer = Discretizer(timestep=TIMESTEP,\n","                          store_masks=True,\n","                          impute_strategy='previous',\n","                          start_time='zero')"],"metadata":{"id":"USEPOzQUVGej","executionInfo":{"status":"ok","timestamp":1681415797601,"user_tz":300,"elapsed":2687,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["discretizer_header = discretizer.transform(train_reader.read_example(0)[\"X\"])[1].split(',')\n","cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n","\n","normalizer = Normalizer(fields=cont_channels)  # choose here which columns to standardize\n","normalizer_state = 'ihm_normalizer'\n","normalizer_state = os.path.join(os.path.dirname(data_path), normalizer_state)\n","normalizer.load_params(normalizer_state)"],"metadata":{"id":"n-Eqe4l2Vtn7","executionInfo":{"status":"ok","timestamp":1681415937761,"user_tz":300,"elapsed":112552,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["train_raw = utils.load_data(train_reader, discretizer, normalizer, return_names=True)\n","val_raw = utils.load_data(val_reader, discretizer, normalizer, return_names=True)"],"metadata":{"id":"2nuWQUPUZDNW","executionInfo":{"status":"ok","timestamp":1681264267977,"user_tz":300,"elapsed":4080195,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["demographic_data = []\n","with open('demographic_data.txt', 'r') as f:\n","  for line in f:\n","    demographic_data.append(np.fromstring(line, dtype=float, sep=' '))\n","\n","diagnosis_data = []\n","with open('diagnosis_data.txt', 'r') as f:\n","  for line in f:\n","    diagnosis_data.append(np.fromstring(line, dtype=int, sep=' '))\n","\n","idx_list = []\n","with open('idx_list.txt', 'r') as f:\n","  for line in f:\n","    idx_list.append(line.strip())\n","\n","len(demographic_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjR4Ah1rZDIn","executionInfo":{"status":"ok","timestamp":1681415979698,"user_tz":300,"elapsed":3582,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"38501532-0321-48dd-98f2-b3937208bb32"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-761523da05f3>:9: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n","  diagnosis_data.append(np.fromstring(line, dtype=int, sep=' '))\n"]},{"output_type":"execute_result","data":{"text/plain":["42125"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["class Dataset(Dataset):\n","  def __init__(self, x, y, name):\n","    self.x = x\n","    self.y = y\n","    self.name = name\n","  \n","  def __getitem__(self, index):\n","    return self.x[index], self.y[index], self.name[index]\n","  \n","  def __len__(self):\n","    return len(self.x)"],"metadata":{"id":"3EQDS3mjbi05","executionInfo":{"status":"ok","timestamp":1681415979698,"user_tz":300,"elapsed":10,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 256\n","train_dataset = Dataset(train_raw['data'][0], train_raw['data'][1], train_raw['names'])\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","val_dataset = Dataset(val_raw['data'][0], val_raw['data'][1], val_raw['names'])\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"id":"GOrTvUANeiwI","executionInfo":{"status":"ok","timestamp":1681266589288,"user_tz":300,"elapsed":249,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":185,"outputs":[]},{"cell_type":"markdown","source":["# ConCare Model"],"metadata":{"id":"W8Imh5JuZUb8"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n","print(\"available device: {}\".format(device))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTRqdZw_ZV3x","executionInfo":{"status":"ok","timestamp":1681415982973,"user_tz":300,"elapsed":209,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"a69438f9-1828-40fe-ac5e-8bdc7317a797"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["available device: cuda:0\n"]}]},{"cell_type":"code","source":["class DemographicEmbed(nn.Module):\n","  def __init__(self, demo_input_dim, hidden_dim, dropout=0.5):\n","    super().__init__()\n","    self.demo_input_dim = demo_input_dim\n","    self.hidden_dim = hidden_dim\n","\n","    self.fc = nn.Linear(self.demo_input_dim, self.hidden_dim)\n","    self.dropout = nn.Dropout(dropout)\n","  \n","  def forward(self, x):\n","    return self.dropout(F.sigmoid(self.fc(x)))"],"metadata":{"id":"osxsnJwZymGQ","executionInfo":{"status":"ok","timestamp":1681415984055,"user_tz":300,"elapsed":0,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class TimeAwareSelfAttention(nn.Module):\n","  def __init__(self, input_dim, hidden_dim):\n","    super().__init__()\n","    self.input_dim = input_dim\n","    self.hidden_dim = hidden_dim\n","\n","    self.w_qs = nn.Parameter(torch.randn(input_dim, hidden_dim))\n","    self.w_ks = nn.Parameter(torch.randn(input_dim, hidden_dim))\n","    self.beta = nn.Parameter(torch.zeros(1)+0.8)\n","\n","    nn.init.kaiming_uniform_(self.w_qs, a=math.sqrt(5))\n","    nn.init.kaiming_uniform_(self.w_ks, a=math.sqrt(5))\n","  \n","  def forward(self, input):\n","    b, time_step, input_dim = input.size()\n","    time_decays = torch.tensor(range(47, -1, -1), dtype=torch.float32).unsqueeze(-1).unsqueeze(0).to(device)\n","    b_time_decays = time_decays.repeat(b, 1, 1)\n","\n","    q = torch.matmul(input[:, -1, :], self.w_qs).reshape(b, 1, self.hidden_dim) # B*1*H\n","    k = torch.matmul(input, self.w_ks) # B*T*H\n","    v = input # B*T*H\n","    product = torch.matmul(q, k.transpose(1, 2)).squeeze() # B*T\n","    denominator = self.beta * torch.log(math.e + (1 - F.sigmoid(product)) * (b_time_decays.squeeze()))\n","    weights = F.softmax(F.tanh(product / denominator)) # B*T\n","    output = torch.matmul(weights.unsqueeze(1), v).squeeze() # B*H\n","\n","    return output, weights"],"metadata":{"id":"Lnphzxbfvh0P","executionInfo":{"status":"ok","timestamp":1681415984477,"user_tz":300,"elapsed":1,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class ScaledDotProductAttention(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    \n","  def forward(self, q, k, v):\n","    d_k = q.size(-1)\n","    attn = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n","    attn = F.softmax(attn, dim=-1)\n","    output = torch.matmul(attn, v)\n","\n","    return output, attn"],"metadata":{"id":"Wt3T3gbXzh_0","executionInfo":{"status":"ok","timestamp":1681415984477,"user_tz":300,"elapsed":1,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def cov(u):\n","  miu = torch.mean(u, dim=1).unsqueeze(1)\n","  diff = u - miu\n","  cov = torch.mm(diff, diff.T) / u.size(1)\n","  return cov\n","\n","def cross_head_decorr(u):\n","  covs = cov(u[0, :, :])\n","  loss = 0.5 * (torch.norm(covs, p='fro') ** 2 - torch.norm(torch.diag(covs)) ** 2)\n","  for i in range(u.size(0)-1):\n","    covs = cov(u[i+1, :, :])\n","    loss += 0.5 * (torch.norm(covs, p='fro') ** 2 - torch.norm(torch.diag(covs)) ** 2)\n","  return loss"],"metadata":{"id":"AjrKSZfusZFU","executionInfo":{"status":"ok","timestamp":1681415985743,"user_tz":300,"elapsed":1,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, n_head, d_model, dropout=0.5):\n","    super().__init__()\n","    self.n_head = n_head\n","    self.d_model = d_model\n","\n","    self.w_qs = nn.Linear(d_model, d_model, bias=False)\n","    self.w_ks = nn.Linear(d_model, d_model, bias=False)\n","    self.w_vs = nn.Linear(d_model, d_model, bias=False)\n","    self.fc = nn.Linear(d_model, d_model, bias=False)\n","\n","    self.attn = ScaledDotProductAttention()\n","\n","    self.dropout = nn.Dropout(dropout)\n","    self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n","\n","  def forward(self, q, k, v):\n","    b, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1)\n","    q = self.w_qs(q).view(b, len_q, self.n_head, self.d_model // self.n_head)\n","    k = self.w_ks(k).view(b, len_k, self.n_head, self.d_model // self.n_head)\n","    v = self.w_vs(v).view(b, len_v, self.n_head, self.d_model // self.n_head)\n","    q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n","\n","    q, attn = self.attn(q, k, v)\n","\n","    q = q.transpose(1, 2).contiguous().view(b, len_q, -1)\n","    output_q = self.dropout(self.fc(q))\n","\n","    # DeCov\n","    u = q.transpose(0, 1).transpose(1, 2)\n","    decov_loss = cross_head_decorr(u)\n","\n","    return output_q, decov_loss\n"],"metadata":{"id":"-Zdx7jxAx8ST","executionInfo":{"status":"ok","timestamp":1681415985936,"user_tz":300,"elapsed":2,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class PositionwiseFeedForward(nn.Module):\n","  def __init__(self, d_model, ff_hidden, dropout=0.5):\n","    super().__init__()\n","    self.fc1 = nn.Linear(d_model, ff_hidden)\n","    self.fc2 = nn.Linear(ff_hidden, d_model)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x):\n","    output = self.fc2(self.dropout(F.relu(self.fc1(x))))\n","    return output"],"metadata":{"id":"hSJCXZntwUC8","executionInfo":{"status":"ok","timestamp":1681415986513,"user_tz":300,"elapsed":578,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class ResConnect(nn.Module):\n","  def __init__(self, norm_shape, dropout=0.5):\n","    super().__init__()\n","    self.lnorm = nn.LayerNorm(norm_shape)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x, layer):\n","    res = layer(self.lnorm(x))\n","    output = x + self.dropout(res[0])\n","    return output, res[1]"],"metadata":{"id":"KlfNS6Xpt6WS","executionInfo":{"status":"ok","timestamp":1681415986513,"user_tz":300,"elapsed":4,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["class FinalAttention(nn.Module):\n","  def __init__(self, input_dim, hidden_dim, dropout=0.5):\n","    super().__init__()\n","\n","    self.input_dim = input_dim\n","    self.hidden_dim = hidden_dim\n","\n","    self.w_qs = nn.Linear(input_dim, hidden_dim)\n","    self.w_ks = nn.Linear(input_dim, hidden_dim)\n","    self.w_vs = nn.Linear(input_dim, hidden_dim)\n","\n","    # Parameter Initialization\n","    nn.init.kaiming_uniform_(self.w_qs.weight, a=math.sqrt(5))\n","    nn.init.kaiming_uniform_(self.w_ks.weight, a=math.sqrt(5))\n","    nn.init.kaiming_uniform_(self.w_vs.weight, a=math.sqrt(5))\n","    \n","    self.dropout = nn.Dropout(dropout)\n","  \n","  def forward(self, input):\n","    batch_size, time_step, input_dim = input.size()\n","    q = self.w_qs(input[:, -1, :]).reshape(batch_size, self.hidden_dim, 1)\n","    k = self.w_ks(input)\n","    v = self.w_vs(input)\n","\n","    attention = F.tanh(torch.matmul(k, q).squeeze())\n","    score = F.softmax(attention)\n","\n","    if self.dropout is not None:\n","      score = self.dropout(score)\n","\n","    v = torch.matmul(score.unsqueeze(1), v).squeeze()\n","\n","    return v, score"],"metadata":{"id":"o2xtgG7LZZE8","executionInfo":{"status":"ok","timestamp":1681415986513,"user_tz":300,"elapsed":3,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class ConCare(nn.Module):\n","  def __init__(self, demo_input_dim, input_dim, hidden_dim1, hidden_dim2, d_model, n_head, ff_hidden, output_dim, dropout=0.5):\n","    super().__init__()\n","    self.demo_input_dim = demo_input_dim\n","    self.input_dim = input_dim\n","    self.hidden_dim1 = hidden_dim1\n","    self.hidden_dim2 = hidden_dim2\n","    self.d_model = d_model\n","    self.n_head = n_head\n","    self.ff_hidden = ff_hidden\n","    self.output_dim = output_dim\n","    self.dropout = dropout\n","\n","    self.demo_embed = DemographicEmbed(self.demo_input_dim, self.hidden_dim1)\n","    self.gru = nn.GRU(1, self.hidden_dim1, batch_first=True)\n","    self.time_attn = TimeAwareSelfAttention(self.hidden_dim1, self.hidden_dim2)\n","    self.multi_attn = MultiHeadAttention(self.n_head, self.d_model)\n","    self.final_attn = FinalAttention(self.hidden_dim1, self.hidden_dim1, dropout=dropout)\n","    self.res = ResConnect(self.d_model, dropout=self.dropout)\n","    self.pos_ff = PositionwiseFeedForward(self.d_model, self.ff_hidden, dropout=self.dropout)\n","    self.output_fc = nn.Linear(self.hidden_dim1, self.output_dim)\n","  \n","  def forward(self, input, demo):\n","    # Demographic embedding\n","    demo_embedding = self.demo_embed(demo)\n","\n","    # First record embedding\n","    batch_size = input.size(0)\n","    feat_dim = input.size(2)\n","    record_embedding1 = self.gru(input[:, :, 0].unsqueeze(-1), torch.zeros(batch_size, self.hidden_dim1).unsqueeze(0).to(device))[0]\n","    time_attn_output = self.time_attn(record_embedding1)[0].unsqueeze(1)\n","\n","    # All other records embeddings\n","    for i in range(1, feat_dim):\n","      embedding = self.gru(input[:, :, i].unsqueeze(-1), torch.zeros(batch_size, self.hidden_dim1).unsqueeze(0).to(device))[0]\n","      attn = self.time_attn(embedding)[0].unsqueeze(1)\n","      time_attn_output = torch.cat((time_attn_output, attn), 1)\n","    \n","    # Combine with demographic embedding\n","    demo_embedding = demo_embedding.unsqueeze(1)\n","    time_attn_output = torch.cat((time_attn_output, demo_embedding), 1)\n","\n","    # Get multi-head attention\n","    multi_attn_output, dev_loss = self.res(time_attn_output, lambda x: self.multi_attn(time_attn_output, time_attn_output, time_attn_output))\n","    final_input = self.res(multi_attn_output, lambda x: self.pos_ff(multi_attn_output))[0]\n","\n","    # Get final output\n","    value, score = self.final_attn(final_input)\n","    output = F.sigmoid(self.output_fc(value))\n","\n","    return output, dev_loss"],"metadata":{"id":"row6kSkZsN3A","executionInfo":{"status":"ok","timestamp":1681415986926,"user_tz":300,"elapsed":1,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"ycMI90-I-THV"}},{"cell_type":"code","source":["RANDOM_SEED = 42\n","np.random.seed(RANDOM_SEED)\n","random.seed(RANDOM_SEED)\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed(RANDOM_SEED)"],"metadata":{"id":"iGTYs-lr-Uly","executionInfo":{"status":"ok","timestamp":1681415990767,"user_tz":300,"elapsed":1,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["model = ConCare(demo_input_dim=12, input_dim=76, hidden_dim1=64, hidden_dim2=8, d_model=64, n_head=4, ff_hidden=256, output_dim=1).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_func = nn.BCELoss()"],"metadata":{"id":"1DkBKR7z_CC3","executionInfo":{"status":"ok","timestamp":1681415996663,"user_tz":300,"elapsed":3739,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["max_roc = 0\n","max_prc = 0\n","train_total_loss = []\n","val_total_loss = []\n","result_history = []\n","file_name = 'model/concare0'\n","\n","\n","for epoch in range(100):\n","  \n","  # Start training\n","  train_batch_total_loss = []\n","  model.train()\n","\n","  for step, (batch_x, batch_y, batch_name) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","    batch_x = batch_x.float().to(device)\n","    batch_y = batch_y.float().to(device)\n","\n","    # Get batch demographic data\n","    batch_demo = []\n","    for i in range(len(batch_name)):\n","      cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","      cur_idx = cur_id + '_' + cur_ep\n","      cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","      batch_demo.append(cur_demo)\n","    batch_demo = torch.stack(batch_demo).to(device)\n","\n","    # Get model outputs\n","    output, decov_loss = model(batch_x, batch_demo)\n","\n","    # Get loss\n","    loss = loss_func(output, batch_y.unsqueeze(-1))\n","    loss += decov_loss\n","    train_batch_total_loss.append(loss.cpu().detach().numpy())\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    if step % 50 == 0:\n","      print('Epoch %d Batch %d: Train Loss = %.4f'%(epoch, step, np.mean(np.array(train_batch_total_loss))))\n","    \n","  train_total_loss.append(np.mean(np.array(train_batch_total_loss)))\n","  print('Epoch %d: Train Loss = %.4f'%(epoch, np.mean(np.array(train_batch_total_loss))))\n","\n","  # Start Validating\n","  val_batch_total_loss = []\n","  y_true = []\n","  y_pred = []\n","\n","  with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(val_loader):\n","      batch_x = batch_x.float().to(device)\n","      batch_y = batch_y.float().to(device)\n","\n","      # Get batch demographic data\n","      batch_demo = []\n","      for i in range(len(batch_name)):\n","        cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","        cur_idx = cur_id + '_' + cur_ep\n","        cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","        batch_demo.append(cur_demo)\n","      batch_demo = torch.stack(batch_demo).to(device)\n","\n","      # Get model outputs\n","      output, decov_loss = model(batch_x, batch_demo)\n","\n","      # Get loss\n","      loss = loss_func(output, batch_y.unsqueeze(-1))\n","      loss += decov_loss\n","      val_batch_total_loss.append(loss.cpu().detach().numpy())\n","      y_pred += list(output.cpu().detach().numpy())\n","      y_true += list(batch_y.cpu().numpy().flatten())\n","    \n","    val_total_loss.append(np.mean(np.array(val_batch_total_loss)))\n","    print('Epoch %d: Validation Loss = %.4f'%(epoch, np.mean(np.array(val_batch_total_loss))))\n","\n","    y_pred = np.array(y_pred)\n","    y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","    result = metrics.print_metrics_binary(y_true, y_pred)\n","    result_history.append(result)\n","\n","    cur_auroc = result['auroc']\n","    print('Epoch %d: Validation AUROC = %.4f'%(epoch, cur_auroc))\n","    \n","    if cur_auroc > max_roc:\n","        max_roc = cur_auroc\n","        state = {\n","            'net': model.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'epoch': epoch\n","        }\n","        torch.save(state, file_name)\n","        print('\\n------------ Save best model ------------\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SnVsIv98_uls","outputId":"6d3eb122-454d-4fbd-dcff-62fa2b778384","executionInfo":{"status":"ok","timestamp":1681268624022,"user_tz":300,"elapsed":2016155,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":198,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 Batch 0: Train Loss = 0.6550\n","Epoch 0 Batch 50: Train Loss = 0.4276\n","Epoch 0: Train Loss = 0.4236\n","Epoch 0: Validation Loss = 0.3986\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.4722230713839298\n","AUC of PRC = 0.12724271411033997\n","min(+P, Se) = 0.14481409001956946\n","f1_score = nan\n","Epoch 0: Validation AUROC = 0.4722\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 Batch 0: Train Loss = 0.3433\n","Epoch 1 Batch 50: Train Loss = 0.4014\n","Epoch 1: Train Loss = 0.4014\n","Epoch 1: Validation Loss = 0.4006\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6003055283823809\n","AUC of PRC = 0.18205209712450593\n","min(+P, Se) = 0.21484375\n","f1_score = nan\n","Epoch 1: Validation AUROC = 0.6003\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 Batch 0: Train Loss = 0.3778\n","Epoch 2 Batch 50: Train Loss = 0.4042\n","Epoch 2: Train Loss = 0.4008\n","Epoch 2: Validation Loss = 0.3995\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6270893623814571\n","AUC of PRC = 0.20175052133434207\n","min(+P, Se) = 0.24768518518518517\n","f1_score = nan\n","Epoch 2: Validation AUROC = 0.6271\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 Batch 0: Train Loss = 0.3806\n","Epoch 3 Batch 50: Train Loss = 0.4000\n","Epoch 3: Train Loss = 0.4015\n","Epoch 3: Validation Loss = 0.3983\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.621325677291378\n","AUC of PRC = 0.19983993592769675\n","min(+P, Se) = 0.25\n","f1_score = nan\n","Epoch 3: Validation AUROC = 0.6213\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 Batch 0: Train Loss = 0.3554\n","Epoch 4 Batch 50: Train Loss = 0.4013\n","Epoch 4: Train Loss = 0.3996\n","Epoch 4: Validation Loss = 0.3982\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6237322015706095\n","AUC of PRC = 0.20183394088016865\n","min(+P, Se) = 0.2545454545454545\n","f1_score = nan\n","Epoch 4: Validation AUROC = 0.6237\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5 Batch 0: Train Loss = 0.4103\n","Epoch 5 Batch 50: Train Loss = 0.4006\n","Epoch 5: Train Loss = 0.3999\n","Epoch 5: Validation Loss = 0.4007\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6350574712643677\n","AUC of PRC = 0.2055931631447042\n","min(+P, Se) = 0.24074074074074073\n","f1_score = nan\n","Epoch 5: Validation AUROC = 0.6351\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6 Batch 0: Train Loss = 0.3608\n","Epoch 6 Batch 50: Train Loss = 0.4040\n","Epoch 6: Train Loss = 0.3994\n","Epoch 6: Validation Loss = 0.4010\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6668241861634194\n","AUC of PRC = 0.22321569153624887\n","min(+P, Se) = 0.25517241379310346\n","f1_score = nan\n","Epoch 6: Validation AUROC = 0.6668\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7 Batch 0: Train Loss = 0.4480\n","Epoch 7 Batch 50: Train Loss = 0.3993\n","Epoch 7: Train Loss = 0.4006\n","Epoch 7: Validation Loss = 0.3950\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6292908141083122\n","AUC of PRC = 0.195283213054985\n","min(+P, Se) = 0.22453703703703703\n","f1_score = nan\n","Epoch 7: Validation AUROC = 0.6293\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8 Batch 0: Train Loss = 0.3864\n","Epoch 8 Batch 50: Train Loss = 0.3982\n","Epoch 8: Train Loss = 0.3991\n","Epoch 8: Validation Loss = 0.3927\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6539504700959212\n","AUC of PRC = 0.2106299159249932\n","min(+P, Se) = 0.23136246786632392\n","f1_score = nan\n","Epoch 8: Validation AUROC = 0.6540\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9 Batch 0: Train Loss = 0.4577\n","Epoch 9 Batch 50: Train Loss = 0.3948\n","Epoch 9: Train Loss = 0.3931\n","Epoch 9: Validation Loss = 0.3868\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6788895002853184\n","AUC of PRC = 0.2376056554990692\n","min(+P, Se) = 0.2647058823529412\n","f1_score = nan\n","Epoch 9: Validation AUROC = 0.6789\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10 Batch 0: Train Loss = 0.3853\n","Epoch 10 Batch 50: Train Loss = 0.3892\n","Epoch 10: Train Loss = 0.3890\n","Epoch 10: Validation Loss = 0.3823\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6898385913426266\n","AUC of PRC = 0.2465433416377089\n","min(+P, Se) = 0.2824074074074074\n","f1_score = nan\n","Epoch 10: Validation AUROC = 0.6898\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11 Batch 0: Train Loss = 0.3755\n","Epoch 11 Batch 50: Train Loss = 0.3911\n","Epoch 11: Train Loss = 0.3877\n","Epoch 11: Validation Loss = 0.3826\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6985679736963669\n","AUC of PRC = 0.2632955816887441\n","min(+P, Se) = 0.2950108459869848\n","f1_score = nan\n","Epoch 11: Validation AUROC = 0.6986\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12 Batch 0: Train Loss = 0.4798\n","Epoch 12 Batch 50: Train Loss = 0.3881\n","Epoch 12: Train Loss = 0.3890\n","Epoch 12: Validation Loss = 0.3795\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7010874364827042\n","AUC of PRC = 0.26998202720174774\n","min(+P, Se) = 0.30925925925925923\n","f1_score = nan\n","Epoch 12: Validation AUROC = 0.7011\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13 Batch 0: Train Loss = 0.3898\n","Epoch 13 Batch 50: Train Loss = 0.3845\n","Epoch 13: Train Loss = 0.3854\n","Epoch 13: Validation Loss = 0.3786\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6871127822613515\n","AUC of PRC = 0.25136228636084157\n","min(+P, Se) = 0.2865731462925852\n","f1_score = nan\n","Epoch 13: Validation AUROC = 0.6871\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14 Batch 0: Train Loss = 0.4279\n","Epoch 14 Batch 50: Train Loss = 0.3923\n","Epoch 14: Train Loss = 0.3917\n","Epoch 14: Validation Loss = 0.3821\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.6935961318985897\n","AUC of PRC = 0.26123167953078824\n","min(+P, Se) = 0.30484988452655887\n","f1_score = nan\n","Epoch 14: Validation AUROC = 0.6936\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15 Batch 0: Train Loss = 0.3896\n","Epoch 15 Batch 50: Train Loss = 0.3821\n","Epoch 15: Train Loss = 0.3831\n","Epoch 15: Validation Loss = 0.3787\n","confusion matrix:\n","[[2723    3]\n"," [ 431    1]]\n","accuracy = 0.8625712394714355\n","precision class 0 = 0.863348126411438\n","precision class 1 = 0.25\n","recall class 0 = 0.9988994598388672\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.697847884568354\n","AUC of PRC = 0.26441685017170447\n","min(+P, Se) = 0.3119266055045872\n","f1_score = 0.004587156158017453\n","Epoch 15: Validation AUROC = 0.6978\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16 Batch 0: Train Loss = 0.3387\n","Epoch 16 Batch 50: Train Loss = 0.3864\n","Epoch 16: Train Loss = 0.3863\n","Epoch 16: Validation Loss = 0.3727\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7016614697970165\n","AUC of PRC = 0.27558188060812333\n","min(+P, Se) = 0.33410138248847926\n","f1_score = nan\n","Epoch 16: Validation AUROC = 0.7017\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17 Batch 0: Train Loss = 0.4121\n","Epoch 17 Batch 50: Train Loss = 0.3812\n","Epoch 17: Train Loss = 0.3811\n","Epoch 17: Validation Loss = 0.3731\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7021463411320344\n","AUC of PRC = 0.27167836643538945\n","min(+P, Se) = 0.32805429864253394\n","f1_score = nan\n","Epoch 17: Validation AUROC = 0.7021\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18 Batch 0: Train Loss = 0.3994\n","Epoch 18 Batch 50: Train Loss = 0.3816\n","Epoch 18: Train Loss = 0.3808\n","Epoch 18: Validation Loss = 0.3731\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7034931116002283\n","AUC of PRC = 0.27659733692909916\n","min(+P, Se) = 0.32967032967032966\n","f1_score = nan\n","Epoch 18: Validation AUROC = 0.7035\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19 Batch 0: Train Loss = 0.3990\n","Epoch 19 Batch 50: Train Loss = 0.3767\n","Epoch 19: Train Loss = 0.3784\n","Epoch 19: Validation Loss = 0.3754\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7033496032716502\n","AUC of PRC = 0.27536661624138276\n","min(+P, Se) = 0.33263157894736844\n","f1_score = nan\n","Epoch 19: Validation AUROC = 0.7033\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20 Batch 0: Train Loss = 0.3763\n","Epoch 20 Batch 50: Train Loss = 0.3799\n","Epoch 20: Train Loss = 0.3797\n","Epoch 20: Validation Loss = 0.3734\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7047906306893834\n","AUC of PRC = 0.2723758834535616\n","min(+P, Se) = 0.33047210300429186\n","f1_score = nan\n","Epoch 20: Validation AUROC = 0.7048\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21 Batch 0: Train Loss = 0.3626\n","Epoch 21 Batch 50: Train Loss = 0.3824\n","Epoch 21: Train Loss = 0.3791\n","Epoch 21: Validation Loss = 0.3838\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7048364854215918\n","AUC of PRC = 0.28660887455074857\n","min(+P, Se) = 0.3510392609699769\n","f1_score = nan\n","Epoch 21: Validation AUROC = 0.7048\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22 Batch 0: Train Loss = 0.3095\n","Epoch 22 Batch 50: Train Loss = 0.3766\n","Epoch 22: Train Loss = 0.3755\n","Epoch 22: Validation Loss = 0.3700\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7096622714056684\n","AUC of PRC = 0.2853709150728726\n","min(+P, Se) = 0.3394919168591224\n","f1_score = nan\n","Epoch 22: Validation AUROC = 0.7097\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23 Batch 0: Train Loss = 0.4048\n","Epoch 23 Batch 50: Train Loss = 0.3801\n","Epoch 23: Train Loss = 0.3814\n","Epoch 23: Validation Loss = 0.3700\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7143063367843264\n","AUC of PRC = 0.2863737736795604\n","min(+P, Se) = 0.3333333333333333\n","f1_score = nan\n","Epoch 23: Validation AUROC = 0.7143\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24 Batch 0: Train Loss = 0.3558\n","Epoch 24 Batch 50: Train Loss = 0.3792\n","Epoch 24: Train Loss = 0.3782\n","Epoch 24: Validation Loss = 0.3675\n","confusion matrix:\n","[[2726    0]\n"," [ 431    1]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8634780049324036\n","precision class 1 = 1.0\n","recall class 0 = 1.0\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7181182236895736\n","AUC of PRC = 0.2966043330317828\n","min(+P, Se) = 0.3541666666666667\n","f1_score = 0.004618937719448061\n","Epoch 24: Validation AUROC = 0.7181\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25 Batch 0: Train Loss = 0.3396\n","Epoch 25 Batch 50: Train Loss = 0.3760\n","Epoch 25: Train Loss = 0.3753\n","Epoch 25: Validation Loss = 0.3685\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7222774177332139\n","AUC of PRC = 0.29521425761619946\n","min(+P, Se) = 0.3402777777777778\n","f1_score = nan\n","Epoch 25: Validation AUROC = 0.7223\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26 Batch 0: Train Loss = 0.3614\n","Epoch 26 Batch 50: Train Loss = 0.3787\n","Epoch 26: Train Loss = 0.3773\n","Epoch 26: Validation Loss = 0.3664\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7226094399608706\n","AUC of PRC = 0.29982786556993624\n","min(+P, Se) = 0.34988713318284426\n","f1_score = nan\n","Epoch 26: Validation AUROC = 0.7226\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27 Batch 0: Train Loss = 0.4259\n","Epoch 27 Batch 50: Train Loss = 0.3753\n","Epoch 27: Train Loss = 0.3726\n","Epoch 27: Validation Loss = 0.3642\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.729857035134915\n","AUC of PRC = 0.31395336543195623\n","min(+P, Se) = 0.3709677419354839\n","f1_score = nan\n","Epoch 27: Validation AUROC = 0.7299\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28 Batch 0: Train Loss = 0.3915\n","Epoch 28 Batch 50: Train Loss = 0.3714\n","Epoch 28: Train Loss = 0.3739\n","Epoch 28: Validation Loss = 0.3688\n","confusion matrix:\n","[[2724    2]\n"," [ 431    1]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8633914589881897\n","precision class 1 = 0.3333333432674408\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7263143324909649\n","AUC of PRC = 0.3065266098627568\n","min(+P, Se) = 0.3433179723502304\n","f1_score = 0.004597701305583315\n","Epoch 28: Validation AUROC = 0.7263\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29 Batch 0: Train Loss = 0.3926\n","Epoch 29 Batch 50: Train Loss = 0.3736\n","Epoch 29: Train Loss = 0.3692\n","Epoch 29: Validation Loss = 0.3645\n","confusion matrix:\n","[[2724    2]\n"," [ 431    1]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8633914589881897\n","precision class 1 = 0.3333333432674408\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7272322762968398\n","AUC of PRC = 0.3082962195356761\n","min(+P, Se) = 0.3524416135881104\n","f1_score = 0.004597701305583315\n","Epoch 29: Validation AUROC = 0.7272\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30 Batch 0: Train Loss = 0.3868\n","Epoch 30 Batch 50: Train Loss = 0.3718\n","Epoch 30: Train Loss = 0.3698\n","Epoch 30: Validation Loss = 0.3659\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7325811458927746\n","AUC of PRC = 0.3169988937548251\n","min(+P, Se) = 0.367816091954023\n","f1_score = nan\n","Epoch 30: Validation AUROC = 0.7326\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31 Batch 0: Train Loss = 0.3747\n","Epoch 31 Batch 50: Train Loss = 0.3641\n","Epoch 31: Train Loss = 0.3696\n","Epoch 31: Validation Loss = 0.3733\n","confusion matrix:\n","[[2724    2]\n"," [ 425    7]]\n","accuracy = 0.8647878170013428\n","precision class 0 = 0.8650365471839905\n","precision class 1 = 0.7777777910232544\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.016203703358769417\n","AUC of ROC = 0.7124712983342845\n","AUC of PRC = 0.2897387206039861\n","min(+P, Se) = 0.3425925925925926\n","f1_score = 0.03174603116954182\n","Epoch 31: Validation AUROC = 0.7125\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32 Batch 0: Train Loss = 0.3967\n","Epoch 32 Batch 50: Train Loss = 0.3759\n","Epoch 32: Train Loss = 0.3742\n","Epoch 32: Validation Loss = 0.3697\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7299317613651803\n","AUC of PRC = 0.30755608837704534\n","min(+P, Se) = 0.3690205011389522\n","f1_score = nan\n","Epoch 32: Validation AUROC = 0.7299\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33 Batch 0: Train Loss = 0.2513\n","Epoch 33 Batch 50: Train Loss = 0.3656\n","Epoch 33: Train Loss = 0.3712\n","Epoch 33: Validation Loss = 0.3663\n","confusion matrix:\n","[[2725    1]\n"," [ 431    1]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8634347319602966\n","precision class 1 = 0.5\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7342285196054454\n","AUC of PRC = 0.31173020278254326\n","min(+P, Se) = 0.3532110091743119\n","f1_score = 0.00460829504622042\n","Epoch 33: Validation AUROC = 0.7342\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34 Batch 0: Train Loss = 0.3489\n","Epoch 34 Batch 50: Train Loss = 0.3665\n","Epoch 34: Train Loss = 0.3669\n","Epoch 34: Validation Loss = 0.3621\n","confusion matrix:\n","[[2722    4]\n"," [ 426    6]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8646759986877441\n","precision class 1 = 0.6000000238418579\n","recall class 0 = 0.9985326528549194\n","recall class 1 = 0.013888888992369175\n","AUC of ROC = 0.7365552226841662\n","AUC of PRC = 0.3152958581920026\n","min(+P, Se) = 0.36926605504587157\n","f1_score = 0.02714932120076265\n","Epoch 34: Validation AUROC = 0.7366\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35 Batch 0: Train Loss = 0.4136\n","Epoch 35 Batch 50: Train Loss = 0.3705\n","Epoch 35: Train Loss = 0.3676\n","Epoch 35: Validation Loss = 0.3604\n","confusion matrix:\n","[[2726    0]\n"," [ 431    1]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8634780049324036\n","precision class 1 = 1.0\n","recall class 0 = 1.0\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7404095676747915\n","AUC of PRC = 0.3257587020773653\n","min(+P, Se) = 0.3721461187214612\n","f1_score = 0.004618937719448061\n","Epoch 35: Validation AUROC = 0.7404\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36 Batch 0: Train Loss = 0.3847\n","Epoch 36 Batch 50: Train Loss = 0.3660\n","Epoch 36: Train Loss = 0.3638\n","Epoch 36: Validation Loss = 0.3605\n","confusion matrix:\n","[[2720    6]\n"," [ 424    8]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8651399612426758\n","precision class 1 = 0.5714285969734192\n","recall class 0 = 0.9977989792823792\n","recall class 1 = 0.018518518656492233\n","AUC of ROC = 0.7314504870791555\n","AUC of PRC = 0.3105221316740441\n","min(+P, Se) = 0.363013698630137\n","f1_score = 0.035874440450719525\n","Epoch 36: Validation AUROC = 0.7315\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37 Batch 0: Train Loss = 0.3826\n","Epoch 37 Batch 50: Train Loss = 0.3634\n","Epoch 37: Train Loss = 0.3659\n","Epoch 37: Validation Loss = 0.3601\n","confusion matrix:\n","[[2719    7]\n"," [ 424    8]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8650970458984375\n","precision class 1 = 0.5333333611488342\n","recall class 0 = 0.9974321126937866\n","recall class 1 = 0.018518518656492233\n","AUC of ROC = 0.7419104609929079\n","AUC of PRC = 0.3200703111706331\n","min(+P, Se) = 0.3709677419354839\n","f1_score = 0.03579418449046175\n","Epoch 37: Validation AUROC = 0.7419\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38 Batch 0: Train Loss = 0.3040\n","Epoch 38 Batch 50: Train Loss = 0.3672\n","Epoch 38: Train Loss = 0.3654\n","Epoch 38: Validation Loss = 0.3601\n","confusion matrix:\n","[[2724    2]\n"," [ 431    1]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8633914589881897\n","precision class 1 = 0.3333333432674408\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7401429308986168\n","AUC of PRC = 0.32128126767773835\n","min(+P, Se) = 0.3530751708428246\n","f1_score = 0.004597701305583315\n","Epoch 38: Validation AUROC = 0.7401\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39 Batch 0: Train Loss = 0.3831\n","Epoch 39 Batch 50: Train Loss = 0.3654\n","Epoch 39: Train Loss = 0.3638\n","Epoch 39: Validation Loss = 0.3632\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7420153324637918\n","AUC of PRC = 0.3238810140695584\n","min(+P, Se) = 0.375\n","f1_score = nan\n","Epoch 39: Validation AUROC = 0.7420\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40 Batch 0: Train Loss = 0.3173\n","Epoch 40 Batch 50: Train Loss = 0.3645\n","Epoch 40: Train Loss = 0.3625\n","Epoch 40: Validation Loss = 0.3571\n","confusion matrix:\n","[[2723    3]\n"," [ 430    2]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8636219501495361\n","precision class 1 = 0.4000000059604645\n","recall class 0 = 0.9988994598388672\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7418582375478927\n","AUC of PRC = 0.32503982538463094\n","min(+P, Se) = 0.3773148148148148\n","f1_score = 0.009153317872898494\n","Epoch 40: Validation AUROC = 0.7419\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41 Batch 0: Train Loss = 0.3185\n","Epoch 41 Batch 50: Train Loss = 0.3599\n","Epoch 41: Train Loss = 0.3634\n","Epoch 41: Validation Loss = 0.3605\n","confusion matrix:\n","[[2716   10]\n"," [ 414   18]]\n","accuracy = 0.865737795829773\n","precision class 0 = 0.8677316308021545\n","precision class 1 = 0.6428571343421936\n","recall class 0 = 0.9963316321372986\n","recall class 1 = 0.0416666679084301\n","AUC of ROC = 0.7423201815168067\n","AUC of PRC = 0.3237316685987522\n","min(+P, Se) = 0.3726851851851852\n","f1_score = 0.07826086956296388\n","Epoch 41: Validation AUROC = 0.7423\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42 Batch 0: Train Loss = 0.3417\n","Epoch 42 Batch 50: Train Loss = 0.3643\n","Epoch 42: Train Loss = 0.3628\n","Epoch 42: Validation Loss = 0.3572\n","confusion matrix:\n","[[2722    4]\n"," [ 432    0]]\n","accuracy = 0.861937940120697\n","precision class 0 = 0.8630310893058777\n","precision class 1 = 0.0\n","recall class 0 = 0.9985326528549194\n","recall class 1 = 0.0\n","AUC of ROC = 0.7389218363631423\n","AUC of PRC = 0.3217026209031741\n","min(+P, Se) = 0.37037037037037035\n","f1_score = nan\n","Epoch 42: Validation AUROC = 0.7389\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43 Batch 0: Train Loss = 0.4656\n","Epoch 43 Batch 50: Train Loss = 0.3638\n","Epoch 43: Train Loss = 0.3651\n","Epoch 43: Validation Loss = 0.3590\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7400359365234641\n","AUC of PRC = 0.3209111891579369\n","min(+P, Se) = 0.3773148148148148\n","f1_score = nan\n","Epoch 43: Validation AUROC = 0.7400\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44 Batch 0: Train Loss = 0.4323\n","Epoch 44 Batch 50: Train Loss = 0.3634\n","Epoch 44: Train Loss = 0.3647\n","Epoch 44: Validation Loss = 0.3591\n","confusion matrix:\n","[[2723    3]\n"," [ 431    1]]\n","accuracy = 0.8625712394714355\n","precision class 0 = 0.863348126411438\n","precision class 1 = 0.25\n","recall class 0 = 0.9988994598388672\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7377338591342626\n","AUC of PRC = 0.3222673984942424\n","min(+P, Se) = 0.3587962962962963\n","f1_score = 0.004587156158017453\n","Epoch 44: Validation AUROC = 0.7377\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45 Batch 0: Train Loss = 0.3106\n","Epoch 45 Batch 50: Train Loss = 0.3651\n","Epoch 45: Train Loss = 0.3640\n","Epoch 45: Validation Loss = 0.3574\n","confusion matrix:\n","[[2721    5]\n"," [ 425    7]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8649078011512756\n","precision class 1 = 0.5833333134651184\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.016203703358769417\n","AUC of ROC = 0.7387375682726013\n","AUC of PRC = 0.32194877316799597\n","min(+P, Se) = 0.37471264367816093\n","f1_score = 0.03153153094738569\n","Epoch 45: Validation AUROC = 0.7387\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46 Batch 0: Train Loss = 0.3204\n","Epoch 46 Batch 50: Train Loss = 0.3609\n","Epoch 46: Train Loss = 0.3597\n","Epoch 46: Validation Loss = 0.3569\n","confusion matrix:\n","[[2723    3]\n"," [ 430    2]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8636219501495361\n","precision class 1 = 0.4000000059604645\n","recall class 0 = 0.9988994598388672\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7397387299258172\n","AUC of PRC = 0.3189202116100041\n","min(+P, Se) = 0.3663594470046083\n","f1_score = 0.009153317872898494\n","Epoch 46: Validation AUROC = 0.7397\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47 Batch 0: Train Loss = 0.4412\n","Epoch 47 Batch 50: Train Loss = 0.3547\n","Epoch 47: Train Loss = 0.3592\n","Epoch 47: Validation Loss = 0.3563\n","confusion matrix:\n","[[2718    8]\n"," [ 424    8]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8650541305541992\n","precision class 1 = 0.5\n","recall class 0 = 0.9970653057098389\n","recall class 1 = 0.018518518656492233\n","AUC of ROC = 0.7405607184587374\n","AUC of PRC = 0.323034992488209\n","min(+P, Se) = 0.3648960739030023\n","f1_score = 0.03571428674064123\n","Epoch 47: Validation AUROC = 0.7406\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48 Batch 0: Train Loss = 0.3455\n","Epoch 48 Batch 50: Train Loss = 0.3587\n","Epoch 48: Train Loss = 0.3591\n","Epoch 48: Validation Loss = 0.3562\n","confusion matrix:\n","[[2717    9]\n"," [ 422   10]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8655622601509094\n","precision class 1 = 0.5263158082962036\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.023148147389292717\n","AUC of ROC = 0.7432848292165973\n","AUC of PRC = 0.31971133456180567\n","min(+P, Se) = 0.3646788990825688\n","f1_score = 0.04434589893366464\n","Epoch 48: Validation AUROC = 0.7433\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49 Batch 0: Train Loss = 0.4663\n","Epoch 49 Batch 50: Train Loss = 0.3639\n","Epoch 49: Train Loss = 0.3617\n","Epoch 49: Validation Loss = 0.3565\n","confusion matrix:\n","[[2725    1]\n"," [ 431    1]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8634347319602966\n","precision class 1 = 0.5\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7443675103937393\n","AUC of PRC = 0.32821488875321747\n","min(+P, Se) = 0.37333333333333335\n","f1_score = 0.00460829504622042\n","Epoch 49: Validation AUROC = 0.7444\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50 Batch 0: Train Loss = 0.3812\n","Epoch 50 Batch 50: Train Loss = 0.3595\n","Epoch 50: Train Loss = 0.3596\n","Epoch 50: Validation Loss = 0.3568\n","confusion matrix:\n","[[2723    3]\n"," [ 431    1]]\n","accuracy = 0.8625712394714355\n","precision class 0 = 0.863348126411438\n","precision class 1 = 0.25\n","recall class 0 = 0.9988994598388672\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7394525624303687\n","AUC of PRC = 0.318713499416251\n","min(+P, Se) = 0.3539651837524178\n","f1_score = 0.004587156158017453\n","Epoch 50: Validation AUROC = 0.7395\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51 Batch 0: Train Loss = 0.3288\n","Epoch 51 Batch 50: Train Loss = 0.3604\n","Epoch 51: Train Loss = 0.3630\n","Epoch 51: Validation Loss = 0.3564\n","confusion matrix:\n","[[2724    2]\n"," [ 432    0]]\n","accuracy = 0.8625712394714355\n","precision class 0 = 0.8631178736686707\n","precision class 1 = 0.0\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.0\n","AUC of ROC = 0.7463553979511427\n","AUC of PRC = 0.3250438283380764\n","min(+P, Se) = 0.3789954337899543\n","f1_score = nan\n","Epoch 51: Validation AUROC = 0.7464\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52 Batch 0: Train Loss = 0.3470\n","Epoch 52 Batch 50: Train Loss = 0.3605\n","Epoch 52: Train Loss = 0.3596\n","Epoch 52: Validation Loss = 0.3587\n","confusion matrix:\n","[[2724    2]\n"," [ 432    0]]\n","accuracy = 0.8625712394714355\n","precision class 0 = 0.8631178736686707\n","precision class 1 = 0.0\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.0\n","AUC of ROC = 0.739042417325616\n","AUC of PRC = 0.3163668714155133\n","min(+P, Se) = 0.3721881390593047\n","f1_score = nan\n","Epoch 52: Validation AUROC = 0.7390\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53 Batch 0: Train Loss = 0.3654\n","Epoch 53 Batch 50: Train Loss = 0.3614\n","Epoch 53: Train Loss = 0.3614\n","Epoch 53: Validation Loss = 0.3551\n","confusion matrix:\n","[[2722    4]\n"," [ 431    1]]\n","accuracy = 0.8622546195983887\n","precision class 0 = 0.8633047938346863\n","precision class 1 = 0.20000000298023224\n","recall class 0 = 0.9985326528549194\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7437221474959919\n","AUC of PRC = 0.32462206856390796\n","min(+P, Se) = 0.3726851851851852\n","f1_score = 0.004576658936449247\n","Epoch 53: Validation AUROC = 0.7437\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54 Batch 0: Train Loss = 0.3745\n","Epoch 54 Batch 50: Train Loss = 0.3597\n","Epoch 54: Train Loss = 0.3585\n","Epoch 54: Validation Loss = 0.3562\n","confusion matrix:\n","[[2723    3]\n"," [ 431    1]]\n","accuracy = 0.8625712394714355\n","precision class 0 = 0.863348126411438\n","precision class 1 = 0.25\n","recall class 0 = 0.9988994598388672\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.744963621912448\n","AUC of PRC = 0.328267283405552\n","min(+P, Se) = 0.3752808988764045\n","f1_score = 0.004587156158017453\n","Epoch 54: Validation AUROC = 0.7450\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55 Batch 0: Train Loss = 0.3738\n","Epoch 55 Batch 50: Train Loss = 0.3566\n","Epoch 55: Train Loss = 0.3576\n","Epoch 55: Validation Loss = 0.3546\n","confusion matrix:\n","[[2721    5]\n"," [ 427    5]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8643583059310913\n","precision class 1 = 0.5\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.011574073694646358\n","AUC of ROC = 0.7444057226705797\n","AUC of PRC = 0.32458762102085714\n","min(+P, Se) = 0.37727272727272726\n","f1_score = 0.02262443296404001\n","Epoch 55: Validation AUROC = 0.7444\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56 Batch 0: Train Loss = 0.3533\n","Epoch 56 Batch 50: Train Loss = 0.3598\n","Epoch 56: Train Loss = 0.3582\n","Epoch 56: Validation Loss = 0.3579\n","confusion matrix:\n","[[2725    1]\n"," [ 431    1]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8634347319602966\n","precision class 1 = 0.5\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7443895885981359\n","AUC of PRC = 0.3201330907965557\n","min(+P, Se) = 0.36574074074074076\n","f1_score = 0.00460829504622042\n","Epoch 56: Validation AUROC = 0.7444\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57 Batch 0: Train Loss = 0.4445\n","Epoch 57 Batch 50: Train Loss = 0.3537\n","Epoch 57: Train Loss = 0.3545\n","Epoch 57: Validation Loss = 0.3560\n","confusion matrix:\n","[[2710   16]\n"," [ 417   15]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.866645336151123\n","precision class 1 = 0.4838709533214569\n","recall class 0 = 0.9941306114196777\n","recall class 1 = 0.0347222238779068\n","AUC of ROC = 0.742864494171354\n","AUC of PRC = 0.3159780820349902\n","min(+P, Se) = 0.34868421052631576\n","f1_score = 0.06479481730638327\n","Epoch 57: Validation AUROC = 0.7429\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58 Batch 0: Train Loss = 0.2828\n","Epoch 58 Batch 50: Train Loss = 0.3571\n","Epoch 58: Train Loss = 0.3607\n","Epoch 58: Validation Loss = 0.3557\n","confusion matrix:\n","[[2721    5]\n"," [ 423    9]]\n","accuracy = 0.8644711971282959\n","precision class 0 = 0.8654580116271973\n","precision class 1 = 0.6428571343421936\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.02083333395421505\n","AUC of ROC = 0.7445229069862233\n","AUC of PRC = 0.32708062269877064\n","min(+P, Se) = 0.3755656108597285\n","f1_score = 0.04035874678880095\n","Epoch 58: Validation AUROC = 0.7445\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59 Batch 0: Train Loss = 0.3368\n","Epoch 59 Batch 50: Train Loss = 0.3543\n","Epoch 59: Train Loss = 0.3550\n","Epoch 59: Validation Loss = 0.3533\n","confusion matrix:\n","[[2725    1]\n"," [ 430    2]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8637083768844604\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7466101464634114\n","AUC of PRC = 0.3426890547768269\n","min(+P, Se) = 0.37962962962962965\n","f1_score = 0.00919540261116663\n","Epoch 59: Validation AUROC = 0.7466\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60 Batch 0: Train Loss = 0.3694\n","Epoch 60 Batch 50: Train Loss = 0.3624\n","Epoch 60: Train Loss = 0.3603\n","Epoch 60: Validation Loss = 0.3687\n","confusion matrix:\n","[[2725    1]\n"," [ 432    0]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8631612062454224\n","precision class 1 = 0.0\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.0\n","AUC of ROC = 0.7404422604005326\n","AUC of PRC = 0.32498426265449626\n","min(+P, Se) = 0.3568181818181818\n","f1_score = nan\n","Epoch 60: Validation AUROC = 0.7404\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61 Batch 0: Train Loss = 0.3214\n","Epoch 61 Batch 50: Train Loss = 0.3612\n","Epoch 61: Train Loss = 0.3603\n","Epoch 61: Validation Loss = 0.3528\n","confusion matrix:\n","[[2720    6]\n"," [ 414   18]]\n","accuracy = 0.8670044541358948\n","precision class 0 = 0.8679004311561584\n","precision class 1 = 0.75\n","recall class 0 = 0.9977989792823792\n","recall class 1 = 0.0416666679084301\n","AUC of ROC = 0.7482779000570636\n","AUC of PRC = 0.33025485874398336\n","min(+P, Se) = 0.37962962962962965\n","f1_score = 0.07894736879254971\n","Epoch 61: Validation AUROC = 0.7483\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62 Batch 0: Train Loss = 0.3700\n","Epoch 62 Batch 50: Train Loss = 0.3572\n","Epoch 62: Train Loss = 0.3558\n","Epoch 62: Validation Loss = 0.3531\n","confusion matrix:\n","[[2719    7]\n"," [ 428    4]]\n","accuracy = 0.8622546195983887\n","precision class 0 = 0.8639974594116211\n","precision class 1 = 0.3636363744735718\n","recall class 0 = 0.9974321126937866\n","recall class 1 = 0.009259259328246117\n","AUC of ROC = 0.7489139221760278\n","AUC of PRC = 0.3319311286070882\n","min(+P, Se) = 0.3686635944700461\n","f1_score = 0.018058691160105524\n","Epoch 62: Validation AUROC = 0.7489\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63 Batch 0: Train Loss = 0.3026\n","Epoch 63 Batch 50: Train Loss = 0.3569\n","Epoch 63: Train Loss = 0.3568\n","Epoch 63: Validation Loss = 0.3588\n","confusion matrix:\n","[[2725    1]\n"," [ 428    4]]\n","accuracy = 0.8641545176506042\n","precision class 0 = 0.8642562627792358\n","precision class 1 = 0.800000011920929\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.009259259328246117\n","AUC of ROC = 0.7429044047716096\n","AUC of PRC = 0.329861701289313\n","min(+P, Se) = 0.36681222707423583\n","f1_score = 0.01830663574579699\n","Epoch 63: Validation AUROC = 0.7429\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64 Batch 0: Train Loss = 0.3505\n","Epoch 64 Batch 50: Train Loss = 0.3598\n","Epoch 64: Train Loss = 0.3606\n","Epoch 64: Validation Loss = 0.3580\n","confusion matrix:\n","[[2725    1]\n"," [ 430    2]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8637083768844604\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7428568517159859\n","AUC of PRC = 0.32714486725654723\n","min(+P, Se) = 0.38657407407407407\n","f1_score = 0.00919540261116663\n","Epoch 64: Validation AUROC = 0.7429\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65 Batch 0: Train Loss = 0.3523\n","Epoch 65 Batch 50: Train Loss = 0.3565\n","Epoch 65: Train Loss = 0.3566\n","Epoch 65: Validation Loss = 0.3568\n","confusion matrix:\n","[[2721    5]\n"," [ 432    0]]\n","accuracy = 0.8616212606430054\n","precision class 0 = 0.8629876375198364\n","precision class 1 = 0.0\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.0\n","AUC of ROC = 0.7399726739762507\n","AUC of PRC = 0.31919366667687404\n","min(+P, Se) = 0.3579676674364896\n","f1_score = nan\n","Epoch 65: Validation AUROC = 0.7400\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:31: RuntimeWarning: invalid value encountered in double_scalars\n","  f1_score=2*prec1*rec1/(prec1+rec1)\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66 Batch 0: Train Loss = 0.3793\n","Epoch 66 Batch 50: Train Loss = 0.3591\n","Epoch 66: Train Loss = 0.3597\n","Epoch 66: Validation Loss = 0.3534\n","confusion matrix:\n","[[2721    5]\n"," [ 428    4]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8640838265419006\n","precision class 1 = 0.4444444477558136\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.009259259328246117\n","AUC of ROC = 0.7476452745849299\n","AUC of PRC = 0.32956013436184295\n","min(+P, Se) = 0.3574660633484163\n","f1_score = 0.01814058992774325\n","Epoch 66: Validation AUROC = 0.7476\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67 Batch 0: Train Loss = 0.3242\n","Epoch 67 Batch 50: Train Loss = 0.3532\n","Epoch 67: Train Loss = 0.3544\n","Epoch 67: Validation Loss = 0.3525\n","confusion matrix:\n","[[2717    9]\n"," [ 421   11]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8658381104469299\n","precision class 1 = 0.550000011920929\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.025462962687015533\n","AUC of ROC = 0.7502674859378822\n","AUC of PRC = 0.3281189134844248\n","min(+P, Se) = 0.3638132295719844\n","f1_score = 0.04867256402371879\n","Epoch 67: Validation AUROC = 0.7503\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68 Batch 0: Train Loss = 0.3239\n","Epoch 68 Batch 50: Train Loss = 0.3566\n","Epoch 68: Train Loss = 0.3572\n","Epoch 68: Validation Loss = 0.3545\n","confusion matrix:\n","[[2721    5]\n"," [ 430    2]]\n","accuracy = 0.8622546195983887\n","precision class 0 = 0.8635354042053223\n","precision class 1 = 0.2857142984867096\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7466831743702617\n","AUC of PRC = 0.32827065023632274\n","min(+P, Se) = 0.35372848948374763\n","f1_score = 0.009111617005422349\n","Epoch 68: Validation AUROC = 0.7467\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69 Batch 0: Train Loss = 0.3679\n","Epoch 69 Batch 50: Train Loss = 0.3557\n","Epoch 69: Train Loss = 0.3558\n","Epoch 69: Validation Loss = 0.3531\n","confusion matrix:\n","[[2718    8]\n"," [ 422   10]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8656051158905029\n","precision class 1 = 0.5555555820465088\n","recall class 0 = 0.9970653057098389\n","recall class 1 = 0.023148147389292717\n","AUC of ROC = 0.7480392856172386\n","AUC of PRC = 0.33378835832526865\n","min(+P, Se) = 0.3741496598639456\n","f1_score = 0.04444444527626031\n","Epoch 69: Validation AUROC = 0.7480\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70 Batch 0: Train Loss = 0.4229\n","Epoch 70 Batch 50: Train Loss = 0.3573\n","Epoch 70: Train Loss = 0.3544\n","Epoch 70: Validation Loss = 0.3519\n","confusion matrix:\n","[[2721    5]\n"," [ 424    8]]\n","accuracy = 0.8641545176506042\n","precision class 0 = 0.8651828169822693\n","precision class 1 = 0.6153846383094788\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.018518518656492233\n","AUC of ROC = 0.750116335153936\n","AUC of PRC = 0.3414353442051985\n","min(+P, Se) = 0.36574074074074076\n","f1_score = 0.035955057112861497\n","Epoch 70: Validation AUROC = 0.7501\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71 Batch 0: Train Loss = 0.3359\n","Epoch 71 Batch 50: Train Loss = 0.3543\n","Epoch 71: Train Loss = 0.3571\n","Epoch 71: Validation Loss = 0.3593\n","confusion matrix:\n","[[2708   18]\n"," [ 409   23]]\n","accuracy = 0.8647878170013428\n","precision class 0 = 0.8687840700149536\n","precision class 1 = 0.5609756112098694\n","recall class 0 = 0.9933969378471375\n","recall class 1 = 0.05324074253439903\n","AUC of ROC = 0.7463316214233309\n","AUC of PRC = 0.33452435819320286\n","min(+P, Se) = 0.37471264367816093\n","f1_score = 0.09725159276678391\n","Epoch 71: Validation AUROC = 0.7463\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72 Batch 0: Train Loss = 0.3417\n","Epoch 72 Batch 50: Train Loss = 0.3594\n","Epoch 72: Train Loss = 0.3591\n","Epoch 72: Validation Loss = 0.3590\n","confusion matrix:\n","[[2725    1]\n"," [ 431    1]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8634347319602966\n","precision class 1 = 0.5\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7395544618352762\n","AUC of PRC = 0.325418600278204\n","min(+P, Se) = 0.3680555555555556\n","f1_score = 0.00460829504622042\n","Epoch 72: Validation AUROC = 0.7396\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73 Batch 0: Train Loss = 0.3319\n","Epoch 73 Batch 50: Train Loss = 0.3622\n","Epoch 73: Train Loss = 0.3613\n","Epoch 73: Validation Loss = 0.3623\n","confusion matrix:\n","[[2726    0]\n"," [ 432    0]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8632045388221741\n","precision class 1 = nan\n","recall class 0 = 1.0\n","recall class 1 = 0.0\n","AUC of ROC = 0.7462042471671966\n","AUC of PRC = 0.32430858313384603\n","min(+P, Se) = 0.36342592592592593\n","f1_score = nan\n","Epoch 73: Validation AUROC = 0.7462\n"]},{"output_type":"stream","name":"stderr","text":["/content/drive/My Drive/CS598_DL4H/mimic3-benchmarks-master/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n","  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n","<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74 Batch 0: Train Loss = 0.3752\n","Epoch 74 Batch 50: Train Loss = 0.3554\n","Epoch 74: Train Loss = 0.3543\n","Epoch 74: Validation Loss = 0.3530\n","confusion matrix:\n","[[2721    5]\n"," [ 426    6]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8646329641342163\n","precision class 1 = 0.5454545617103577\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.013888888992369175\n","AUC of ROC = 0.7467222358088096\n","AUC of PRC = 0.33025211201168925\n","min(+P, Se) = 0.3695150115473441\n","f1_score = 0.02708803601852081\n","Epoch 74: Validation AUROC = 0.7467\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75 Batch 0: Train Loss = 0.3600\n","Epoch 75 Batch 50: Train Loss = 0.3526\n","Epoch 75: Train Loss = 0.3556\n","Epoch 75: Validation Loss = 0.3635\n","confusion matrix:\n","[[2698   28]\n"," [ 396   36]]\n","accuracy = 0.865737795829773\n","precision class 0 = 0.872010350227356\n","precision class 1 = 0.5625\n","recall class 0 = 0.9897285103797913\n","recall class 1 = 0.0833333358168602\n","AUC of ROC = 0.7472410736121302\n","AUC of PRC = 0.3284017206173994\n","min(+P, Se) = 0.35648148148148145\n","f1_score = 0.14516129911442108\n","Epoch 75: Validation AUROC = 0.7472\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76 Batch 0: Train Loss = 0.3594\n","Epoch 76 Batch 50: Train Loss = 0.3549\n","Epoch 76: Train Loss = 0.3547\n","Epoch 76: Validation Loss = 0.3556\n","confusion matrix:\n","[[2724    2]\n"," [ 431    1]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8633914589881897\n","precision class 1 = 0.3333333432674408\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.745475666422108\n","AUC of PRC = 0.3295292209604226\n","min(+P, Se) = 0.3541666666666667\n","f1_score = 0.004597701305583315\n","Epoch 76: Validation AUROC = 0.7455\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77 Batch 0: Train Loss = 0.3275\n","Epoch 77 Batch 50: Train Loss = 0.3549\n","Epoch 77: Train Loss = 0.3543\n","Epoch 77: Validation Loss = 0.3545\n","confusion matrix:\n","[[2724    2]\n"," [ 431    1]]\n","accuracy = 0.8628879189491272\n","precision class 0 = 0.8633914589881897\n","precision class 1 = 0.3333333432674408\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7478635091437733\n","AUC of PRC = 0.335595725497309\n","min(+P, Se) = 0.3587962962962963\n","f1_score = 0.004597701305583315\n","Epoch 77: Validation AUROC = 0.7479\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78 Batch 0: Train Loss = 0.4104\n","Epoch 78 Batch 50: Train Loss = 0.3580\n","Epoch 78: Train Loss = 0.3544\n","Epoch 78: Validation Loss = 0.3541\n","confusion matrix:\n","[[2726    0]\n"," [ 431    1]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8634780049324036\n","precision class 1 = 1.0\n","recall class 0 = 1.0\n","recall class 1 = 0.002314814832061529\n","AUC of ROC = 0.7526217867720986\n","AUC of PRC = 0.33647191307972524\n","min(+P, Se) = 0.3709677419354839\n","f1_score = 0.004618937719448061\n","Epoch 78: Validation AUROC = 0.7526\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79 Batch 0: Train Loss = 0.3720\n","Epoch 79 Batch 50: Train Loss = 0.3576\n","Epoch 79: Train Loss = 0.3548\n","Epoch 79: Validation Loss = 0.3523\n","confusion matrix:\n","[[2724    2]\n"," [ 428    4]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8642131686210632\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.009259259328246117\n","AUC of ROC = 0.7496467487296541\n","AUC of PRC = 0.3347164312420402\n","min(+P, Se) = 0.35355648535564854\n","f1_score = 0.0182648396700045\n","Epoch 79: Validation AUROC = 0.7496\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80 Batch 0: Train Loss = 0.3082\n","Epoch 80 Batch 50: Train Loss = 0.3548\n","Epoch 80: Train Loss = 0.3526\n","Epoch 80: Validation Loss = 0.3545\n","confusion matrix:\n","[[2726    0]\n"," [ 429    3]]\n","accuracy = 0.8641545176506042\n","precision class 0 = 0.864025354385376\n","precision class 1 = 1.0\n","recall class 0 = 1.0\n","recall class 1 = 0.0069444444961845875\n","AUC of ROC = 0.7441110635580555\n","AUC of PRC = 0.33574190547193855\n","min(+P, Se) = 0.3574660633484163\n","f1_score = 0.013793103913915014\n","Epoch 80: Validation AUROC = 0.7441\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81 Batch 0: Train Loss = 0.4071\n","Epoch 81 Batch 50: Train Loss = 0.3514\n","Epoch 81: Train Loss = 0.3520\n","Epoch 81: Validation Loss = 0.3596\n","confusion matrix:\n","[[2720    6]\n"," [ 429    3]]\n","accuracy = 0.8622546195983887\n","precision class 0 = 0.8637662529945374\n","precision class 1 = 0.3333333432674408\n","recall class 0 = 0.9977989792823792\n","recall class 1 = 0.0069444444961845875\n","AUC of ROC = 0.7464454090921442\n","AUC of PRC = 0.31594396991647955\n","min(+P, Se) = 0.3597285067873303\n","f1_score = 0.01360544215411457\n","Epoch 81: Validation AUROC = 0.7464\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82 Batch 0: Train Loss = 0.3765\n","Epoch 82 Batch 50: Train Loss = 0.3541\n","Epoch 82: Train Loss = 0.3562\n","Epoch 82: Validation Loss = 0.3566\n","confusion matrix:\n","[[2723    3]\n"," [ 428    4]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8641701340675354\n","precision class 1 = 0.5714285969734192\n","recall class 0 = 0.9988994598388672\n","recall class 1 = 0.009259259328246117\n","AUC of ROC = 0.746300202440151\n","AUC of PRC = 0.3252790254618582\n","min(+P, Se) = 0.35990888382687924\n","f1_score = 0.018223234010844698\n","Epoch 82: Validation AUROC = 0.7463\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83 Batch 0: Train Loss = 0.3259\n","Epoch 83 Batch 50: Train Loss = 0.3564\n","Epoch 83: Train Loss = 0.3539\n","Epoch 83: Validation Loss = 0.3522\n","confusion matrix:\n","[[2716   10]\n"," [ 415   17]]\n","accuracy = 0.8654211759567261\n","precision class 0 = 0.867454469203949\n","precision class 1 = 0.6296296119689941\n","recall class 0 = 0.9963316321372986\n","recall class 1 = 0.039351850748062134\n","AUC of ROC = 0.748719464144996\n","AUC of PRC = 0.33685991265126786\n","min(+P, Se) = 0.3611111111111111\n","f1_score = 0.07407407529626353\n","Epoch 83: Validation AUROC = 0.7487\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84 Batch 0: Train Loss = 0.3669\n","Epoch 84 Batch 50: Train Loss = 0.3514\n","Epoch 84: Train Loss = 0.3532\n","Epoch 84: Validation Loss = 0.3532\n","confusion matrix:\n","[[2724    2]\n"," [ 430    2]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8636651635169983\n","precision class 1 = 0.5\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7474550623624359\n","AUC of PRC = 0.3327102171768372\n","min(+P, Se) = 0.34953703703703703\n","f1_score = 0.009174312316034905\n","Epoch 84: Validation AUROC = 0.7475\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85 Batch 0: Train Loss = 0.3999\n","Epoch 85 Batch 50: Train Loss = 0.3536\n","Epoch 85: Train Loss = 0.3539\n","Epoch 85: Validation Loss = 0.3515\n","confusion matrix:\n","[[2721    5]\n"," [ 425    7]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8649078011512756\n","precision class 1 = 0.5833333134651184\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.016203703358769417\n","AUC of ROC = 0.7530315072959974\n","AUC of PRC = 0.33270313967559595\n","min(+P, Se) = 0.36342592592592593\n","f1_score = 0.03153153094738569\n","Epoch 85: Validation AUROC = 0.7530\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86 Batch 0: Train Loss = 0.3964\n","Epoch 86 Batch 50: Train Loss = 0.3507\n","Epoch 86: Train Loss = 0.3504\n","Epoch 86: Validation Loss = 0.3543\n","confusion matrix:\n","[[2717    9]\n"," [ 422   10]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8655622601509094\n","precision class 1 = 0.5263158082962036\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.023148147389292717\n","AUC of ROC = 0.7457074875682727\n","AUC of PRC = 0.3177666356928463\n","min(+P, Se) = 0.3541666666666667\n","f1_score = 0.04434589893366464\n","Epoch 86: Validation AUROC = 0.7457\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87 Batch 0: Train Loss = 0.3457\n","Epoch 87 Batch 50: Train Loss = 0.3544\n","Epoch 87: Train Loss = 0.3551\n","Epoch 87: Validation Loss = 0.3514\n","confusion matrix:\n","[[2723    3]\n"," [ 427    5]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8644444346427917\n","precision class 1 = 0.625\n","recall class 0 = 0.9988994598388672\n","recall class 1 = 0.011574073694646358\n","AUC of ROC = 0.7521067701964621\n","AUC of PRC = 0.3368953841332224\n","min(+P, Se) = 0.37962962962962965\n","f1_score = 0.022727271430502283\n","Epoch 87: Validation AUROC = 0.7521\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88 Batch 0: Train Loss = 0.3199\n","Epoch 88 Batch 50: Train Loss = 0.3517\n","Epoch 88: Train Loss = 0.3538\n","Epoch 88: Validation Loss = 0.3549\n","confusion matrix:\n","[[2724    2]\n"," [ 430    2]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8636651635169983\n","precision class 1 = 0.5\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7483390397000083\n","AUC of PRC = 0.3239566236326956\n","min(+P, Se) = 0.3515981735159817\n","f1_score = 0.009174312316034905\n","Epoch 88: Validation AUROC = 0.7483\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89 Batch 0: Train Loss = 0.3375\n","Epoch 89 Batch 50: Train Loss = 0.3529\n","Epoch 89: Train Loss = 0.3534\n","Epoch 89: Validation Loss = 0.3551\n","confusion matrix:\n","[[2724    2]\n"," [ 430    2]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.8636651635169983\n","precision class 1 = 0.5\n","recall class 0 = 0.9992663264274597\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7508279326648732\n","AUC of PRC = 0.32943757912146543\n","min(+P, Se) = 0.36551724137931035\n","f1_score = 0.009174312316034905\n","Epoch 89: Validation AUROC = 0.7508\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90 Batch 0: Train Loss = 0.3761\n","Epoch 90 Batch 50: Train Loss = 0.3531\n","Epoch 90: Train Loss = 0.3519\n","Epoch 90: Validation Loss = 0.3530\n","confusion matrix:\n","[[2722    4]\n"," [ 428    4]]\n","accuracy = 0.8632045388221741\n","precision class 0 = 0.864126980304718\n","precision class 1 = 0.5\n","recall class 0 = 0.9985326528549194\n","recall class 1 = 0.009259259328246117\n","AUC of ROC = 0.7470771854025706\n","AUC of PRC = 0.32196119593038564\n","min(+P, Se) = 0.3474903474903475\n","f1_score = 0.018181817450306666\n","Epoch 90: Validation AUROC = 0.7471\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91 Batch 0: Train Loss = 0.3562\n","Epoch 91 Batch 50: Train Loss = 0.3536\n","Epoch 91: Train Loss = 0.3515\n","Epoch 91: Validation Loss = 0.3526\n","confusion matrix:\n","[[2725    1]\n"," [ 430    2]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8637083768844604\n","precision class 1 = 0.6666666865348816\n","recall class 0 = 0.9996331334114075\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7530977419091873\n","AUC of PRC = 0.32968207583423215\n","min(+P, Se) = 0.36794582392776526\n","f1_score = 0.00919540261116663\n","Epoch 91: Validation AUROC = 0.7531\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92 Batch 0: Train Loss = 0.3292\n","Epoch 92 Batch 50: Train Loss = 0.3526\n","Epoch 92: Train Loss = 0.3493\n","Epoch 92: Validation Loss = 0.3551\n","confusion matrix:\n","[[2717    9]\n"," [ 422   10]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8655622601509094\n","precision class 1 = 0.5263158082962036\n","recall class 0 = 0.9966984391212463\n","recall class 1 = 0.023148147389292717\n","AUC of ROC = 0.7425307736202821\n","AUC of PRC = 0.31737399343976364\n","min(+P, Se) = 0.3575883575883576\n","f1_score = 0.04434589893366464\n","Epoch 92: Validation AUROC = 0.7425\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93 Batch 0: Train Loss = 0.3245\n","Epoch 93 Batch 50: Train Loss = 0.3507\n","Epoch 93: Train Loss = 0.3497\n","Epoch 93: Validation Loss = 0.3531\n","confusion matrix:\n","[[2722    4]\n"," [ 427    5]]\n","accuracy = 0.8635212182998657\n","precision class 0 = 0.8644014000892639\n","precision class 1 = 0.5555555820465088\n","recall class 0 = 0.9985326528549194\n","recall class 1 = 0.011574073694646358\n","AUC of ROC = 0.756297383223282\n","AUC of PRC = 0.3300441724971362\n","min(+P, Se) = 0.35648148148148145\n","f1_score = 0.022675735622284525\n","Epoch 93: Validation AUROC = 0.7563\n","\n","------------ Save best model ------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94 Batch 0: Train Loss = 0.3179\n","Epoch 94 Batch 50: Train Loss = 0.3489\n","Epoch 94: Train Loss = 0.3515\n","Epoch 94: Validation Loss = 0.3525\n","confusion matrix:\n","[[2714   12]\n"," [ 416   16]]\n","accuracy = 0.8644711971282959\n","precision class 0 = 0.8670926690101624\n","precision class 1 = 0.5714285969734192\n","recall class 0 = 0.9955979585647583\n","recall class 1 = 0.03703703731298447\n","AUC of ROC = 0.7546831268172061\n","AUC of PRC = 0.33196944359802255\n","min(+P, Se) = 0.3541666666666667\n","f1_score = 0.06956522062280003\n","Epoch 94: Validation AUROC = 0.7547\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95 Batch 0: Train Loss = 0.3850\n","Epoch 95 Batch 50: Train Loss = 0.3487\n","Epoch 95: Train Loss = 0.3509\n","Epoch 95: Validation Loss = 0.3554\n","confusion matrix:\n","[[2721    5]\n"," [ 424    8]]\n","accuracy = 0.8641545176506042\n","precision class 0 = 0.8651828169822693\n","precision class 1 = 0.6153846383094788\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.018518518656492233\n","AUC of ROC = 0.7446562253743104\n","AUC of PRC = 0.3161964029443622\n","min(+P, Se) = 0.3673469387755102\n","f1_score = 0.035955057112861497\n","Epoch 95: Validation AUROC = 0.7447\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96 Batch 0: Train Loss = 0.3319\n","Epoch 96 Batch 50: Train Loss = 0.3576\n","Epoch 96: Train Loss = 0.3569\n","Epoch 96: Validation Loss = 0.3556\n","confusion matrix:\n","[[2726    0]\n"," [ 430    2]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8637515902519226\n","precision class 1 = 1.0\n","recall class 0 = 1.0\n","recall class 1 = 0.004629629664123058\n","AUC of ROC = 0.7538764231950219\n","AUC of PRC = 0.3426402624611993\n","min(+P, Se) = 0.3839080459770115\n","f1_score = 0.00921659009244084\n","Epoch 96: Validation AUROC = 0.7539\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97 Batch 0: Train Loss = 0.3129\n","Epoch 97 Batch 50: Train Loss = 0.3499\n","Epoch 97: Train Loss = 0.3502\n","Epoch 97: Validation Loss = 0.3525\n","confusion matrix:\n","[[2718    8]\n"," [ 418   14]]\n","accuracy = 0.8651044964790344\n","precision class 0 = 0.8667091727256775\n","precision class 1 = 0.6363636255264282\n","recall class 0 = 0.9970653057098389\n","recall class 1 = 0.032407406717538834\n","AUC of ROC = 0.7517042675470775\n","AUC of PRC = 0.333527572141141\n","min(+P, Se) = 0.35185185185185186\n","f1_score = 0.06167400785396493\n","Epoch 97: Validation AUROC = 0.7517\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98 Batch 0: Train Loss = 0.3801\n","Epoch 98 Batch 50: Train Loss = 0.3521\n","Epoch 98: Train Loss = 0.3525\n","Epoch 98: Validation Loss = 0.3528\n","confusion matrix:\n","[[2712   14]\n"," [ 413   19]]\n","accuracy = 0.8647878170013428\n","precision class 0 = 0.8678399920463562\n","precision class 1 = 0.5757575631141663\n","recall class 0 = 0.994864284992218\n","recall class 1 = 0.04398148134350777\n","AUC of ROC = 0.7522273511589359\n","AUC of PRC = 0.33424595069177043\n","min(+P, Se) = 0.3534136546184739\n","f1_score = 0.08172042826832147\n","Epoch 98: Validation AUROC = 0.7522\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-188-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-194-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99 Batch 0: Train Loss = 0.3837\n","Epoch 99 Batch 50: Train Loss = 0.3459\n","Epoch 99: Train Loss = 0.3488\n","Epoch 99: Validation Loss = 0.3515\n","confusion matrix:\n","[[2721    5]\n"," [ 425    7]]\n","accuracy = 0.8638378977775574\n","precision class 0 = 0.8649078011512756\n","precision class 1 = 0.5833333134651184\n","recall class 0 = 0.9981657862663269\n","recall class 1 = 0.016203703358769417\n","AUC of ROC = 0.7532038871226326\n","AUC of PRC = 0.32723007249111546\n","min(+P, Se) = 0.3618421052631579\n","f1_score = 0.03153153094738569\n","Epoch 99: Validation AUROC = 0.7532\n"]}]},{"cell_type":"markdown","source":["# Test"],"metadata":{"id":"zbnQg6g8iCCv"}},{"cell_type":"code","source":["file_name = 'model/concare0'\n","BATCH_SIZE = 256\n","\n","checkpoint = torch.load(file_name)\n","save_epoch = checkpoint['epoch']\n","model.load_state_dict(checkpoint['net'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","model.eval()\n","\n","test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'test'),\n","                                            listfile=os.path.join(data_path, 'test_listfile.csv'),\n","                                            period_length=48.0)\n","test_raw = utils.load_data(test_reader, discretizer, normalizer, return_names=True)\n","test_dataset = Dataset(test_raw['data'][0], test_raw['data'][1], test_raw['names'])\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"],"metadata":{"id":"11s3h5lSQ8_Z","executionInfo":{"status":"ok","timestamp":1681417171781,"user_tz":300,"elapsed":1161089,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["batch_loss = []\n","y_true = []\n","y_pred = []\n","with torch.no_grad():\n","    model.eval()\n","    for step, (batch_x, batch_y, batch_name) in enumerate(test_loader):\n","        batch_x = batch_x.float().to(device)\n","        batch_y = batch_y.float().to(device)\n","        batch_demo = []\n","        for i in range(len(batch_name)):\n","            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n","            cur_idx = cur_id + '_' + cur_ep\n","            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n","            batch_demo.append(cur_demo)\n","\n","        batch_demo = torch.stack(batch_demo).to(device)\n","        output = model(batch_x, batch_demo)[0]\n","\n","        loss = loss_func(output, batch_y.unsqueeze(-1))\n","        batch_loss.append(loss.cpu().detach().numpy())\n","        y_pred += list(output.cpu().detach().numpy().flatten())\n","        y_true += list(batch_y.cpu().numpy().flatten())\n","\n","print(\"\\nTest Prediction Result\")\n","y_pred = np.array(y_pred)\n","y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n","test_res = metrics.print_metrics_binary(y_true, y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbWI5rzyMoUn","executionInfo":{"status":"ok","timestamp":1681417658459,"user_tz":300,"elapsed":2960,"user":{"displayName":"Yimeng Lu","userId":"05134445319834767363"}},"outputId":"d4129ab4-7892-4633-c4ad-2072d0136e85"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-afdceca3a47c>:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  weights = F.softmax(F.tanh(product / denominator)) # B*T\n","<ipython-input-19-a3370d8276f2>:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  score = F.softmax(attention)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Prediction Result\n","confusion matrix:\n","[[2861    1]\n"," [ 373    1]]\n","accuracy = 0.8844252228736877\n","precision class 0 = 0.8846629858016968\n","precision class 1 = 0.5\n","recall class 0 = 0.9996505975723267\n","recall class 1 = 0.002673796843737364\n","AUC of ROC = 0.7537481735594943\n","AUC of PRC = 0.2976196014396501\n","min(+P, Se) = 0.32981530343007914\n","f1_score = 0.005319148955880186\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"y0zU9JdnS6Td"},"execution_count":null,"outputs":[]}]}